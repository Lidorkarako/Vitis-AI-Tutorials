##
##* Â© Copyright (C) 2016-2020 Xilinx, Inc
##*
##* Licensed under the Apache License, Version 2.0 (the "License"). You may
##* not use this file except in compliance with the License. A copy of the
##* License is located at
##*
##*     http://www.apache.org/licenses/LICENSE-2.0
##*
##* Unless required by applicable law or agreed to in writing, software
##* distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
##* WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
##* License for the specific language governing permissions and limitations
##* under the License.
##*/

W0318 20:26:16.970762 24729 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 3, it will be converted to NVCaffe Format.
W0318 20:26:16.972398 24729 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 7, it will be converted to NVCaffe Format.
W0318 20:26:16.972409 24729 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 21, it will be converted to NVCaffe Format.
I0318 20:26:16.976043 24729 decent_p.cpp:296] pruning/alexnetBNnoLRN/regular_rate_0.3/net_finetune.prototxt
I0318 20:26:17.076189 24729 gpu_memory.cpp:99] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0318 20:26:17.076905 24729 gpu_memory.cpp:101] Total memory: 25620447232, Free: 24555880448, dev_info[0]: total=25620447232 free=24555880448
I0318 20:26:17.076916 24729 caffe_interface.cpp:539] Using GPUs 0
I0318 20:26:17.077150 24729 caffe_interface.cpp:544] GPU 0: Quadro P6000
I0318 20:26:17.915374 24729 solver.cpp:97] Initializing solver from parameters:
test_iter: 80
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 12000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 500
snapshot_prefix: "pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/"
solver_mode: GPU
device_id: 0
random_seed: 1201
net: "pruning/alexnetBNnoLRN/regular_rate_0.3/net_finetune.prototxt"
type: "Adam"
I0318 20:26:17.915486 24729 solver.cpp:145] Creating training net from net file: pruning/alexnetBNnoLRN/regular_rate_0.3/net_finetune.prototxt
I0318 20:26:17.915696 24729 net.cpp:369] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0318 20:26:17.915706 24729 net.cpp:369] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0318 20:26:17.915709 24729 net.cpp:369] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0318 20:26:17.915822 24729 net.cpp:98] Initializing net from parameters:
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0318 20:26:17.915879 24729 layer_factory.hpp:123] Creating layer data
I0318 20:26:17.915997 24729 internal_thread.cpp:73] Starting internal thread(s) on GPU 0
I0318 20:26:17.916541 24729 net.cpp:140] Creating Layer data
I0318 20:26:17.916550 24729 net.cpp:455] data -> data
I0318 20:26:17.916558 24729 net.cpp:455] data -> label
I0318 20:26:17.918782 24768 db_lmdb.cpp:81] Opened lmdb input/lmdb/train_lmdb
I0318 20:26:17.918829 24768 data_reader.cpp:166] TRAIN: reading data using 1 channel(s)
I0318 20:26:17.919091 24729 data_layer.cpp:124] ReshapePrefetch 256, 3, 227, 227
I0318 20:26:17.919154 24729 data_layer.cpp:129] output data size: 256,3,227,227
I0318 20:26:18.301183 24729 internal_thread.cpp:73] Starting internal thread(s) on GPU 0
I0318 20:26:18.301247 24729 net.cpp:190] Setting up data
I0318 20:26:18.301254 24729 net.cpp:197] Top shape: 256 3 227 227 (39574272)
I0318 20:26:18.301257 24729 net.cpp:197] Top shape: 256 (256)
I0318 20:26:18.301259 24729 net.cpp:205] Memory required for data: 158298112
I0318 20:26:18.301265 24729 layer_factory.hpp:123] Creating layer conv1
I0318 20:26:18.301276 24729 net.cpp:140] Creating Layer conv1
I0318 20:26:18.301280 24729 net.cpp:481] conv1 <- data
I0318 20:26:18.301293 24729 net.cpp:455] conv1 -> conv1
I0318 20:26:18.301806 24729 net.cpp:190] Setting up conv1
I0318 20:26:18.301815 24729 net.cpp:197] Top shape: 256 96 55 55 (74342400)
I0318 20:26:18.301818 24729 net.cpp:205] Memory required for data: 455667712
I0318 20:26:18.301831 24729 layer_factory.hpp:123] Creating layer bn1
I0318 20:26:18.301838 24729 net.cpp:140] Creating Layer bn1
I0318 20:26:18.301841 24729 net.cpp:481] bn1 <- conv1
I0318 20:26:18.301847 24729 net.cpp:455] bn1 -> bn1
I0318 20:26:18.302274 24729 net.cpp:190] Setting up bn1
I0318 20:26:18.302281 24729 net.cpp:197] Top shape: 256 96 55 55 (74342400)
I0318 20:26:18.302284 24729 net.cpp:205] Memory required for data: 753037312
I0318 20:26:18.302291 24729 layer_factory.hpp:123] Creating layer relu1
I0318 20:26:18.302296 24729 net.cpp:140] Creating Layer relu1
I0318 20:26:18.302299 24729 net.cpp:481] relu1 <- bn1
I0318 20:26:18.302302 24729 net.cpp:455] relu1 -> relu1
I0318 20:26:18.302330 24729 net.cpp:190] Setting up relu1
I0318 20:26:18.302336 24729 net.cpp:197] Top shape: 256 96 55 55 (74342400)
I0318 20:26:18.302340 24729 net.cpp:205] Memory required for data: 1050406912
I0318 20:26:18.302341 24729 layer_factory.hpp:123] Creating layer pool1
I0318 20:26:18.302346 24729 net.cpp:140] Creating Layer pool1
I0318 20:26:18.302350 24729 net.cpp:481] pool1 <- relu1
I0318 20:26:18.302352 24729 net.cpp:455] pool1 -> pool1
I0318 20:26:18.302376 24729 net.cpp:190] Setting up pool1
I0318 20:26:18.302382 24729 net.cpp:197] Top shape: 256 96 27 27 (17915904)
I0318 20:26:18.302386 24729 net.cpp:205] Memory required for data: 1122070528
I0318 20:26:18.302389 24729 layer_factory.hpp:123] Creating layer conv2
I0318 20:26:18.302395 24729 net.cpp:140] Creating Layer conv2
I0318 20:26:18.302399 24729 net.cpp:481] conv2 <- pool1
I0318 20:26:18.302404 24729 net.cpp:455] conv2 -> conv2
I0318 20:26:18.317602 24729 net.cpp:190] Setting up conv2
I0318 20:26:18.317620 24729 net.cpp:197] Top shape: 256 256 27 27 (47775744)
I0318 20:26:18.317622 24729 net.cpp:205] Memory required for data: 1313173504
I0318 20:26:18.317631 24729 layer_factory.hpp:123] Creating layer bn2
I0318 20:26:18.317638 24729 net.cpp:140] Creating Layer bn2
I0318 20:26:18.317642 24729 net.cpp:481] bn2 <- conv2
I0318 20:26:18.317647 24729 net.cpp:455] bn2 -> bn2
I0318 20:26:18.318126 24729 net.cpp:190] Setting up bn2
I0318 20:26:18.318135 24729 net.cpp:197] Top shape: 256 256 27 27 (47775744)
I0318 20:26:18.318137 24729 net.cpp:205] Memory required for data: 1504276480
I0318 20:26:18.318145 24729 layer_factory.hpp:123] Creating layer relu2
I0318 20:26:18.318150 24729 net.cpp:140] Creating Layer relu2
I0318 20:26:18.318153 24729 net.cpp:481] relu2 <- bn2
I0318 20:26:18.318157 24729 net.cpp:455] relu2 -> relu2
I0318 20:26:18.318176 24729 net.cpp:190] Setting up relu2
I0318 20:26:18.318182 24729 net.cpp:197] Top shape: 256 256 27 27 (47775744)
I0318 20:26:18.318187 24729 net.cpp:205] Memory required for data: 1695379456
I0318 20:26:18.318192 24729 layer_factory.hpp:123] Creating layer pool2
I0318 20:26:18.318198 24729 net.cpp:140] Creating Layer pool2
I0318 20:26:18.318203 24729 net.cpp:481] pool2 <- relu2
I0318 20:26:18.318209 24729 net.cpp:455] pool2 -> pool2
I0318 20:26:18.318243 24729 net.cpp:190] Setting up pool2
I0318 20:26:18.318249 24729 net.cpp:197] Top shape: 256 256 13 13 (11075584)
I0318 20:26:18.318251 24729 net.cpp:205] Memory required for data: 1739681792
I0318 20:26:18.318255 24729 layer_factory.hpp:123] Creating layer conv3
I0318 20:26:18.318264 24729 net.cpp:140] Creating Layer conv3
I0318 20:26:18.318286 24729 net.cpp:481] conv3 <- pool2
I0318 20:26:18.318295 24729 net.cpp:455] conv3 -> conv3
I0318 20:26:18.329344 24729 net.cpp:190] Setting up conv3
I0318 20:26:18.329403 24729 net.cpp:197] Top shape: 256 384 13 13 (16613376)
I0318 20:26:18.329416 24729 net.cpp:205] Memory required for data: 1806135296
I0318 20:26:18.329433 24729 layer_factory.hpp:123] Creating layer relu3
I0318 20:26:18.329453 24729 net.cpp:140] Creating Layer relu3
I0318 20:26:18.329465 24729 net.cpp:481] relu3 <- conv3
I0318 20:26:18.329481 24729 net.cpp:455] relu3 -> relu3
I0318 20:26:18.329519 24729 net.cpp:190] Setting up relu3
I0318 20:26:18.329536 24729 net.cpp:197] Top shape: 256 384 13 13 (16613376)
I0318 20:26:18.329547 24729 net.cpp:205] Memory required for data: 1872588800
I0318 20:26:18.329560 24729 layer_factory.hpp:123] Creating layer conv4
I0318 20:26:18.329577 24729 net.cpp:140] Creating Layer conv4
I0318 20:26:18.329591 24729 net.cpp:481] conv4 <- relu3
I0318 20:26:18.329604 24729 net.cpp:455] conv4 -> conv4
I0318 20:26:18.347708 24729 net.cpp:190] Setting up conv4
I0318 20:26:18.347731 24729 net.cpp:197] Top shape: 256 384 13 13 (16613376)
I0318 20:26:18.347734 24729 net.cpp:205] Memory required for data: 1939042304
I0318 20:26:18.347745 24729 layer_factory.hpp:123] Creating layer relu4
I0318 20:26:18.347754 24729 net.cpp:140] Creating Layer relu4
I0318 20:26:18.347756 24729 net.cpp:481] relu4 <- conv4
I0318 20:26:18.347762 24729 net.cpp:455] relu4 -> relu4
I0318 20:26:18.347788 24729 net.cpp:190] Setting up relu4
I0318 20:26:18.347795 24729 net.cpp:197] Top shape: 256 384 13 13 (16613376)
I0318 20:26:18.347798 24729 net.cpp:205] Memory required for data: 2005495808
I0318 20:26:18.347802 24729 layer_factory.hpp:123] Creating layer conv5
I0318 20:26:18.347811 24729 net.cpp:140] Creating Layer conv5
I0318 20:26:18.347816 24729 net.cpp:481] conv5 <- relu4
I0318 20:26:18.347822 24729 net.cpp:455] conv5 -> conv5
I0318 20:26:18.365077 24729 net.cpp:190] Setting up conv5
I0318 20:26:18.365099 24729 net.cpp:197] Top shape: 256 256 13 13 (11075584)
I0318 20:26:18.365103 24729 net.cpp:205] Memory required for data: 2049798144
I0318 20:26:18.365111 24729 layer_factory.hpp:123] Creating layer relu5
I0318 20:26:18.365123 24729 net.cpp:140] Creating Layer relu5
I0318 20:26:18.365126 24729 net.cpp:481] relu5 <- conv5
I0318 20:26:18.365134 24729 net.cpp:455] relu5 -> relu5
I0318 20:26:18.365178 24729 net.cpp:190] Setting up relu5
I0318 20:26:18.365193 24729 net.cpp:197] Top shape: 256 256 13 13 (11075584)
I0318 20:26:18.365208 24729 net.cpp:205] Memory required for data: 2094100480
I0318 20:26:18.365219 24729 layer_factory.hpp:123] Creating layer pool5
I0318 20:26:18.365236 24729 net.cpp:140] Creating Layer pool5
I0318 20:26:18.365252 24729 net.cpp:481] pool5 <- relu5
I0318 20:26:18.365267 24729 net.cpp:455] pool5 -> pool5
I0318 20:26:18.365311 24729 net.cpp:190] Setting up pool5
I0318 20:26:18.365329 24729 net.cpp:197] Top shape: 256 256 6 6 (2359296)
I0318 20:26:18.365342 24729 net.cpp:205] Memory required for data: 2103537664
I0318 20:26:18.365366 24729 layer_factory.hpp:123] Creating layer fc6
I0318 20:26:18.365391 24729 net.cpp:140] Creating Layer fc6
I0318 20:26:18.365407 24729 net.cpp:481] fc6 <- pool5
I0318 20:26:18.365428 24729 net.cpp:455] fc6 -> fc6
I0318 20:26:18.709262 24729 net.cpp:190] Setting up fc6
I0318 20:26:18.709287 24729 net.cpp:197] Top shape: 256 4096 (1048576)
I0318 20:26:18.709290 24729 net.cpp:205] Memory required for data: 2107731968
I0318 20:26:18.709297 24729 layer_factory.hpp:123] Creating layer relu6
I0318 20:26:18.709304 24729 net.cpp:140] Creating Layer relu6
I0318 20:26:18.709306 24729 net.cpp:481] relu6 <- fc6
I0318 20:26:18.709311 24729 net.cpp:455] relu6 -> relu6
I0318 20:26:18.709326 24729 net.cpp:190] Setting up relu6
I0318 20:26:18.709334 24729 net.cpp:197] Top shape: 256 4096 (1048576)
I0318 20:26:18.709336 24729 net.cpp:205] Memory required for data: 2111926272
I0318 20:26:18.709337 24729 layer_factory.hpp:123] Creating layer drop6
I0318 20:26:18.709342 24729 net.cpp:140] Creating Layer drop6
I0318 20:26:18.709367 24729 net.cpp:481] drop6 <- relu6
I0318 20:26:18.709372 24729 net.cpp:455] drop6 -> drop6
I0318 20:26:18.709414 24729 net.cpp:190] Setting up drop6
I0318 20:26:18.709419 24729 net.cpp:197] Top shape: 256 4096 (1048576)
I0318 20:26:18.709421 24729 net.cpp:205] Memory required for data: 2116120576
I0318 20:26:18.709424 24729 layer_factory.hpp:123] Creating layer fc7
I0318 20:26:18.709429 24729 net.cpp:140] Creating Layer fc7
I0318 20:26:18.709434 24729 net.cpp:481] fc7 <- drop6
I0318 20:26:18.709439 24729 net.cpp:455] fc7 -> fc7
I0318 20:26:18.845014 24729 net.cpp:190] Setting up fc7
I0318 20:26:18.845038 24729 net.cpp:197] Top shape: 256 4096 (1048576)
I0318 20:26:18.845041 24729 net.cpp:205] Memory required for data: 2120314880
I0318 20:26:18.845047 24729 layer_factory.hpp:123] Creating layer bn7
I0318 20:26:18.845055 24729 net.cpp:140] Creating Layer bn7
I0318 20:26:18.845058 24729 net.cpp:481] bn7 <- fc7
I0318 20:26:18.845064 24729 net.cpp:455] bn7 -> bn7
I0318 20:26:18.845461 24729 net.cpp:190] Setting up bn7
I0318 20:26:18.845468 24729 net.cpp:197] Top shape: 256 4096 (1048576)
I0318 20:26:18.845470 24729 net.cpp:205] Memory required for data: 2124509184
I0318 20:26:18.845476 24729 layer_factory.hpp:123] Creating layer relu7
I0318 20:26:18.845482 24729 net.cpp:140] Creating Layer relu7
I0318 20:26:18.845484 24729 net.cpp:481] relu7 <- bn7
I0318 20:26:18.845487 24729 net.cpp:455] relu7 -> relu7
I0318 20:26:18.845504 24729 net.cpp:190] Setting up relu7
I0318 20:26:18.845510 24729 net.cpp:197] Top shape: 256 4096 (1048576)
I0318 20:26:18.845512 24729 net.cpp:205] Memory required for data: 2128703488
I0318 20:26:18.845515 24729 layer_factory.hpp:123] Creating layer drop7
I0318 20:26:18.845536 24729 net.cpp:140] Creating Layer drop7
I0318 20:26:18.845540 24729 net.cpp:481] drop7 <- relu7
I0318 20:26:18.845544 24729 net.cpp:455] drop7 -> drop7
I0318 20:26:18.845568 24729 net.cpp:190] Setting up drop7
I0318 20:26:18.845574 24729 net.cpp:197] Top shape: 256 4096 (1048576)
I0318 20:26:18.845577 24729 net.cpp:205] Memory required for data: 2132897792
I0318 20:26:18.845580 24729 layer_factory.hpp:123] Creating layer fc8
I0318 20:26:18.845587 24729 net.cpp:140] Creating Layer fc8
I0318 20:26:18.845588 24729 net.cpp:481] fc8 <- drop7
I0318 20:26:18.845592 24729 net.cpp:455] fc8 -> fc8
I0318 20:26:18.845726 24729 net.cpp:190] Setting up fc8
I0318 20:26:18.845731 24729 net.cpp:197] Top shape: 256 2 (512)
I0318 20:26:18.845732 24729 net.cpp:205] Memory required for data: 2132899840
I0318 20:26:18.845736 24729 layer_factory.hpp:123] Creating layer loss
I0318 20:26:18.845739 24729 net.cpp:140] Creating Layer loss
I0318 20:26:18.845742 24729 net.cpp:481] loss <- fc8
I0318 20:26:18.845746 24729 net.cpp:481] loss <- label
I0318 20:26:18.845748 24729 net.cpp:455] loss -> loss
I0318 20:26:18.845755 24729 layer_factory.hpp:123] Creating layer loss
I0318 20:26:18.845804 24729 net.cpp:190] Setting up loss
I0318 20:26:18.845809 24729 net.cpp:197] Top shape: (1)
I0318 20:26:18.845811 24729 net.cpp:200]     with loss weight 1
I0318 20:26:18.845822 24729 net.cpp:205] Memory required for data: 2132899844
I0318 20:26:18.845825 24729 net.cpp:266] loss needs backward computation.
I0318 20:26:18.845829 24729 net.cpp:266] fc8 needs backward computation.
I0318 20:26:18.845831 24729 net.cpp:266] drop7 needs backward computation.
I0318 20:26:18.845834 24729 net.cpp:266] relu7 needs backward computation.
I0318 20:26:18.845837 24729 net.cpp:266] bn7 needs backward computation.
I0318 20:26:18.845841 24729 net.cpp:266] fc7 needs backward computation.
I0318 20:26:18.845844 24729 net.cpp:266] drop6 needs backward computation.
I0318 20:26:18.845847 24729 net.cpp:266] relu6 needs backward computation.
I0318 20:26:18.845850 24729 net.cpp:266] fc6 needs backward computation.
I0318 20:26:18.845854 24729 net.cpp:266] pool5 needs backward computation.
I0318 20:26:18.845857 24729 net.cpp:266] relu5 needs backward computation.
I0318 20:26:18.845860 24729 net.cpp:266] conv5 needs backward computation.
I0318 20:26:18.845863 24729 net.cpp:266] relu4 needs backward computation.
I0318 20:26:18.845881 24729 net.cpp:266] conv4 needs backward computation.
I0318 20:26:18.845883 24729 net.cpp:266] relu3 needs backward computation.
I0318 20:26:18.845885 24729 net.cpp:266] conv3 needs backward computation.
I0318 20:26:18.845890 24729 net.cpp:266] pool2 needs backward computation.
I0318 20:26:18.845893 24729 net.cpp:266] relu2 needs backward computation.
I0318 20:26:18.845896 24729 net.cpp:266] bn2 needs backward computation.
I0318 20:26:18.845899 24729 net.cpp:266] conv2 needs backward computation.
I0318 20:26:18.845901 24729 net.cpp:266] pool1 needs backward computation.
I0318 20:26:18.845904 24729 net.cpp:266] relu1 needs backward computation.
I0318 20:26:18.845907 24729 net.cpp:266] bn1 needs backward computation.
I0318 20:26:18.845911 24729 net.cpp:266] conv1 needs backward computation.
I0318 20:26:18.845914 24729 net.cpp:268] data does not need backward computation.
I0318 20:26:18.845917 24729 net.cpp:310] This network produces output loss
I0318 20:26:18.845935 24729 net.cpp:330] Network initialization done.
I0318 20:26:18.846158 24729 solver.cpp:235] Creating test net (#0) specified by net file: pruning/alexnetBNnoLRN/regular_rate_0.3/net_finetune.prototxt
I0318 20:26:18.846181 24729 net.cpp:369] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0318 20:26:18.846314 24729 net.cpp:98] Initializing net from parameters:
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0318 20:26:18.846395 24729 layer_factory.hpp:123] Creating layer data
I0318 20:26:18.846431 24729 internal_thread.cpp:73] Starting internal thread(s) on GPU 0
I0318 20:26:18.846995 24729 net.cpp:140] Creating Layer data
I0318 20:26:18.847007 24729 net.cpp:455] data -> data
I0318 20:26:18.847016 24729 net.cpp:455] data -> label
I0318 20:26:18.849433 24799 db_lmdb.cpp:81] Opened lmdb input/lmdb/valid_lmdb
I0318 20:26:18.849468 24799 data_reader.cpp:166] TEST: reading data using 1 channel(s)
I0318 20:26:18.849727 24729 data_layer.cpp:124] ReshapePrefetch 50, 3, 227, 227
I0318 20:26:18.849807 24729 data_layer.cpp:129] output data size: 50,3,227,227
I0318 20:26:18.926491 24729 internal_thread.cpp:73] Starting internal thread(s) on GPU 0
I0318 20:26:18.926537 24729 net.cpp:190] Setting up data
I0318 20:26:18.926563 24729 net.cpp:197] Top shape: 50 3 227 227 (7729350)
I0318 20:26:18.926565 24729 net.cpp:197] Top shape: 50 (50)
I0318 20:26:18.926568 24729 net.cpp:205] Memory required for data: 30917600
I0318 20:26:18.926570 24729 layer_factory.hpp:123] Creating layer label_data_1_split
I0318 20:26:18.926596 24729 net.cpp:140] Creating Layer label_data_1_split
I0318 20:26:18.926601 24729 net.cpp:481] label_data_1_split <- label
I0318 20:26:18.926606 24729 net.cpp:455] label_data_1_split -> label_data_1_split_0
I0318 20:26:18.926614 24729 net.cpp:455] label_data_1_split -> label_data_1_split_1
I0318 20:26:18.926617 24729 net.cpp:455] label_data_1_split -> label_data_1_split_2
I0318 20:26:18.926667 24729 net.cpp:190] Setting up label_data_1_split
I0318 20:26:18.926672 24729 net.cpp:197] Top shape: 50 (50)
I0318 20:26:18.926674 24729 net.cpp:197] Top shape: 50 (50)
I0318 20:26:18.926677 24729 net.cpp:197] Top shape: 50 (50)
I0318 20:26:18.926679 24729 net.cpp:205] Memory required for data: 30918200
I0318 20:26:18.926681 24729 layer_factory.hpp:123] Creating layer conv1
I0318 20:26:18.926689 24729 net.cpp:140] Creating Layer conv1
I0318 20:26:18.926693 24729 net.cpp:481] conv1 <- data
I0318 20:26:18.926697 24729 net.cpp:455] conv1 -> conv1
I0318 20:26:18.927206 24729 net.cpp:190] Setting up conv1
I0318 20:26:18.927213 24729 net.cpp:197] Top shape: 50 96 55 55 (14520000)
I0318 20:26:18.927217 24729 net.cpp:205] Memory required for data: 88998200
I0318 20:26:18.927224 24729 layer_factory.hpp:123] Creating layer bn1
I0318 20:26:18.927232 24729 net.cpp:140] Creating Layer bn1
I0318 20:26:18.927234 24729 net.cpp:481] bn1 <- conv1
I0318 20:26:18.927239 24729 net.cpp:455] bn1 -> bn1
I0318 20:26:18.927666 24729 net.cpp:190] Setting up bn1
I0318 20:26:18.927671 24729 net.cpp:197] Top shape: 50 96 55 55 (14520000)
I0318 20:26:18.927673 24729 net.cpp:205] Memory required for data: 147078200
I0318 20:26:18.927681 24729 layer_factory.hpp:123] Creating layer relu1
I0318 20:26:18.927687 24729 net.cpp:140] Creating Layer relu1
I0318 20:26:18.927690 24729 net.cpp:481] relu1 <- bn1
I0318 20:26:18.927695 24729 net.cpp:455] relu1 -> relu1
I0318 20:26:18.927709 24729 net.cpp:190] Setting up relu1
I0318 20:26:18.927713 24729 net.cpp:197] Top shape: 50 96 55 55 (14520000)
I0318 20:26:18.927716 24729 net.cpp:205] Memory required for data: 205158200
I0318 20:26:18.927717 24729 layer_factory.hpp:123] Creating layer pool1
I0318 20:26:18.927723 24729 net.cpp:140] Creating Layer pool1
I0318 20:26:18.927726 24729 net.cpp:481] pool1 <- relu1
I0318 20:26:18.927729 24729 net.cpp:455] pool1 -> pool1
I0318 20:26:18.927750 24729 net.cpp:190] Setting up pool1
I0318 20:26:18.927755 24729 net.cpp:197] Top shape: 50 96 27 27 (3499200)
I0318 20:26:18.927757 24729 net.cpp:205] Memory required for data: 219155000
I0318 20:26:18.927758 24729 layer_factory.hpp:123] Creating layer conv2
I0318 20:26:18.927764 24729 net.cpp:140] Creating Layer conv2
I0318 20:26:18.927768 24729 net.cpp:481] conv2 <- pool1
I0318 20:26:18.927772 24729 net.cpp:455] conv2 -> conv2
I0318 20:26:18.933715 24729 net.cpp:190] Setting up conv2
I0318 20:26:18.933733 24729 net.cpp:197] Top shape: 50 256 27 27 (9331200)
I0318 20:26:18.933738 24729 net.cpp:205] Memory required for data: 256479800
I0318 20:26:18.933748 24729 layer_factory.hpp:123] Creating layer bn2
I0318 20:26:18.933770 24729 net.cpp:140] Creating Layer bn2
I0318 20:26:18.933776 24729 net.cpp:481] bn2 <- conv2
I0318 20:26:18.933784 24729 net.cpp:455] bn2 -> bn2
I0318 20:26:18.934244 24729 net.cpp:190] Setting up bn2
I0318 20:26:18.934252 24729 net.cpp:197] Top shape: 50 256 27 27 (9331200)
I0318 20:26:18.934255 24729 net.cpp:205] Memory required for data: 293804600
I0318 20:26:18.934265 24729 layer_factory.hpp:123] Creating layer relu2
I0318 20:26:18.934276 24729 net.cpp:140] Creating Layer relu2
I0318 20:26:18.934281 24729 net.cpp:481] relu2 <- bn2
I0318 20:26:18.934288 24729 net.cpp:455] relu2 -> relu2
I0318 20:26:18.934311 24729 net.cpp:190] Setting up relu2
I0318 20:26:18.934317 24729 net.cpp:197] Top shape: 50 256 27 27 (9331200)
I0318 20:26:18.934330 24729 net.cpp:205] Memory required for data: 331129400
I0318 20:26:18.934334 24729 layer_factory.hpp:123] Creating layer pool2
I0318 20:26:18.934341 24729 net.cpp:140] Creating Layer pool2
I0318 20:26:18.934345 24729 net.cpp:481] pool2 <- relu2
I0318 20:26:18.934352 24729 net.cpp:455] pool2 -> pool2
I0318 20:26:18.934379 24729 net.cpp:190] Setting up pool2
I0318 20:26:18.934386 24729 net.cpp:197] Top shape: 50 256 13 13 (2163200)
I0318 20:26:18.934389 24729 net.cpp:205] Memory required for data: 339782200
I0318 20:26:18.934392 24729 layer_factory.hpp:123] Creating layer conv3
I0318 20:26:18.934403 24729 net.cpp:140] Creating Layer conv3
I0318 20:26:18.934407 24729 net.cpp:481] conv3 <- pool2
I0318 20:26:18.934418 24729 net.cpp:455] conv3 -> conv3
I0318 20:26:18.946017 24729 net.cpp:190] Setting up conv3
I0318 20:26:18.946060 24729 net.cpp:197] Top shape: 50 384 13 13 (3244800)
I0318 20:26:18.946065 24729 net.cpp:205] Memory required for data: 352761400
I0318 20:26:18.946074 24729 layer_factory.hpp:123] Creating layer relu3
I0318 20:26:18.946082 24729 net.cpp:140] Creating Layer relu3
I0318 20:26:18.946089 24729 net.cpp:481] relu3 <- conv3
I0318 20:26:18.946099 24729 net.cpp:455] relu3 -> relu3
I0318 20:26:18.946128 24729 net.cpp:190] Setting up relu3
I0318 20:26:18.946136 24729 net.cpp:197] Top shape: 50 384 13 13 (3244800)
I0318 20:26:18.946141 24729 net.cpp:205] Memory required for data: 365740600
I0318 20:26:18.946146 24729 layer_factory.hpp:123] Creating layer conv4
I0318 20:26:18.946159 24729 net.cpp:140] Creating Layer conv4
I0318 20:26:18.946166 24729 net.cpp:481] conv4 <- relu3
I0318 20:26:18.946173 24729 net.cpp:455] conv4 -> conv4
I0318 20:26:18.960304 24729 net.cpp:190] Setting up conv4
I0318 20:26:18.960325 24729 net.cpp:197] Top shape: 50 384 13 13 (3244800)
I0318 20:26:18.960330 24729 net.cpp:205] Memory required for data: 378719800
I0318 20:26:18.960343 24729 layer_factory.hpp:123] Creating layer relu4
I0318 20:26:18.960353 24729 net.cpp:140] Creating Layer relu4
I0318 20:26:18.960359 24729 net.cpp:481] relu4 <- conv4
I0318 20:26:18.960368 24729 net.cpp:455] relu4 -> relu4
I0318 20:26:18.960398 24729 net.cpp:190] Setting up relu4
I0318 20:26:18.960404 24729 net.cpp:197] Top shape: 50 384 13 13 (3244800)
I0318 20:26:18.960407 24729 net.cpp:205] Memory required for data: 391699000
I0318 20:26:18.960409 24729 layer_factory.hpp:123] Creating layer conv5
I0318 20:26:18.960417 24729 net.cpp:140] Creating Layer conv5
I0318 20:26:18.960423 24729 net.cpp:481] conv5 <- relu4
I0318 20:26:18.960433 24729 net.cpp:455] conv5 -> conv5
I0318 20:26:18.974362 24729 net.cpp:190] Setting up conv5
I0318 20:26:18.974385 24729 net.cpp:197] Top shape: 50 256 13 13 (2163200)
I0318 20:26:18.974390 24729 net.cpp:205] Memory required for data: 400351800
I0318 20:26:18.974397 24729 layer_factory.hpp:123] Creating layer relu5
I0318 20:26:18.974404 24729 net.cpp:140] Creating Layer relu5
I0318 20:26:18.974409 24729 net.cpp:481] relu5 <- conv5
I0318 20:26:18.974417 24729 net.cpp:455] relu5 -> relu5
I0318 20:26:18.974459 24729 net.cpp:190] Setting up relu5
I0318 20:26:18.974463 24729 net.cpp:197] Top shape: 50 256 13 13 (2163200)
I0318 20:26:18.974465 24729 net.cpp:205] Memory required for data: 409004600
I0318 20:26:18.974468 24729 layer_factory.hpp:123] Creating layer pool5
I0318 20:26:18.974475 24729 net.cpp:140] Creating Layer pool5
I0318 20:26:18.974478 24729 net.cpp:481] pool5 <- relu5
I0318 20:26:18.974483 24729 net.cpp:455] pool5 -> pool5
I0318 20:26:18.974524 24729 net.cpp:190] Setting up pool5
I0318 20:26:18.974550 24729 net.cpp:197] Top shape: 50 256 6 6 (460800)
I0318 20:26:18.974555 24729 net.cpp:205] Memory required for data: 410847800
I0318 20:26:18.974557 24729 layer_factory.hpp:123] Creating layer fc6
I0318 20:26:18.974566 24729 net.cpp:140] Creating Layer fc6
I0318 20:26:18.974571 24729 net.cpp:481] fc6 <- pool5
I0318 20:26:18.974577 24729 net.cpp:455] fc6 -> fc6
I0318 20:26:19.295708 24729 net.cpp:190] Setting up fc6
I0318 20:26:19.295734 24729 net.cpp:197] Top shape: 50 4096 (204800)
I0318 20:26:19.295773 24729 net.cpp:205] Memory required for data: 411667000
I0318 20:26:19.295783 24729 layer_factory.hpp:123] Creating layer relu6
I0318 20:26:19.295791 24729 net.cpp:140] Creating Layer relu6
I0318 20:26:19.295797 24729 net.cpp:481] relu6 <- fc6
I0318 20:26:19.295804 24729 net.cpp:455] relu6 -> relu6
I0318 20:26:19.295831 24729 net.cpp:190] Setting up relu6
I0318 20:26:19.295835 24729 net.cpp:197] Top shape: 50 4096 (204800)
I0318 20:26:19.295840 24729 net.cpp:205] Memory required for data: 412486200
I0318 20:26:19.295841 24729 layer_factory.hpp:123] Creating layer drop6
I0318 20:26:19.295847 24729 net.cpp:140] Creating Layer drop6
I0318 20:26:19.295851 24729 net.cpp:481] drop6 <- relu6
I0318 20:26:19.295856 24729 net.cpp:455] drop6 -> drop6
I0318 20:26:19.295878 24729 net.cpp:190] Setting up drop6
I0318 20:26:19.295882 24729 net.cpp:197] Top shape: 50 4096 (204800)
I0318 20:26:19.295886 24729 net.cpp:205] Memory required for data: 413305400
I0318 20:26:19.295888 24729 layer_factory.hpp:123] Creating layer fc7
I0318 20:26:19.295895 24729 net.cpp:140] Creating Layer fc7
I0318 20:26:19.295898 24729 net.cpp:481] fc7 <- drop6
I0318 20:26:19.295904 24729 net.cpp:455] fc7 -> fc7
I0318 20:26:19.437921 24729 net.cpp:190] Setting up fc7
I0318 20:26:19.437947 24729 net.cpp:197] Top shape: 50 4096 (204800)
I0318 20:26:19.437950 24729 net.cpp:205] Memory required for data: 414124600
I0318 20:26:19.437959 24729 layer_factory.hpp:123] Creating layer bn7
I0318 20:26:19.437970 24729 net.cpp:140] Creating Layer bn7
I0318 20:26:19.437974 24729 net.cpp:481] bn7 <- fc7
I0318 20:26:19.437983 24729 net.cpp:455] bn7 -> bn7
I0318 20:26:19.438406 24729 net.cpp:190] Setting up bn7
I0318 20:26:19.438412 24729 net.cpp:197] Top shape: 50 4096 (204800)
I0318 20:26:19.438416 24729 net.cpp:205] Memory required for data: 414943800
I0318 20:26:19.438423 24729 layer_factory.hpp:123] Creating layer relu7
I0318 20:26:19.438431 24729 net.cpp:140] Creating Layer relu7
I0318 20:26:19.438436 24729 net.cpp:481] relu7 <- bn7
I0318 20:26:19.438441 24729 net.cpp:455] relu7 -> relu7
I0318 20:26:19.438458 24729 net.cpp:190] Setting up relu7
I0318 20:26:19.438462 24729 net.cpp:197] Top shape: 50 4096 (204800)
I0318 20:26:19.438465 24729 net.cpp:205] Memory required for data: 415763000
I0318 20:26:19.438468 24729 layer_factory.hpp:123] Creating layer drop7
I0318 20:26:19.438475 24729 net.cpp:140] Creating Layer drop7
I0318 20:26:19.438478 24729 net.cpp:481] drop7 <- relu7
I0318 20:26:19.438484 24729 net.cpp:455] drop7 -> drop7
I0318 20:26:19.438505 24729 net.cpp:190] Setting up drop7
I0318 20:26:19.438509 24729 net.cpp:197] Top shape: 50 4096 (204800)
I0318 20:26:19.438513 24729 net.cpp:205] Memory required for data: 416582200
I0318 20:26:19.438516 24729 layer_factory.hpp:123] Creating layer fc8
I0318 20:26:19.438524 24729 net.cpp:140] Creating Layer fc8
I0318 20:26:19.438526 24729 net.cpp:481] fc8 <- drop7
I0318 20:26:19.438532 24729 net.cpp:455] fc8 -> fc8
I0318 20:26:19.438663 24729 net.cpp:190] Setting up fc8
I0318 20:26:19.438668 24729 net.cpp:197] Top shape: 50 2 (100)
I0318 20:26:19.438670 24729 net.cpp:205] Memory required for data: 416582600
I0318 20:26:19.438675 24729 layer_factory.hpp:123] Creating layer fc8_fc8_0_split
I0318 20:26:19.438681 24729 net.cpp:140] Creating Layer fc8_fc8_0_split
I0318 20:26:19.438685 24729 net.cpp:481] fc8_fc8_0_split <- fc8
I0318 20:26:19.438689 24729 net.cpp:455] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0318 20:26:19.438697 24729 net.cpp:455] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0318 20:26:19.438704 24729 net.cpp:455] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0318 20:26:19.438740 24729 net.cpp:190] Setting up fc8_fc8_0_split
I0318 20:26:19.438743 24729 net.cpp:197] Top shape: 50 2 (100)
I0318 20:26:19.438747 24729 net.cpp:197] Top shape: 50 2 (100)
I0318 20:26:19.438751 24729 net.cpp:197] Top shape: 50 2 (100)
I0318 20:26:19.438753 24729 net.cpp:205] Memory required for data: 416583800
I0318 20:26:19.438757 24729 layer_factory.hpp:123] Creating layer accuracy
I0318 20:26:19.438762 24729 net.cpp:140] Creating Layer accuracy
I0318 20:26:19.438776 24729 net.cpp:481] accuracy <- fc8_fc8_0_split_0
I0318 20:26:19.438779 24729 net.cpp:481] accuracy <- label_data_1_split_0
I0318 20:26:19.438786 24729 net.cpp:455] accuracy -> accuracy
I0318 20:26:19.438793 24729 net.cpp:190] Setting up accuracy
I0318 20:26:19.438798 24729 net.cpp:197] Top shape: (1)
I0318 20:26:19.438800 24729 net.cpp:205] Memory required for data: 416583804
I0318 20:26:19.438803 24729 layer_factory.hpp:123] Creating layer loss
I0318 20:26:19.438809 24729 net.cpp:140] Creating Layer loss
I0318 20:26:19.438813 24729 net.cpp:481] loss <- fc8_fc8_0_split_1
I0318 20:26:19.438817 24729 net.cpp:481] loss <- label_data_1_split_1
I0318 20:26:19.438822 24729 net.cpp:455] loss -> loss
I0318 20:26:19.438833 24729 layer_factory.hpp:123] Creating layer loss
I0318 20:26:19.438894 24729 net.cpp:190] Setting up loss
I0318 20:26:19.438899 24729 net.cpp:197] Top shape: (1)
I0318 20:26:19.438901 24729 net.cpp:200]     with loss weight 1
I0318 20:26:19.438911 24729 net.cpp:205] Memory required for data: 416583808
I0318 20:26:19.438915 24729 layer_factory.hpp:123] Creating layer accuracy-top1
I0318 20:26:19.438922 24729 net.cpp:140] Creating Layer accuracy-top1
I0318 20:26:19.438925 24729 net.cpp:481] accuracy-top1 <- fc8_fc8_0_split_2
I0318 20:26:19.438928 24729 net.cpp:481] accuracy-top1 <- label_data_1_split_2
I0318 20:26:19.438935 24729 net.cpp:455] accuracy-top1 -> top-1
I0318 20:26:19.438941 24729 net.cpp:190] Setting up accuracy-top1
I0318 20:26:19.438946 24729 net.cpp:197] Top shape: (1)
I0318 20:26:19.438948 24729 net.cpp:205] Memory required for data: 416583812
I0318 20:26:19.438952 24729 net.cpp:268] accuracy-top1 does not need backward computation.
I0318 20:26:19.438956 24729 net.cpp:266] loss needs backward computation.
I0318 20:26:19.438961 24729 net.cpp:268] accuracy does not need backward computation.
I0318 20:26:19.438963 24729 net.cpp:266] fc8_fc8_0_split needs backward computation.
I0318 20:26:19.438968 24729 net.cpp:266] fc8 needs backward computation.
I0318 20:26:19.438971 24729 net.cpp:266] drop7 needs backward computation.
I0318 20:26:19.438974 24729 net.cpp:266] relu7 needs backward computation.
I0318 20:26:19.438977 24729 net.cpp:266] bn7 needs backward computation.
I0318 20:26:19.438982 24729 net.cpp:266] fc7 needs backward computation.
I0318 20:26:19.438985 24729 net.cpp:266] drop6 needs backward computation.
I0318 20:26:19.438989 24729 net.cpp:266] relu6 needs backward computation.
I0318 20:26:19.438992 24729 net.cpp:266] fc6 needs backward computation.
I0318 20:26:19.438997 24729 net.cpp:266] pool5 needs backward computation.
I0318 20:26:19.439000 24729 net.cpp:266] relu5 needs backward computation.
I0318 20:26:19.439003 24729 net.cpp:266] conv5 needs backward computation.
I0318 20:26:19.439007 24729 net.cpp:266] relu4 needs backward computation.
I0318 20:26:19.439011 24729 net.cpp:266] conv4 needs backward computation.
I0318 20:26:19.439014 24729 net.cpp:266] relu3 needs backward computation.
I0318 20:26:19.439018 24729 net.cpp:266] conv3 needs backward computation.
I0318 20:26:19.439021 24729 net.cpp:266] pool2 needs backward computation.
I0318 20:26:19.439025 24729 net.cpp:266] relu2 needs backward computation.
I0318 20:26:19.439029 24729 net.cpp:266] bn2 needs backward computation.
I0318 20:26:19.439033 24729 net.cpp:266] conv2 needs backward computation.
I0318 20:26:19.439035 24729 net.cpp:266] pool1 needs backward computation.
I0318 20:26:19.439040 24729 net.cpp:266] relu1 needs backward computation.
I0318 20:26:19.439043 24729 net.cpp:266] bn1 needs backward computation.
I0318 20:26:19.439046 24729 net.cpp:266] conv1 needs backward computation.
I0318 20:26:19.439050 24729 net.cpp:268] label_data_1_split does not need backward computation.
I0318 20:26:19.439056 24729 net.cpp:268] data does not need backward computation.
I0318 20:26:19.439060 24729 net.cpp:310] This network produces output accuracy
I0318 20:26:19.439064 24729 net.cpp:310] This network produces output loss
I0318 20:26:19.439066 24729 net.cpp:310] This network produces output top-1
I0318 20:26:19.439091 24729 net.cpp:330] Network initialization done.
I0318 20:26:19.439158 24729 solver.cpp:109] Solver scaffolding done.
I0318 20:26:19.439960 24729 caffe_interface.cpp:139] Finetuning from pruning/alexnetBNnoLRN/regular_rate_0.3/sparse.caffemodel
I0318 20:26:20.971406 24729 caffe_interface.cpp:573] Starting Optimization
I0318 20:26:20.971439 24729 solver.cpp:387] Solving
I0318 20:26:20.971442 24729 solver.cpp:388] Learning Rate Policy: step
I0318 20:26:20.972637 24729 solver.cpp:470] Iteration 0, Testing net (#0)
I0318 20:26:22.482911 24729 solver.cpp:569]     Test net output #0: accuracy = 0.95225
I0318 20:26:22.482937 24729 solver.cpp:569]     Test net output #1: loss = 0.259799 (* 1 = 0.259799 loss)
I0318 20:26:22.482940 24729 solver.cpp:569]     Test net output #2: top-1 = 0.95225
I0318 20:26:22.740797 24729 solver.cpp:316] Iteration 0 (0 iter/s, 1.76925s/50 iter), loss = 0.00347762, remaining 333333 hours and 20 minutes
I0318 20:26:22.740825 24729 solver.cpp:337]     Train net output #0: loss = 0.00347762 (* 1 = 0.00347762 loss)
I0318 20:26:22.740840 24729 sgd_solver.cpp:152] Iteration 0, lr = 0.001
I0318 20:26:35.431753 24729 solver.cpp:316] Iteration 50 (3.93998 iter/s, 12.6904s/50 iter), loss = 0.109054, remaining 0 hours and 50 minutes
I0318 20:26:35.431785 24729 solver.cpp:337]     Train net output #0: loss = 0.109054 (* 1 = 0.109054 loss)
I0318 20:26:35.431792 24729 sgd_solver.cpp:152] Iteration 50, lr = 0.001
I0318 20:26:48.186017 24729 solver.cpp:316] Iteration 100 (3.92042 iter/s, 12.7537s/50 iter), loss = 0.0607698, remaining 0 hours and 50 minutes
I0318 20:26:48.186224 24729 solver.cpp:337]     Train net output #0: loss = 0.0607698 (* 1 = 0.0607698 loss)
I0318 20:26:48.186250 24729 sgd_solver.cpp:152] Iteration 100, lr = 0.001
I0318 20:27:00.974581 24729 solver.cpp:316] Iteration 150 (3.90996 iter/s, 12.7879s/50 iter), loss = 0.124484, remaining 0 hours and 50 minutes
I0318 20:27:00.974611 24729 solver.cpp:337]     Train net output #0: loss = 0.124484 (* 1 = 0.124484 loss)
I0318 20:27:00.974615 24729 sgd_solver.cpp:152] Iteration 150, lr = 0.001
I0318 20:27:13.804930 24729 solver.cpp:316] Iteration 200 (3.89717 iter/s, 12.8298s/50 iter), loss = 0.0712141, remaining 0 hours and 50 minutes
I0318 20:27:13.804958 24729 solver.cpp:337]     Train net output #0: loss = 0.0712141 (* 1 = 0.0712141 loss)
I0318 20:27:13.804965 24729 sgd_solver.cpp:152] Iteration 200, lr = 0.001
I0318 20:27:26.699471 24729 solver.cpp:316] Iteration 250 (3.87777 iter/s, 12.894s/50 iter), loss = 0.117427, remaining 0 hours and 50 minutes
I0318 20:27:26.699530 24729 solver.cpp:337]     Train net output #0: loss = 0.117427 (* 1 = 0.117427 loss)
I0318 20:27:26.699537 24729 sgd_solver.cpp:152] Iteration 250, lr = 0.001
I0318 20:27:39.650629 24729 solver.cpp:316] Iteration 300 (3.86083 iter/s, 12.9506s/50 iter), loss = 0.0793085, remaining 0 hours and 50 minutes
I0318 20:27:39.650656 24729 solver.cpp:337]     Train net output #0: loss = 0.0793085 (* 1 = 0.0793085 loss)
I0318 20:27:39.650661 24729 sgd_solver.cpp:152] Iteration 300, lr = 0.001
I0318 20:27:52.610105 24729 solver.cpp:316] Iteration 350 (3.85834 iter/s, 12.9589s/50 iter), loss = 0.0907802, remaining 0 hours and 50 minutes
I0318 20:27:52.610133 24729 solver.cpp:337]     Train net output #0: loss = 0.0907802 (* 1 = 0.0907802 loss)
I0318 20:27:52.610138 24729 sgd_solver.cpp:152] Iteration 350, lr = 0.001
I0318 20:28:05.560847 24729 solver.cpp:316] Iteration 400 (3.86094 iter/s, 12.9502s/50 iter), loss = 0.118363, remaining 0 hours and 49 minutes
I0318 20:28:05.560997 24729 solver.cpp:337]     Train net output #0: loss = 0.118363 (* 1 = 0.118363 loss)
I0318 20:28:05.561007 24729 sgd_solver.cpp:152] Iteration 400, lr = 0.001
I0318 20:28:18.491683 24729 solver.cpp:316] Iteration 450 (3.86692 iter/s, 12.9302s/50 iter), loss = 0.152649, remaining 0 hours and 49 minutes
I0318 20:28:18.491710 24729 solver.cpp:337]     Train net output #0: loss = 0.152649 (* 1 = 0.152649 loss)
I0318 20:28:18.491715 24729 sgd_solver.cpp:152] Iteration 450, lr = 0.001
I0318 20:28:31.196200 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_500.caffemodel
I0318 20:28:33.506165 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_500.solverstate
I0318 20:28:34.179885 24729 solver.cpp:316] Iteration 500 (3.18724 iter/s, 15.6876s/50 iter), loss = 0.114142, remaining 0 hours and 59 minutes
I0318 20:28:34.179913 24729 solver.cpp:337]     Train net output #0: loss = 0.114142 (* 1 = 0.114142 loss)
I0318 20:28:34.179919 24729 sgd_solver.cpp:152] Iteration 500, lr = 0.001
I0318 20:28:47.132006 24729 solver.cpp:316] Iteration 550 (3.86053 iter/s, 12.9516s/50 iter), loss = 0.140654, remaining 0 hours and 49 minutes
I0318 20:28:47.132169 24729 solver.cpp:337]     Train net output #0: loss = 0.140654 (* 1 = 0.140654 loss)
I0318 20:28:47.132177 24729 sgd_solver.cpp:152] Iteration 550, lr = 0.001
I0318 20:29:00.063757 24729 solver.cpp:316] Iteration 600 (3.86665 iter/s, 12.9311s/50 iter), loss = 0.0643508, remaining 0 hours and 49 minutes
I0318 20:29:00.063786 24729 solver.cpp:337]     Train net output #0: loss = 0.0643508 (* 1 = 0.0643508 loss)
I0318 20:29:00.063791 24729 sgd_solver.cpp:152] Iteration 600, lr = 0.001
I0318 20:29:13.002890 24729 solver.cpp:316] Iteration 650 (3.86441 iter/s, 12.9386s/50 iter), loss = 0.104378, remaining 0 hours and 48 minutes
I0318 20:29:13.002920 24729 solver.cpp:337]     Train net output #0: loss = 0.104378 (* 1 = 0.104378 loss)
I0318 20:29:13.002926 24729 sgd_solver.cpp:152] Iteration 650, lr = 0.001
I0318 20:29:25.948355 24729 solver.cpp:316] Iteration 700 (3.86252 iter/s, 12.9449s/50 iter), loss = 0.0789952, remaining 0 hours and 48 minutes
I0318 20:29:25.948503 24729 solver.cpp:337]     Train net output #0: loss = 0.0789952 (* 1 = 0.0789952 loss)
I0318 20:29:25.948511 24729 sgd_solver.cpp:152] Iteration 700, lr = 0.001
I0318 20:29:38.875713 24729 solver.cpp:316] Iteration 750 (3.86796 iter/s, 12.9267s/50 iter), loss = 0.076, remaining 0 hours and 48 minutes
I0318 20:29:38.875742 24729 solver.cpp:337]     Train net output #0: loss = 0.076 (* 1 = 0.076 loss)
I0318 20:29:38.875747 24729 sgd_solver.cpp:152] Iteration 750, lr = 0.001
I0318 20:29:51.811488 24729 solver.cpp:316] Iteration 800 (3.86541 iter/s, 12.9352s/50 iter), loss = 0.0853006, remaining 0 hours and 48 minutes
I0318 20:29:51.811517 24729 solver.cpp:337]     Train net output #0: loss = 0.0853006 (* 1 = 0.0853006 loss)
I0318 20:29:51.811523 24729 sgd_solver.cpp:152] Iteration 800, lr = 0.001
I0318 20:30:04.762851 24729 solver.cpp:316] Iteration 850 (3.86076 iter/s, 12.9508s/50 iter), loss = 0.0994237, remaining 0 hours and 47 minutes
I0318 20:30:04.762985 24729 solver.cpp:337]     Train net output #0: loss = 0.0994237 (* 1 = 0.0994237 loss)
I0318 20:30:04.762993 24729 sgd_solver.cpp:152] Iteration 850, lr = 0.001
I0318 20:30:17.719871 24729 solver.cpp:316] Iteration 900 (3.8591 iter/s, 12.9564s/50 iter), loss = 0.108377, remaining 0 hours and 47 minutes
I0318 20:30:17.719899 24729 solver.cpp:337]     Train net output #0: loss = 0.108377 (* 1 = 0.108377 loss)
I0318 20:30:17.719907 24729 sgd_solver.cpp:152] Iteration 900, lr = 0.001
I0318 20:30:30.662596 24729 solver.cpp:316] Iteration 950 (3.86333 iter/s, 12.9422s/50 iter), loss = 0.124686, remaining 0 hours and 47 minutes
I0318 20:30:30.662624 24729 solver.cpp:337]     Train net output #0: loss = 0.124686 (* 1 = 0.124686 loss)
I0318 20:30:30.662631 24729 sgd_solver.cpp:152] Iteration 950, lr = 0.001
I0318 20:30:43.358296 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_1000.caffemodel
I0318 20:30:45.595000 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_1000.solverstate
I0318 20:30:46.014842 24729 solver.cpp:470] Iteration 1000, Testing net (#0)
I0318 20:30:47.483260 24729 solver.cpp:569]     Test net output #0: accuracy = 0.89225
I0318 20:30:47.483289 24729 solver.cpp:569]     Test net output #1: loss = 0.381634 (* 1 = 0.381634 loss)
I0318 20:30:47.483292 24729 solver.cpp:569]     Test net output #2: top-1 = 0.89225
I0318 20:30:47.728945 24729 solver.cpp:316] Iteration 1000 (2.92986 iter/s, 17.0657s/50 iter), loss = 0.0916183, remaining 1 hours and 2 minutes
I0318 20:30:47.728967 24729 solver.cpp:337]     Train net output #0: loss = 0.0916183 (* 1 = 0.0916183 loss)
I0318 20:30:47.728973 24729 sgd_solver.cpp:152] Iteration 1000, lr = 0.001
I0318 20:31:00.641122 24729 solver.cpp:316] Iteration 1050 (3.87247 iter/s, 12.9116s/50 iter), loss = 0.114468, remaining 0 hours and 46 minutes
I0318 20:31:00.641149 24729 solver.cpp:337]     Train net output #0: loss = 0.114468 (* 1 = 0.114468 loss)
I0318 20:31:00.641155 24729 sgd_solver.cpp:152] Iteration 1050, lr = 0.001
I0318 20:31:13.572422 24729 solver.cpp:316] Iteration 1100 (3.86675 iter/s, 12.9308s/50 iter), loss = 0.0761634, remaining 0 hours and 46 minutes
I0318 20:31:13.572593 24729 solver.cpp:337]     Train net output #0: loss = 0.0761634 (* 1 = 0.0761634 loss)
I0318 20:31:13.572602 24729 sgd_solver.cpp:152] Iteration 1100, lr = 0.001
I0318 20:31:26.524588 24729 solver.cpp:316] Iteration 1150 (3.86056 iter/s, 12.9515s/50 iter), loss = 0.100863, remaining 0 hours and 46 minutes
I0318 20:31:26.524617 24729 solver.cpp:337]     Train net output #0: loss = 0.100863 (* 1 = 0.100863 loss)
I0318 20:31:26.524623 24729 sgd_solver.cpp:152] Iteration 1150, lr = 0.001
I0318 20:31:39.463903 24729 solver.cpp:316] Iteration 1200 (3.86435 iter/s, 12.9388s/50 iter), loss = 0.0811803, remaining 0 hours and 46 minutes
I0318 20:31:39.463930 24729 solver.cpp:337]     Train net output #0: loss = 0.0811803 (* 1 = 0.0811803 loss)
I0318 20:31:39.463937 24729 sgd_solver.cpp:152] Iteration 1200, lr = 0.001
I0318 20:31:52.385857 24729 solver.cpp:316] Iteration 1250 (3.86954 iter/s, 12.9214s/50 iter), loss = 0.126354, remaining 0 hours and 46 minutes
I0318 20:31:52.386001 24729 solver.cpp:337]     Train net output #0: loss = 0.126354 (* 1 = 0.126354 loss)
I0318 20:31:52.386008 24729 sgd_solver.cpp:152] Iteration 1250, lr = 0.001
I0318 20:32:05.334662 24729 solver.cpp:316] Iteration 1300 (3.86155 iter/s, 12.9482s/50 iter), loss = 0.0888494, remaining 0 hours and 46 minutes
I0318 20:32:05.334692 24729 solver.cpp:337]     Train net output #0: loss = 0.0888494 (* 1 = 0.0888494 loss)
I0318 20:32:05.334698 24729 sgd_solver.cpp:152] Iteration 1300, lr = 0.001
I0318 20:32:18.273617 24729 solver.cpp:316] Iteration 1350 (3.86446 iter/s, 12.9384s/50 iter), loss = 0.101716, remaining 0 hours and 45 minutes
I0318 20:32:18.273645 24729 solver.cpp:337]     Train net output #0: loss = 0.101716 (* 1 = 0.101716 loss)
I0318 20:32:18.273650 24729 sgd_solver.cpp:152] Iteration 1350, lr = 0.001
I0318 20:32:31.203326 24729 solver.cpp:316] Iteration 1400 (3.86722 iter/s, 12.9292s/50 iter), loss = 0.136756, remaining 0 hours and 45 minutes
I0318 20:32:31.203467 24729 solver.cpp:337]     Train net output #0: loss = 0.136756 (* 1 = 0.136756 loss)
I0318 20:32:31.203475 24729 sgd_solver.cpp:152] Iteration 1400, lr = 0.001
I0318 20:32:44.170347 24729 solver.cpp:316] Iteration 1450 (3.85613 iter/s, 12.9664s/50 iter), loss = 0.100819, remaining 0 hours and 45 minutes
I0318 20:32:44.170377 24729 solver.cpp:337]     Train net output #0: loss = 0.100819 (* 1 = 0.100819 loss)
I0318 20:32:44.170382 24729 sgd_solver.cpp:152] Iteration 1450, lr = 0.001
I0318 20:32:56.839303 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_1500.caffemodel
I0318 20:32:59.106735 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_1500.solverstate
I0318 20:32:59.783188 24729 solver.cpp:316] Iteration 1500 (3.20262 iter/s, 15.6122s/50 iter), loss = 0.0850603, remaining 0 hours and 54 minutes
I0318 20:32:59.783218 24729 solver.cpp:337]     Train net output #0: loss = 0.0850603 (* 1 = 0.0850603 loss)
I0318 20:32:59.783226 24729 sgd_solver.cpp:152] Iteration 1500, lr = 0.001
I0318 20:33:12.684357 24729 solver.cpp:316] Iteration 1550 (3.87578 iter/s, 12.9006s/50 iter), loss = 0.0586013, remaining 0 hours and 44 minutes
I0318 20:33:12.684536 24729 solver.cpp:337]     Train net output #0: loss = 0.0586013 (* 1 = 0.0586013 loss)
I0318 20:33:12.684546 24729 sgd_solver.cpp:152] Iteration 1550, lr = 0.001
I0318 20:33:25.627306 24729 solver.cpp:316] Iteration 1600 (3.86331 iter/s, 12.9423s/50 iter), loss = 0.0607121, remaining 0 hours and 44 minutes
I0318 20:33:25.627336 24729 solver.cpp:337]     Train net output #0: loss = 0.0607121 (* 1 = 0.0607121 loss)
I0318 20:33:25.627343 24729 sgd_solver.cpp:152] Iteration 1600, lr = 0.001
I0318 20:33:38.582988 24729 solver.cpp:316] Iteration 1650 (3.85947 iter/s, 12.9551s/50 iter), loss = 0.0848184, remaining 0 hours and 44 minutes
I0318 20:33:38.583016 24729 solver.cpp:337]     Train net output #0: loss = 0.0848184 (* 1 = 0.0848184 loss)
I0318 20:33:38.583021 24729 sgd_solver.cpp:152] Iteration 1650, lr = 0.001
I0318 20:33:51.532114 24729 solver.cpp:316] Iteration 1700 (3.86142 iter/s, 12.9486s/50 iter), loss = 0.0829301, remaining 0 hours and 44 minutes
I0318 20:33:51.532253 24729 solver.cpp:337]     Train net output #0: loss = 0.0829301 (* 1 = 0.0829301 loss)
I0318 20:33:51.532260 24729 sgd_solver.cpp:152] Iteration 1700, lr = 0.001
I0318 20:34:04.474339 24729 solver.cpp:316] Iteration 1750 (3.86352 iter/s, 12.9416s/50 iter), loss = 0.0677905, remaining 0 hours and 44 minutes
I0318 20:34:04.474367 24729 solver.cpp:337]     Train net output #0: loss = 0.0677905 (* 1 = 0.0677905 loss)
I0318 20:34:04.474373 24729 sgd_solver.cpp:152] Iteration 1750, lr = 0.001
I0318 20:34:17.405553 24729 solver.cpp:316] Iteration 1800 (3.86677 iter/s, 12.9307s/50 iter), loss = 0.120396, remaining 0 hours and 43 minutes
I0318 20:34:17.405581 24729 solver.cpp:337]     Train net output #0: loss = 0.120396 (* 1 = 0.120396 loss)
I0318 20:34:17.405586 24729 sgd_solver.cpp:152] Iteration 1800, lr = 0.001
I0318 20:34:30.366940 24729 solver.cpp:316] Iteration 1850 (3.85777 iter/s, 12.9609s/50 iter), loss = 0.0699048, remaining 0 hours and 43 minutes
I0318 20:34:30.367650 24729 solver.cpp:337]     Train net output #0: loss = 0.0699048 (* 1 = 0.0699048 loss)
I0318 20:34:30.367656 24729 sgd_solver.cpp:152] Iteration 1850, lr = 0.001
I0318 20:34:43.301610 24729 solver.cpp:316] Iteration 1900 (3.86594 iter/s, 12.9335s/50 iter), loss = 0.0755282, remaining 0 hours and 43 minutes
I0318 20:34:43.301636 24729 solver.cpp:337]     Train net output #0: loss = 0.0755282 (* 1 = 0.0755282 loss)
I0318 20:34:43.301641 24729 sgd_solver.cpp:152] Iteration 1900, lr = 0.001
I0318 20:34:56.250038 24729 solver.cpp:316] Iteration 1950 (3.86163 iter/s, 12.9479s/50 iter), loss = 0.0748237, remaining 0 hours and 43 minutes
I0318 20:34:56.250064 24729 solver.cpp:337]     Train net output #0: loss = 0.0748237 (* 1 = 0.0748237 loss)
I0318 20:34:56.250070 24729 sgd_solver.cpp:152] Iteration 1950, lr = 0.001
I0318 20:35:08.948696 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_2000.caffemodel
I0318 20:35:11.232298 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_2000.solverstate
I0318 20:35:11.672021 24729 solver.cpp:470] Iteration 2000, Testing net (#0)
I0318 20:35:13.157651 24729 solver.cpp:569]     Test net output #0: accuracy = 0.89875
I0318 20:35:13.157678 24729 solver.cpp:569]     Test net output #1: loss = 0.320659 (* 1 = 0.320659 loss)
I0318 20:35:13.157681 24729 solver.cpp:569]     Test net output #2: top-1 = 0.89875
I0318 20:35:13.404565 24729 solver.cpp:316] Iteration 2000 (2.9148 iter/s, 17.1538s/50 iter), loss = 0.109091, remaining 0 hours and 56 minutes
I0318 20:35:13.404590 24729 solver.cpp:337]     Train net output #0: loss = 0.109091 (* 1 = 0.109091 loss)
I0318 20:35:13.404597 24729 sgd_solver.cpp:152] Iteration 2000, lr = 0.001
I0318 20:35:26.322201 24729 solver.cpp:316] Iteration 2050 (3.87084 iter/s, 12.9171s/50 iter), loss = 0.0967005, remaining 0 hours and 42 minutes
I0318 20:35:26.322228 24729 solver.cpp:337]     Train net output #0: loss = 0.0967006 (* 1 = 0.0967006 loss)
I0318 20:35:26.322234 24729 sgd_solver.cpp:152] Iteration 2050, lr = 0.001
I0318 20:35:39.245618 24729 solver.cpp:316] Iteration 2100 (3.86911 iter/s, 12.9229s/50 iter), loss = 0.119935, remaining 0 hours and 42 minutes
I0318 20:35:39.245786 24729 solver.cpp:337]     Train net output #0: loss = 0.119935 (* 1 = 0.119935 loss)
I0318 20:35:39.245795 24729 sgd_solver.cpp:152] Iteration 2100, lr = 0.001
I0318 20:35:52.173811 24729 solver.cpp:316] Iteration 2150 (3.86772 iter/s, 12.9275s/50 iter), loss = 0.11051, remaining 0 hours and 42 minutes
I0318 20:35:52.173840 24729 solver.cpp:337]     Train net output #0: loss = 0.11051 (* 1 = 0.11051 loss)
I0318 20:35:52.173846 24729 sgd_solver.cpp:152] Iteration 2150, lr = 0.001
I0318 20:36:05.095932 24729 solver.cpp:316] Iteration 2200 (3.86949 iter/s, 12.9216s/50 iter), loss = 0.113732, remaining 0 hours and 42 minutes
I0318 20:36:05.095958 24729 solver.cpp:337]     Train net output #0: loss = 0.113732 (* 1 = 0.113732 loss)
I0318 20:36:05.095965 24729 sgd_solver.cpp:152] Iteration 2200, lr = 0.001
I0318 20:36:18.032711 24729 solver.cpp:316] Iteration 2250 (3.86511 iter/s, 12.9362s/50 iter), loss = 0.0751381, remaining 0 hours and 41 minutes
I0318 20:36:18.032871 24729 solver.cpp:337]     Train net output #0: loss = 0.0751381 (* 1 = 0.0751381 loss)
I0318 20:36:18.032881 24729 sgd_solver.cpp:152] Iteration 2250, lr = 0.001
I0318 20:36:30.980818 24729 solver.cpp:316] Iteration 2300 (3.86177 iter/s, 12.9474s/50 iter), loss = 0.143062, remaining 0 hours and 41 minutes
I0318 20:36:30.980845 24729 solver.cpp:337]     Train net output #0: loss = 0.143062 (* 1 = 0.143062 loss)
I0318 20:36:30.980851 24729 sgd_solver.cpp:152] Iteration 2300, lr = 0.001
I0318 20:36:43.929545 24729 solver.cpp:316] Iteration 2350 (3.86154 iter/s, 12.9482s/50 iter), loss = 0.105685, remaining 0 hours and 41 minutes
I0318 20:36:43.929574 24729 solver.cpp:337]     Train net output #0: loss = 0.105685 (* 1 = 0.105685 loss)
I0318 20:36:43.929579 24729 sgd_solver.cpp:152] Iteration 2350, lr = 0.001
I0318 20:36:56.849895 24729 solver.cpp:316] Iteration 2400 (3.87002 iter/s, 12.9198s/50 iter), loss = 0.130199, remaining 0 hours and 41 minutes
I0318 20:36:56.850030 24729 solver.cpp:337]     Train net output #0: loss = 0.130199 (* 1 = 0.130199 loss)
I0318 20:36:56.850039 24729 sgd_solver.cpp:152] Iteration 2400, lr = 0.001
I0318 20:37:09.798112 24729 solver.cpp:316] Iteration 2450 (3.86173 iter/s, 12.9476s/50 iter), loss = 0.130202, remaining 0 hours and 41 minutes
I0318 20:37:09.798138 24729 solver.cpp:337]     Train net output #0: loss = 0.130202 (* 1 = 0.130202 loss)
I0318 20:37:09.798143 24729 sgd_solver.cpp:152] Iteration 2450, lr = 0.001
I0318 20:37:22.484315 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_2500.caffemodel
I0318 20:37:24.742179 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_2500.solverstate
I0318 20:37:25.411053 24729 solver.cpp:316] Iteration 2500 (3.2026 iter/s, 15.6123s/50 iter), loss = 0.107598, remaining 0 hours and 49 minutes
I0318 20:37:25.411082 24729 solver.cpp:337]     Train net output #0: loss = 0.107598 (* 1 = 0.107598 loss)
I0318 20:37:25.411089 24729 sgd_solver.cpp:152] Iteration 2500, lr = 0.0001
I0318 20:37:38.300577 24729 solver.cpp:316] Iteration 2550 (3.87928 iter/s, 12.889s/50 iter), loss = 0.0736564, remaining 0 hours and 40 minutes
I0318 20:37:38.300711 24729 solver.cpp:337]     Train net output #0: loss = 0.0736564 (* 1 = 0.0736564 loss)
I0318 20:37:38.300735 24729 sgd_solver.cpp:152] Iteration 2550, lr = 0.0001
I0318 20:37:51.235827 24729 solver.cpp:316] Iteration 2600 (3.8656 iter/s, 12.9346s/50 iter), loss = 0.0606087, remaining 0 hours and 40 minutes
I0318 20:37:51.235854 24729 solver.cpp:337]     Train net output #0: loss = 0.0606087 (* 1 = 0.0606087 loss)
I0318 20:37:51.235859 24729 sgd_solver.cpp:152] Iteration 2600, lr = 0.0001
I0318 20:38:04.178930 24729 solver.cpp:316] Iteration 2650 (3.86322 iter/s, 12.9426s/50 iter), loss = 0.0611914, remaining 0 hours and 40 minutes
I0318 20:38:04.178957 24729 solver.cpp:337]     Train net output #0: loss = 0.0611914 (* 1 = 0.0611914 loss)
I0318 20:38:04.178963 24729 sgd_solver.cpp:152] Iteration 2650, lr = 0.0001
I0318 20:38:17.102632 24729 solver.cpp:316] Iteration 2700 (3.86902 iter/s, 12.9232s/50 iter), loss = 0.0325751, remaining 0 hours and 40 minutes
I0318 20:38:17.102794 24729 solver.cpp:337]     Train net output #0: loss = 0.0325751 (* 1 = 0.0325751 loss)
I0318 20:38:17.102803 24729 sgd_solver.cpp:152] Iteration 2700, lr = 0.0001
I0318 20:38:30.055907 24729 solver.cpp:316] Iteration 2750 (3.86023 iter/s, 12.9526s/50 iter), loss = 0.0496463, remaining 0 hours and 39 minutes
I0318 20:38:30.055936 24729 solver.cpp:337]     Train net output #0: loss = 0.0496463 (* 1 = 0.0496463 loss)
I0318 20:38:30.055943 24729 sgd_solver.cpp:152] Iteration 2750, lr = 0.0001
I0318 20:38:42.988452 24729 solver.cpp:316] Iteration 2800 (3.86637 iter/s, 12.932s/50 iter), loss = 0.0533494, remaining 0 hours and 39 minutes
I0318 20:38:42.988481 24729 solver.cpp:337]     Train net output #0: loss = 0.0533495 (* 1 = 0.0533495 loss)
I0318 20:38:42.988487 24729 sgd_solver.cpp:152] Iteration 2800, lr = 0.0001
I0318 20:38:55.926062 24729 solver.cpp:316] Iteration 2850 (3.86486 iter/s, 12.9371s/50 iter), loss = 0.0364817, remaining 0 hours and 39 minutes
I0318 20:38:55.926201 24729 solver.cpp:337]     Train net output #0: loss = 0.0364818 (* 1 = 0.0364818 loss)
I0318 20:38:55.926209 24729 sgd_solver.cpp:152] Iteration 2850, lr = 0.0001
I0318 20:39:08.861403 24729 solver.cpp:316] Iteration 2900 (3.86557 iter/s, 12.9347s/50 iter), loss = 0.051822, remaining 0 hours and 39 minutes
I0318 20:39:08.861433 24729 solver.cpp:337]     Train net output #0: loss = 0.051822 (* 1 = 0.051822 loss)
I0318 20:39:08.861440 24729 sgd_solver.cpp:152] Iteration 2900, lr = 0.0001
I0318 20:39:21.798902 24729 solver.cpp:316] Iteration 2950 (3.86489 iter/s, 12.937s/50 iter), loss = 0.0393696, remaining 0 hours and 38 minutes
I0318 20:39:21.798930 24729 solver.cpp:337]     Train net output #0: loss = 0.0393696 (* 1 = 0.0393696 loss)
I0318 20:39:21.798938 24729 sgd_solver.cpp:152] Iteration 2950, lr = 0.0001
I0318 20:39:34.493665 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_3000.caffemodel
I0318 20:39:36.789863 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_3000.solverstate
I0318 20:39:37.224668 24729 solver.cpp:470] Iteration 3000, Testing net (#0)
I0318 20:39:38.764560 24729 solver.cpp:569]     Test net output #0: accuracy = 0.946
I0318 20:39:38.764586 24729 solver.cpp:569]     Test net output #1: loss = 0.137794 (* 1 = 0.137794 loss)
I0318 20:39:38.764590 24729 solver.cpp:569]     Test net output #2: top-1 = 0.946
I0318 20:39:39.013849 24729 solver.cpp:316] Iteration 3000 (2.90457 iter/s, 17.2142s/50 iter), loss = 0.0372746, remaining 0 hours and 51 minutes
I0318 20:39:39.013875 24729 solver.cpp:337]     Train net output #0: loss = 0.0372746 (* 1 = 0.0372746 loss)
I0318 20:39:39.013882 24729 sgd_solver.cpp:152] Iteration 3000, lr = 0.0001
I0318 20:39:51.892444 24729 solver.cpp:316] Iteration 3050 (3.88257 iter/s, 12.8781s/50 iter), loss = 0.0201491, remaining 0 hours and 38 minutes
I0318 20:39:51.892474 24729 solver.cpp:337]     Train net output #0: loss = 0.0201492 (* 1 = 0.0201492 loss)
I0318 20:39:51.892482 24729 sgd_solver.cpp:152] Iteration 3050, lr = 0.0001
I0318 20:40:04.834522 24729 solver.cpp:316] Iteration 3100 (3.86353 iter/s, 12.9415s/50 iter), loss = 0.00836108, remaining 0 hours and 38 minutes
I0318 20:40:04.837638 24729 solver.cpp:337]     Train net output #0: loss = 0.00836111 (* 1 = 0.00836111 loss)
I0318 20:40:04.837646 24729 sgd_solver.cpp:152] Iteration 3100, lr = 0.0001
I0318 20:40:17.761515 24729 solver.cpp:316] Iteration 3150 (3.86896 iter/s, 12.9234s/50 iter), loss = 0.060684, remaining 0 hours and 37 minutes
I0318 20:40:17.761545 24729 solver.cpp:337]     Train net output #0: loss = 0.060684 (* 1 = 0.060684 loss)
I0318 20:40:17.761550 24729 sgd_solver.cpp:152] Iteration 3150, lr = 0.0001
I0318 20:40:30.719094 24729 solver.cpp:316] Iteration 3200 (3.85891 iter/s, 12.957s/50 iter), loss = 0.0372883, remaining 0 hours and 37 minutes
I0318 20:40:30.719121 24729 solver.cpp:337]     Train net output #0: loss = 0.0372883 (* 1 = 0.0372883 loss)
I0318 20:40:30.719127 24729 sgd_solver.cpp:152] Iteration 3200, lr = 0.0001
I0318 20:40:43.653594 24729 solver.cpp:316] Iteration 3250 (3.86579 iter/s, 12.934s/50 iter), loss = 0.0383948, remaining 0 hours and 37 minutes
I0318 20:40:43.653764 24729 solver.cpp:337]     Train net output #0: loss = 0.0383949 (* 1 = 0.0383949 loss)
I0318 20:40:43.653772 24729 sgd_solver.cpp:152] Iteration 3250, lr = 0.0001
I0318 20:40:56.603767 24729 solver.cpp:316] Iteration 3300 (3.86115 iter/s, 12.9495s/50 iter), loss = 0.0358267, remaining 0 hours and 37 minutes
I0318 20:40:56.603796 24729 solver.cpp:337]     Train net output #0: loss = 0.0358268 (* 1 = 0.0358268 loss)
I0318 20:40:56.603801 24729 sgd_solver.cpp:152] Iteration 3300, lr = 0.0001
I0318 20:41:09.553289 24729 solver.cpp:316] Iteration 3350 (3.86131 iter/s, 12.949s/50 iter), loss = 0.019969, remaining 0 hours and 37 minutes
I0318 20:41:09.553318 24729 solver.cpp:337]     Train net output #0: loss = 0.019969 (* 1 = 0.019969 loss)
I0318 20:41:09.553324 24729 sgd_solver.cpp:152] Iteration 3350, lr = 0.0001
I0318 20:41:22.504261 24729 solver.cpp:316] Iteration 3400 (3.86087 iter/s, 12.9504s/50 iter), loss = 0.0431596, remaining 0 hours and 37 minutes
I0318 20:41:22.504405 24729 solver.cpp:337]     Train net output #0: loss = 0.0431596 (* 1 = 0.0431596 loss)
I0318 20:41:22.504415 24729 sgd_solver.cpp:152] Iteration 3400, lr = 0.0001
I0318 20:41:35.449205 24729 solver.cpp:316] Iteration 3450 (3.86271 iter/s, 12.9443s/50 iter), loss = 0.0317109, remaining 0 hours and 36 minutes
I0318 20:41:35.449232 24729 solver.cpp:337]     Train net output #0: loss = 0.0317109 (* 1 = 0.0317109 loss)
I0318 20:41:35.449237 24729 sgd_solver.cpp:152] Iteration 3450, lr = 0.0001
I0318 20:41:48.123678 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_3500.caffemodel
I0318 20:41:50.385442 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_3500.solverstate
I0318 20:41:51.064587 24729 solver.cpp:316] Iteration 3500 (3.2021 iter/s, 15.6147s/50 iter), loss = 0.0415255, remaining 0 hours and 44 minutes
I0318 20:41:51.064615 24729 solver.cpp:337]     Train net output #0: loss = 0.0415255 (* 1 = 0.0415255 loss)
I0318 20:41:51.064621 24729 sgd_solver.cpp:152] Iteration 3500, lr = 0.0001
I0318 20:42:03.955855 24729 solver.cpp:316] Iteration 3550 (3.87875 iter/s, 12.8907s/50 iter), loss = 0.0511408, remaining 0 hours and 36 minutes
I0318 20:42:03.955992 24729 solver.cpp:337]     Train net output #0: loss = 0.0511408 (* 1 = 0.0511408 loss)
I0318 20:42:03.956001 24729 sgd_solver.cpp:152] Iteration 3550, lr = 0.0001
I0318 20:42:16.901306 24729 solver.cpp:316] Iteration 3600 (3.86255 iter/s, 12.9448s/50 iter), loss = 0.0365974, remaining 0 hours and 36 minutes
I0318 20:42:16.901332 24729 solver.cpp:337]     Train net output #0: loss = 0.0365974 (* 1 = 0.0365974 loss)
I0318 20:42:16.901337 24729 sgd_solver.cpp:152] Iteration 3600, lr = 0.0001
I0318 20:42:29.865890 24729 solver.cpp:316] Iteration 3650 (3.85682 iter/s, 12.964s/50 iter), loss = 0.0411567, remaining 0 hours and 36 minutes
I0318 20:42:29.865917 24729 solver.cpp:337]     Train net output #0: loss = 0.0411568 (* 1 = 0.0411568 loss)
I0318 20:42:29.865923 24729 sgd_solver.cpp:152] Iteration 3650, lr = 0.0001
I0318 20:42:42.792376 24729 solver.cpp:316] Iteration 3700 (3.86819 iter/s, 12.926s/50 iter), loss = 0.0245158, remaining 0 hours and 35 minutes
I0318 20:42:42.792536 24729 solver.cpp:337]     Train net output #0: loss = 0.0245159 (* 1 = 0.0245159 loss)
I0318 20:42:42.792546 24729 sgd_solver.cpp:152] Iteration 3700, lr = 0.0001
I0318 20:42:55.771428 24729 solver.cpp:316] Iteration 3750 (3.85256 iter/s, 12.9784s/50 iter), loss = 0.0127896, remaining 0 hours and 35 minutes
I0318 20:42:55.771456 24729 solver.cpp:337]     Train net output #0: loss = 0.0127897 (* 1 = 0.0127897 loss)
I0318 20:42:55.771461 24729 sgd_solver.cpp:152] Iteration 3750, lr = 0.0001
I0318 20:43:08.723317 24729 solver.cpp:316] Iteration 3800 (3.8606 iter/s, 12.9514s/50 iter), loss = 0.0409762, remaining 0 hours and 35 minutes
I0318 20:43:08.723345 24729 solver.cpp:337]     Train net output #0: loss = 0.0409762 (* 1 = 0.0409762 loss)
I0318 20:43:08.723351 24729 sgd_solver.cpp:152] Iteration 3800, lr = 0.0001
I0318 20:43:21.680263 24729 solver.cpp:316] Iteration 3850 (3.85909 iter/s, 12.9564s/50 iter), loss = 0.0227123, remaining 0 hours and 34 minutes
I0318 20:43:21.680393 24729 solver.cpp:337]     Train net output #0: loss = 0.0227123 (* 1 = 0.0227123 loss)
I0318 20:43:21.680402 24729 sgd_solver.cpp:152] Iteration 3850, lr = 0.0001
I0318 20:43:34.614375 24729 solver.cpp:316] Iteration 3900 (3.86594 iter/s, 12.9335s/50 iter), loss = 0.0380933, remaining 0 hours and 34 minutes
I0318 20:43:34.614404 24729 solver.cpp:337]     Train net output #0: loss = 0.0380934 (* 1 = 0.0380934 loss)
I0318 20:43:34.614411 24729 sgd_solver.cpp:152] Iteration 3900, lr = 0.0001
I0318 20:43:47.576241 24729 solver.cpp:316] Iteration 3950 (3.85763 iter/s, 12.9613s/50 iter), loss = 0.0310878, remaining 0 hours and 34 minutes
I0318 20:43:47.576270 24729 solver.cpp:337]     Train net output #0: loss = 0.0310879 (* 1 = 0.0310879 loss)
I0318 20:43:47.576275 24729 sgd_solver.cpp:152] Iteration 3950, lr = 0.0001
I0318 20:44:00.256927 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_4000.caffemodel
I0318 20:44:02.516451 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_4000.solverstate
I0318 20:44:02.941529 24729 solver.cpp:470] Iteration 4000, Testing net (#0)
I0318 20:44:04.402729 24729 solver.cpp:569]     Test net output #0: accuracy = 0.94225
I0318 20:44:04.402756 24729 solver.cpp:569]     Test net output #1: loss = 0.145044 (* 1 = 0.145044 loss)
I0318 20:44:04.402760 24729 solver.cpp:569]     Test net output #2: top-1 = 0.94225
I0318 20:44:04.646204 24729 solver.cpp:316] Iteration 4000 (2.92924 iter/s, 17.0693s/50 iter), loss = 0.0205258, remaining 0 hours and 45 minutes
I0318 20:44:04.646227 24729 solver.cpp:337]     Train net output #0: loss = 0.0205259 (* 1 = 0.0205259 loss)
I0318 20:44:04.646234 24729 sgd_solver.cpp:152] Iteration 4000, lr = 0.0001
I0318 20:44:17.559103 24729 solver.cpp:316] Iteration 4050 (3.87226 iter/s, 12.9124s/50 iter), loss = 0.0356508, remaining 0 hours and 34 minutes
I0318 20:44:17.559129 24729 solver.cpp:337]     Train net output #0: loss = 0.0356509 (* 1 = 0.0356509 loss)
I0318 20:44:17.559135 24729 sgd_solver.cpp:152] Iteration 4050, lr = 0.0001
I0318 20:44:30.498528 24729 solver.cpp:316] Iteration 4100 (3.86432 iter/s, 12.9389s/50 iter), loss = 0.0206309, remaining 0 hours and 33 minutes
I0318 20:44:30.498656 24729 solver.cpp:337]     Train net output #0: loss = 0.020631 (* 1 = 0.020631 loss)
I0318 20:44:30.498663 24729 sgd_solver.cpp:152] Iteration 4100, lr = 0.0001
I0318 20:44:43.438452 24729 solver.cpp:316] Iteration 4150 (3.8642 iter/s, 12.9393s/50 iter), loss = 0.0271681, remaining 0 hours and 33 minutes
I0318 20:44:43.438480 24729 solver.cpp:337]     Train net output #0: loss = 0.0271682 (* 1 = 0.0271682 loss)
I0318 20:44:43.438486 24729 sgd_solver.cpp:152] Iteration 4150, lr = 0.0001
I0318 20:44:56.392215 24729 solver.cpp:316] Iteration 4200 (3.86004 iter/s, 12.9532s/50 iter), loss = 0.0207513, remaining 0 hours and 33 minutes
I0318 20:44:56.392243 24729 solver.cpp:337]     Train net output #0: loss = 0.0207513 (* 1 = 0.0207513 loss)
I0318 20:44:56.392249 24729 sgd_solver.cpp:152] Iteration 4200, lr = 0.0001
I0318 20:45:09.362535 24729 solver.cpp:316] Iteration 4250 (3.85511 iter/s, 12.9698s/50 iter), loss = 0.0300277, remaining 0 hours and 33 minutes
I0318 20:45:09.362702 24729 solver.cpp:337]     Train net output #0: loss = 0.0300278 (* 1 = 0.0300278 loss)
I0318 20:45:09.362710 24729 sgd_solver.cpp:152] Iteration 4250, lr = 0.0001
I0318 20:45:22.307750 24729 solver.cpp:316] Iteration 4300 (3.86263 iter/s, 12.9445s/50 iter), loss = 0.0127937, remaining 0 hours and 33 minutes
I0318 20:45:22.307780 24729 solver.cpp:337]     Train net output #0: loss = 0.0127937 (* 1 = 0.0127937 loss)
I0318 20:45:22.307785 24729 sgd_solver.cpp:152] Iteration 4300, lr = 0.0001
I0318 20:45:35.230852 24729 solver.cpp:316] Iteration 4350 (3.8692 iter/s, 12.9226s/50 iter), loss = 0.00962169, remaining 0 hours and 32 minutes
I0318 20:45:35.230880 24729 solver.cpp:337]     Train net output #0: loss = 0.00962176 (* 1 = 0.00962176 loss)
I0318 20:45:35.230886 24729 sgd_solver.cpp:152] Iteration 4350, lr = 0.0001
I0318 20:45:48.192098 24729 solver.cpp:316] Iteration 4400 (3.85781 iter/s, 12.9607s/50 iter), loss = 0.0232312, remaining 0 hours and 32 minutes
I0318 20:45:48.192239 24729 solver.cpp:337]     Train net output #0: loss = 0.0232313 (* 1 = 0.0232313 loss)
I0318 20:45:48.192247 24729 sgd_solver.cpp:152] Iteration 4400, lr = 0.0001
I0318 20:46:01.135054 24729 solver.cpp:316] Iteration 4450 (3.8633 iter/s, 12.9423s/50 iter), loss = 0.012772, remaining 0 hours and 32 minutes
I0318 20:46:01.135082 24729 solver.cpp:337]     Train net output #0: loss = 0.012772 (* 1 = 0.012772 loss)
I0318 20:46:01.135087 24729 sgd_solver.cpp:152] Iteration 4450, lr = 0.0001
I0318 20:46:13.819223 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_4500.caffemodel
I0318 20:46:16.092669 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_4500.solverstate
I0318 20:46:16.774039 24729 solver.cpp:316] Iteration 4500 (3.19727 iter/s, 15.6383s/50 iter), loss = 0.0135356, remaining 0 hours and 39 minutes
I0318 20:46:16.774067 24729 solver.cpp:337]     Train net output #0: loss = 0.0135357 (* 1 = 0.0135357 loss)
I0318 20:46:16.774073 24729 sgd_solver.cpp:152] Iteration 4500, lr = 0.0001
I0318 20:46:29.665118 24729 solver.cpp:316] Iteration 4550 (3.87881 iter/s, 12.8905s/50 iter), loss = 0.0215823, remaining 0 hours and 31 minutes
I0318 20:46:29.665257 24729 solver.cpp:337]     Train net output #0: loss = 0.0215824 (* 1 = 0.0215824 loss)
I0318 20:46:29.665266 24729 sgd_solver.cpp:152] Iteration 4550, lr = 0.0001
I0318 20:46:42.604841 24729 solver.cpp:316] Iteration 4600 (3.86426 iter/s, 12.9391s/50 iter), loss = 0.00786702, remaining 0 hours and 31 minutes
I0318 20:46:42.604871 24729 solver.cpp:337]     Train net output #0: loss = 0.0078671 (* 1 = 0.0078671 loss)
I0318 20:46:42.604876 24729 sgd_solver.cpp:152] Iteration 4600, lr = 0.0001
I0318 20:46:55.556792 24729 solver.cpp:316] Iteration 4650 (3.86058 iter/s, 12.9514s/50 iter), loss = 0.0477538, remaining 0 hours and 31 minutes
I0318 20:46:55.556820 24729 solver.cpp:337]     Train net output #0: loss = 0.0477539 (* 1 = 0.0477539 loss)
I0318 20:46:55.556826 24729 sgd_solver.cpp:152] Iteration 4650, lr = 0.0001
I0318 20:47:08.500025 24729 solver.cpp:316] Iteration 4700 (3.86318 iter/s, 12.9427s/50 iter), loss = 0.0282893, remaining 0 hours and 31 minutes
I0318 20:47:08.500201 24729 solver.cpp:337]     Train net output #0: loss = 0.0282894 (* 1 = 0.0282894 loss)
I0318 20:47:08.500224 24729 sgd_solver.cpp:152] Iteration 4700, lr = 0.0001
I0318 20:47:21.450943 24729 solver.cpp:316] Iteration 4750 (3.86093 iter/s, 12.9502s/50 iter), loss = 0.0397676, remaining 0 hours and 31 minutes
I0318 20:47:21.450973 24729 solver.cpp:337]     Train net output #0: loss = 0.0397677 (* 1 = 0.0397677 loss)
I0318 20:47:21.450978 24729 sgd_solver.cpp:152] Iteration 4750, lr = 0.0001
I0318 20:47:34.410189 24729 solver.cpp:316] Iteration 4800 (3.85841 iter/s, 12.9587s/50 iter), loss = 0.0505255, remaining 0 hours and 31 minutes
I0318 20:47:34.410218 24729 solver.cpp:337]     Train net output #0: loss = 0.0505256 (* 1 = 0.0505256 loss)
I0318 20:47:34.410223 24729 sgd_solver.cpp:152] Iteration 4800, lr = 0.0001
I0318 20:47:47.355834 24729 solver.cpp:316] Iteration 4850 (3.86246 iter/s, 12.9451s/50 iter), loss = 0.0433876, remaining 0 hours and 30 minutes
I0318 20:47:47.356398 24729 solver.cpp:337]     Train net output #0: loss = 0.0433877 (* 1 = 0.0433877 loss)
I0318 20:47:47.356406 24729 sgd_solver.cpp:152] Iteration 4850, lr = 0.0001
I0318 20:48:00.292290 24729 solver.cpp:316] Iteration 4900 (3.86537 iter/s, 12.9354s/50 iter), loss = 0.0151911, remaining 0 hours and 30 minutes
I0318 20:48:00.292316 24729 solver.cpp:337]     Train net output #0: loss = 0.0151912 (* 1 = 0.0151912 loss)
I0318 20:48:00.292322 24729 sgd_solver.cpp:152] Iteration 4900, lr = 0.0001
I0318 20:48:13.248816 24729 solver.cpp:316] Iteration 4950 (3.85922 iter/s, 12.956s/50 iter), loss = 0.0124869, remaining 0 hours and 30 minutes
I0318 20:48:13.248845 24729 solver.cpp:337]     Train net output #0: loss = 0.012487 (* 1 = 0.012487 loss)
I0318 20:48:13.248852 24729 sgd_solver.cpp:152] Iteration 4950, lr = 0.0001
I0318 20:48:25.929822 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_5000.caffemodel
I0318 20:48:28.192090 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_5000.solverstate
I0318 20:48:28.619380 24729 solver.cpp:470] Iteration 5000, Testing net (#0)
I0318 20:48:30.091625 24729 solver.cpp:569]     Test net output #0: accuracy = 0.94875
I0318 20:48:30.091651 24729 solver.cpp:569]     Test net output #1: loss = 0.148495 (* 1 = 0.148495 loss)
I0318 20:48:30.091655 24729 solver.cpp:569]     Test net output #2: top-1 = 0.94875
I0318 20:48:30.337640 24729 solver.cpp:316] Iteration 5000 (2.92601 iter/s, 17.0881s/50 iter), loss = 0.0141308, remaining 0 hours and 39 minutes
I0318 20:48:30.337661 24729 solver.cpp:337]     Train net output #0: loss = 0.0141309 (* 1 = 0.0141309 loss)
I0318 20:48:30.337668 24729 sgd_solver.cpp:152] Iteration 5000, lr = 1e-05
I0318 20:48:43.283646 24729 solver.cpp:316] Iteration 5050 (3.86235 iter/s, 12.9455s/50 iter), loss = 0.022843, remaining 0 hours and 29 minutes
I0318 20:48:43.283674 24729 solver.cpp:337]     Train net output #0: loss = 0.0228431 (* 1 = 0.0228431 loss)
I0318 20:48:43.283680 24729 sgd_solver.cpp:152] Iteration 5050, lr = 1e-05
I0318 20:48:56.223081 24729 solver.cpp:316] Iteration 5100 (3.86432 iter/s, 12.9389s/50 iter), loss = 0.00867864, remaining 0 hours and 29 minutes
I0318 20:48:56.223217 24729 solver.cpp:337]     Train net output #0: loss = 0.00867874 (* 1 = 0.00867874 loss)
I0318 20:48:56.223224 24729 sgd_solver.cpp:152] Iteration 5100, lr = 1e-05
I0318 20:49:09.179599 24729 solver.cpp:316] Iteration 5150 (3.85925 iter/s, 12.9559s/50 iter), loss = 0.00444628, remaining 0 hours and 29 minutes
I0318 20:49:09.179626 24729 solver.cpp:337]     Train net output #0: loss = 0.00444638 (* 1 = 0.00444638 loss)
I0318 20:49:09.179632 24729 sgd_solver.cpp:152] Iteration 5150, lr = 1e-05
I0318 20:49:22.105835 24729 solver.cpp:316] Iteration 5200 (3.86826 iter/s, 12.9257s/50 iter), loss = 0.0256729, remaining 0 hours and 29 minutes
I0318 20:49:22.105861 24729 solver.cpp:337]     Train net output #0: loss = 0.025673 (* 1 = 0.025673 loss)
I0318 20:49:22.105867 24729 sgd_solver.cpp:152] Iteration 5200, lr = 1e-05
I0318 20:49:35.023797 24729 solver.cpp:316] Iteration 5250 (3.87074 iter/s, 12.9174s/50 iter), loss = 0.00306303, remaining 0 hours and 28 minutes
I0318 20:49:35.023947 24729 solver.cpp:337]     Train net output #0: loss = 0.00306314 (* 1 = 0.00306314 loss)
I0318 20:49:35.023970 24729 sgd_solver.cpp:152] Iteration 5250, lr = 1e-05
I0318 20:49:47.965132 24729 solver.cpp:316] Iteration 5300 (3.86378 iter/s, 12.9407s/50 iter), loss = 0.036141, remaining 0 hours and 28 minutes
I0318 20:49:47.965162 24729 solver.cpp:337]     Train net output #0: loss = 0.0361411 (* 1 = 0.0361411 loss)
I0318 20:49:47.965167 24729 sgd_solver.cpp:152] Iteration 5300, lr = 1e-05
I0318 20:50:00.903136 24729 solver.cpp:316] Iteration 5350 (3.86474 iter/s, 12.9375s/50 iter), loss = 0.0241004, remaining 0 hours and 28 minutes
I0318 20:50:00.903163 24729 solver.cpp:337]     Train net output #0: loss = 0.0241005 (* 1 = 0.0241005 loss)
I0318 20:50:00.903168 24729 sgd_solver.cpp:152] Iteration 5350, lr = 1e-05
I0318 20:50:13.861821 24729 solver.cpp:316] Iteration 5400 (3.85857 iter/s, 12.9582s/50 iter), loss = 0.0395781, remaining 0 hours and 28 minutes
I0318 20:50:13.861989 24729 solver.cpp:337]     Train net output #0: loss = 0.0395782 (* 1 = 0.0395782 loss)
I0318 20:50:13.861997 24729 sgd_solver.cpp:152] Iteration 5400, lr = 1e-05
I0318 20:50:26.796576 24729 solver.cpp:316] Iteration 5450 (3.86575 iter/s, 12.9341s/50 iter), loss = 0.0253141, remaining 0 hours and 28 minutes
I0318 20:50:26.796604 24729 solver.cpp:337]     Train net output #0: loss = 0.0253142 (* 1 = 0.0253142 loss)
I0318 20:50:26.796609 24729 sgd_solver.cpp:152] Iteration 5450, lr = 1e-05
I0318 20:50:39.457826 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_5500.caffemodel
I0318 20:50:41.728468 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_5500.solverstate
I0318 20:50:42.409162 24729 solver.cpp:316] Iteration 5500 (3.20268 iter/s, 15.6119s/50 iter), loss = 0.00744321, remaining 0 hours and 33 minutes
I0318 20:50:42.409190 24729 solver.cpp:337]     Train net output #0: loss = 0.00744332 (* 1 = 0.00744332 loss)
I0318 20:50:42.409198 24729 sgd_solver.cpp:152] Iteration 5500, lr = 1e-05
I0318 20:50:55.285986 24729 solver.cpp:316] Iteration 5550 (3.88311 iter/s, 12.8763s/50 iter), loss = 0.0340395, remaining 0 hours and 27 minutes
I0318 20:50:55.286154 24729 solver.cpp:337]     Train net output #0: loss = 0.0340396 (* 1 = 0.0340396 loss)
I0318 20:50:55.286162 24729 sgd_solver.cpp:152] Iteration 5550, lr = 1e-05
I0318 20:51:08.246021 24729 solver.cpp:316] Iteration 5600 (3.85821 iter/s, 12.9594s/50 iter), loss = 0.00110063, remaining 0 hours and 27 minutes
I0318 20:51:08.246047 24729 solver.cpp:337]     Train net output #0: loss = 0.00110073 (* 1 = 0.00110073 loss)
I0318 20:51:08.246053 24729 sgd_solver.cpp:152] Iteration 5600, lr = 1e-05
I0318 20:51:21.173692 24729 solver.cpp:316] Iteration 5650 (3.86783 iter/s, 12.9271s/50 iter), loss = 0.00614512, remaining 0 hours and 27 minutes
I0318 20:51:21.173720 24729 solver.cpp:337]     Train net output #0: loss = 0.00614522 (* 1 = 0.00614522 loss)
I0318 20:51:21.173727 24729 sgd_solver.cpp:152] Iteration 5650, lr = 1e-05
I0318 20:51:34.119925 24729 solver.cpp:316] Iteration 5700 (3.86229 iter/s, 12.9457s/50 iter), loss = 0.00248707, remaining 0 hours and 27 minutes
I0318 20:51:34.120055 24729 solver.cpp:337]     Train net output #0: loss = 0.00248717 (* 1 = 0.00248717 loss)
I0318 20:51:34.120064 24729 sgd_solver.cpp:152] Iteration 5700, lr = 1e-05
I0318 20:51:47.061779 24729 solver.cpp:316] Iteration 5750 (3.86362 iter/s, 12.9412s/50 iter), loss = 0.00680997, remaining 0 hours and 26 minutes
I0318 20:51:47.061807 24729 solver.cpp:337]     Train net output #0: loss = 0.00681008 (* 1 = 0.00681008 loss)
I0318 20:51:47.061813 24729 sgd_solver.cpp:152] Iteration 5750, lr = 1e-05
I0318 20:51:59.999244 24729 solver.cpp:316] Iteration 5800 (3.8649 iter/s, 12.9369s/50 iter), loss = 0.00538133, remaining 0 hours and 26 minutes
I0318 20:51:59.999274 24729 solver.cpp:337]     Train net output #0: loss = 0.00538143 (* 1 = 0.00538143 loss)
I0318 20:51:59.999280 24729 sgd_solver.cpp:152] Iteration 5800, lr = 1e-05
I0318 20:52:12.954869 24729 solver.cpp:316] Iteration 5850 (3.85949 iter/s, 12.9551s/50 iter), loss = 0.00397703, remaining 0 hours and 26 minutes
I0318 20:52:12.955006 24729 solver.cpp:337]     Train net output #0: loss = 0.00397713 (* 1 = 0.00397713 loss)
I0318 20:52:12.955013 24729 sgd_solver.cpp:152] Iteration 5850, lr = 1e-05
I0318 20:52:25.907483 24729 solver.cpp:316] Iteration 5900 (3.86042 iter/s, 12.952s/50 iter), loss = 0.00220167, remaining 0 hours and 26 minutes
I0318 20:52:25.907510 24729 solver.cpp:337]     Train net output #0: loss = 0.00220177 (* 1 = 0.00220177 loss)
I0318 20:52:25.907516 24729 sgd_solver.cpp:152] Iteration 5900, lr = 1e-05
I0318 20:52:38.861784 24729 solver.cpp:316] Iteration 5950 (3.85988 iter/s, 12.9538s/50 iter), loss = 0.0114717, remaining 0 hours and 25 minutes
I0318 20:52:38.861812 24729 solver.cpp:337]     Train net output #0: loss = 0.0114718 (* 1 = 0.0114718 loss)
I0318 20:52:38.861819 24729 sgd_solver.cpp:152] Iteration 5950, lr = 1e-05
I0318 20:52:51.543630 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_6000.caffemodel
I0318 20:52:53.826714 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_6000.solverstate
I0318 20:52:54.257414 24729 solver.cpp:470] Iteration 6000, Testing net (#0)
I0318 20:52:55.723769 24729 solver.cpp:569]     Test net output #0: accuracy = 0.954
I0318 20:52:55.723795 24729 solver.cpp:569]     Test net output #1: loss = 0.163963 (* 1 = 0.163963 loss)
I0318 20:52:55.723798 24729 solver.cpp:569]     Test net output #2: top-1 = 0.954
I0318 20:52:55.968432 24729 solver.cpp:316] Iteration 6000 (2.92296 iter/s, 17.106s/50 iter), loss = 0.0210943, remaining 0 hours and 34 minutes
I0318 20:52:55.968456 24729 solver.cpp:337]     Train net output #0: loss = 0.0210944 (* 1 = 0.0210944 loss)
I0318 20:52:55.968462 24729 sgd_solver.cpp:152] Iteration 6000, lr = 1e-05
I0318 20:53:08.881994 24729 solver.cpp:316] Iteration 6050 (3.87206 iter/s, 12.913s/50 iter), loss = 0.0126126, remaining 0 hours and 25 minutes
I0318 20:53:08.882021 24729 solver.cpp:337]     Train net output #0: loss = 0.0126127 (* 1 = 0.0126127 loss)
I0318 20:53:08.882030 24729 sgd_solver.cpp:152] Iteration 6050, lr = 1e-05
I0318 20:53:21.821790 24729 solver.cpp:316] Iteration 6100 (3.86421 iter/s, 12.9393s/50 iter), loss = 0.0153939, remaining 0 hours and 25 minutes
I0318 20:53:21.821943 24729 solver.cpp:337]     Train net output #0: loss = 0.015394 (* 1 = 0.015394 loss)
I0318 20:53:21.821950 24729 sgd_solver.cpp:152] Iteration 6100, lr = 1e-05
I0318 20:53:34.765067 24729 solver.cpp:316] Iteration 6150 (3.86321 iter/s, 12.9426s/50 iter), loss = 0.00217897, remaining 0 hours and 25 minutes
I0318 20:53:34.765095 24729 solver.cpp:337]     Train net output #0: loss = 0.00217907 (* 1 = 0.00217907 loss)
I0318 20:53:34.765101 24729 sgd_solver.cpp:152] Iteration 6150, lr = 1e-05
I0318 20:53:47.701814 24729 solver.cpp:316] Iteration 6200 (3.86512 iter/s, 12.9362s/50 iter), loss = 0.0251142, remaining 0 hours and 24 minutes
I0318 20:53:47.701843 24729 solver.cpp:337]     Train net output #0: loss = 0.0251143 (* 1 = 0.0251143 loss)
I0318 20:53:47.701850 24729 sgd_solver.cpp:152] Iteration 6200, lr = 1e-05
I0318 20:54:00.630559 24729 solver.cpp:316] Iteration 6250 (3.86751 iter/s, 12.9282s/50 iter), loss = 0.0243977, remaining 0 hours and 24 minutes
I0318 20:54:00.630699 24729 solver.cpp:337]     Train net output #0: loss = 0.0243978 (* 1 = 0.0243978 loss)
I0318 20:54:00.630707 24729 sgd_solver.cpp:152] Iteration 6250, lr = 1e-05
I0318 20:54:13.571100 24729 solver.cpp:316] Iteration 6300 (3.86402 iter/s, 12.9399s/50 iter), loss = 0.00319056, remaining 0 hours and 24 minutes
I0318 20:54:13.571128 24729 solver.cpp:337]     Train net output #0: loss = 0.00319067 (* 1 = 0.00319067 loss)
I0318 20:54:13.571133 24729 sgd_solver.cpp:152] Iteration 6300, lr = 1e-05
I0318 20:54:26.509394 24729 solver.cpp:316] Iteration 6350 (3.86466 iter/s, 12.9378s/50 iter), loss = 0.0153028, remaining 0 hours and 24 minutes
I0318 20:54:26.509423 24729 solver.cpp:337]     Train net output #0: loss = 0.0153029 (* 1 = 0.0153029 loss)
I0318 20:54:26.509428 24729 sgd_solver.cpp:152] Iteration 6350, lr = 1e-05
I0318 20:54:39.421753 24729 solver.cpp:316] Iteration 6400 (3.87242 iter/s, 12.9118s/50 iter), loss = 0.00983277, remaining 0 hours and 24 minutes
I0318 20:54:39.421921 24729 solver.cpp:337]     Train net output #0: loss = 0.00983288 (* 1 = 0.00983288 loss)
I0318 20:54:39.421929 24729 sgd_solver.cpp:152] Iteration 6400, lr = 1e-05
I0318 20:54:52.382794 24729 solver.cpp:316] Iteration 6450 (3.85791 iter/s, 12.9604s/50 iter), loss = 0.00490105, remaining 0 hours and 23 minutes
I0318 20:54:52.382819 24729 solver.cpp:337]     Train net output #0: loss = 0.00490116 (* 1 = 0.00490116 loss)
I0318 20:54:52.382827 24729 sgd_solver.cpp:152] Iteration 6450, lr = 1e-05
I0318 20:55:05.081457 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_6500.caffemodel
I0318 20:55:07.421008 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_6500.solverstate
I0318 20:55:08.119765 24729 solver.cpp:316] Iteration 6500 (3.17736 iter/s, 15.7363s/50 iter), loss = 0.0168657, remaining 0 hours and 28 minutes
I0318 20:55:08.119793 24729 solver.cpp:337]     Train net output #0: loss = 0.0168658 (* 1 = 0.0168658 loss)
I0318 20:55:08.119801 24729 sgd_solver.cpp:152] Iteration 6500, lr = 1e-05
I0318 20:55:20.992655 24729 solver.cpp:316] Iteration 6550 (3.88429 iter/s, 12.8724s/50 iter), loss = 0.00141708, remaining 0 hours and 23 minutes
I0318 20:55:20.992796 24729 solver.cpp:337]     Train net output #0: loss = 0.00141719 (* 1 = 0.00141719 loss)
I0318 20:55:20.992805 24729 sgd_solver.cpp:152] Iteration 6550, lr = 1e-05
I0318 20:55:33.932170 24729 solver.cpp:316] Iteration 6600 (3.86433 iter/s, 12.9389s/50 iter), loss = 0.012392, remaining 0 hours and 23 minutes
I0318 20:55:33.932199 24729 solver.cpp:337]     Train net output #0: loss = 0.0123921 (* 1 = 0.0123921 loss)
I0318 20:55:33.932204 24729 sgd_solver.cpp:152] Iteration 6600, lr = 1e-05
I0318 20:55:46.869617 24729 solver.cpp:316] Iteration 6650 (3.86491 iter/s, 12.9369s/50 iter), loss = 0.00285105, remaining 0 hours and 23 minutes
I0318 20:55:46.869645 24729 solver.cpp:337]     Train net output #0: loss = 0.00285116 (* 1 = 0.00285116 loss)
I0318 20:55:46.869652 24729 sgd_solver.cpp:152] Iteration 6650, lr = 1e-05
I0318 20:55:59.804136 24729 solver.cpp:316] Iteration 6700 (3.86578 iter/s, 12.934s/50 iter), loss = 0.00195202, remaining 0 hours and 22 minutes
I0318 20:55:59.804293 24729 solver.cpp:337]     Train net output #0: loss = 0.00195213 (* 1 = 0.00195213 loss)
I0318 20:55:59.804302 24729 sgd_solver.cpp:152] Iteration 6700, lr = 1e-05
I0318 20:56:12.747191 24729 solver.cpp:316] Iteration 6750 (3.86327 iter/s, 12.9424s/50 iter), loss = 0.00713629, remaining 0 hours and 22 minutes
I0318 20:56:12.747221 24729 solver.cpp:337]     Train net output #0: loss = 0.00713639 (* 1 = 0.00713639 loss)
I0318 20:56:12.747227 24729 sgd_solver.cpp:152] Iteration 6750, lr = 1e-05
I0318 20:56:25.685674 24729 solver.cpp:316] Iteration 6800 (3.8646 iter/s, 12.9379s/50 iter), loss = 0.0157747, remaining 0 hours and 22 minutes
I0318 20:56:25.685701 24729 solver.cpp:337]     Train net output #0: loss = 0.0157748 (* 1 = 0.0157748 loss)
I0318 20:56:25.685708 24729 sgd_solver.cpp:152] Iteration 6800, lr = 1e-05
I0318 20:56:38.642657 24729 solver.cpp:316] Iteration 6850 (3.85908 iter/s, 12.9565s/50 iter), loss = 0.000936572, remaining 0 hours and 22 minutes
I0318 20:56:38.642796 24729 solver.cpp:337]     Train net output #0: loss = 0.000936681 (* 1 = 0.000936681 loss)
I0318 20:56:38.642803 24729 sgd_solver.cpp:152] Iteration 6850, lr = 1e-05
I0318 20:56:51.571816 24729 solver.cpp:316] Iteration 6900 (3.86742 iter/s, 12.9285s/50 iter), loss = 0.0143693, remaining 0 hours and 21 minutes
I0318 20:56:51.571842 24729 solver.cpp:337]     Train net output #0: loss = 0.0143694 (* 1 = 0.0143694 loss)
I0318 20:56:51.571849 24729 sgd_solver.cpp:152] Iteration 6900, lr = 1e-05
I0318 20:57:04.526348 24729 solver.cpp:316] Iteration 6950 (3.85981 iter/s, 12.954s/50 iter), loss = 0.00509318, remaining 0 hours and 21 minutes
I0318 20:57:04.526377 24729 solver.cpp:337]     Train net output #0: loss = 0.0050933 (* 1 = 0.0050933 loss)
I0318 20:57:04.526383 24729 sgd_solver.cpp:152] Iteration 6950, lr = 1e-05
I0318 20:57:17.208700 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_7000.caffemodel
I0318 20:57:19.539571 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_7000.solverstate
I0318 20:57:19.969262 24729 solver.cpp:470] Iteration 7000, Testing net (#0)
I0318 20:57:21.504072 24729 solver.cpp:569]     Test net output #0: accuracy = 0.9525
I0318 20:57:21.504096 24729 solver.cpp:569]     Test net output #1: loss = 0.193322 (* 1 = 0.193322 loss)
I0318 20:57:21.504099 24729 solver.cpp:569]     Test net output #2: top-1 = 0.9525
I0318 20:57:21.758298 24729 solver.cpp:316] Iteration 7000 (2.9017 iter/s, 17.2313s/50 iter), loss = 0.0295147, remaining 0 hours and 28 minutes
I0318 20:57:21.758324 24729 solver.cpp:337]     Train net output #0: loss = 0.0295148 (* 1 = 0.0295148 loss)
I0318 20:57:21.758332 24729 sgd_solver.cpp:152] Iteration 7000, lr = 1e-05
I0318 20:57:34.634527 24729 solver.cpp:316] Iteration 7050 (3.88328 iter/s, 12.8757s/50 iter), loss = 0.00755218, remaining 0 hours and 21 minutes
I0318 20:57:34.634557 24729 solver.cpp:337]     Train net output #0: loss = 0.0075523 (* 1 = 0.0075523 loss)
I0318 20:57:34.634563 24729 sgd_solver.cpp:152] Iteration 7050, lr = 1e-05
I0318 20:57:47.584858 24729 solver.cpp:316] Iteration 7100 (3.86106 iter/s, 12.9498s/50 iter), loss = 0.0128811, remaining 0 hours and 20 minutes
I0318 20:57:47.584992 24729 solver.cpp:337]     Train net output #0: loss = 0.0128812 (* 1 = 0.0128812 loss)
I0318 20:57:47.585000 24729 sgd_solver.cpp:152] Iteration 7100, lr = 1e-05
I0318 20:58:00.516561 24729 solver.cpp:316] Iteration 7150 (3.86666 iter/s, 12.9311s/50 iter), loss = 0.00623917, remaining 0 hours and 20 minutes
I0318 20:58:00.516588 24729 solver.cpp:337]     Train net output #0: loss = 0.00623929 (* 1 = 0.00623929 loss)
I0318 20:58:00.516594 24729 sgd_solver.cpp:152] Iteration 7150, lr = 1e-05
I0318 20:58:13.442276 24729 solver.cpp:316] Iteration 7200 (3.86842 iter/s, 12.9252s/50 iter), loss = 0.0129121, remaining 0 hours and 20 minutes
I0318 20:58:13.442303 24729 solver.cpp:337]     Train net output #0: loss = 0.0129122 (* 1 = 0.0129122 loss)
I0318 20:58:13.442310 24729 sgd_solver.cpp:152] Iteration 7200, lr = 1e-05
I0318 20:58:26.397094 24729 solver.cpp:316] Iteration 7250 (3.85973 iter/s, 12.9543s/50 iter), loss = 0.020755, remaining 0 hours and 20 minutes
I0318 20:58:26.397228 24729 solver.cpp:337]     Train net output #0: loss = 0.0207551 (* 1 = 0.0207551 loss)
I0318 20:58:26.397235 24729 sgd_solver.cpp:152] Iteration 7250, lr = 1e-05
I0318 20:58:39.333425 24729 solver.cpp:316] Iteration 7300 (3.86527 iter/s, 12.9357s/50 iter), loss = 0.0112668, remaining 0 hours and 20 minutes
I0318 20:58:39.333453 24729 solver.cpp:337]     Train net output #0: loss = 0.011267 (* 1 = 0.011267 loss)
I0318 20:58:39.333458 24729 sgd_solver.cpp:152] Iteration 7300, lr = 1e-05
I0318 20:58:52.257522 24729 solver.cpp:316] Iteration 7350 (3.8689 iter/s, 12.9236s/50 iter), loss = 0.0151888, remaining 0 hours and 19 minutes
I0318 20:58:52.257551 24729 solver.cpp:337]     Train net output #0: loss = 0.0151889 (* 1 = 0.0151889 loss)
I0318 20:58:52.257556 24729 sgd_solver.cpp:152] Iteration 7350, lr = 1e-05
I0318 20:59:05.194689 24729 solver.cpp:316] Iteration 7400 (3.86499 iter/s, 12.9366s/50 iter), loss = 0.013147, remaining 0 hours and 19 minutes
I0318 20:59:05.194825 24729 solver.cpp:337]     Train net output #0: loss = 0.0131472 (* 1 = 0.0131472 loss)
I0318 20:59:05.194833 24729 sgd_solver.cpp:152] Iteration 7400, lr = 1e-05
I0318 20:59:18.145750 24729 solver.cpp:316] Iteration 7450 (3.86088 iter/s, 12.9504s/50 iter), loss = 0.00281088, remaining 0 hours and 19 minutes
I0318 20:59:18.145778 24729 solver.cpp:337]     Train net output #0: loss = 0.002811 (* 1 = 0.002811 loss)
I0318 20:59:18.145784 24729 sgd_solver.cpp:152] Iteration 7450, lr = 1e-05
I0318 20:59:30.841543 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_7500.caffemodel
I0318 20:59:33.155125 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_7500.solverstate
I0318 20:59:33.832926 24729 solver.cpp:316] Iteration 7500 (3.18745 iter/s, 15.6865s/50 iter), loss = 0.00471795, remaining 0 hours and 23 minutes
I0318 20:59:33.832954 24729 solver.cpp:337]     Train net output #0: loss = 0.00471807 (* 1 = 0.00471807 loss)
I0318 20:59:33.832962 24729 sgd_solver.cpp:152] Iteration 7500, lr = 1e-06
I0318 20:59:46.728318 24729 solver.cpp:316] Iteration 7550 (3.87751 iter/s, 12.8949s/50 iter), loss = 0.0177153, remaining 0 hours and 19 minutes
I0318 20:59:46.728475 24729 solver.cpp:337]     Train net output #0: loss = 0.0177154 (* 1 = 0.0177154 loss)
I0318 20:59:46.728483 24729 sgd_solver.cpp:152] Iteration 7550, lr = 1e-06
I0318 20:59:59.659507 24729 solver.cpp:316] Iteration 7600 (3.86682 iter/s, 12.9305s/50 iter), loss = 0.00260028, remaining 0 hours and 18 minutes
I0318 20:59:59.659533 24729 solver.cpp:337]     Train net output #0: loss = 0.00260041 (* 1 = 0.00260041 loss)
I0318 20:59:59.659539 24729 sgd_solver.cpp:152] Iteration 7600, lr = 1e-06
I0318 21:00:12.599021 24729 solver.cpp:316] Iteration 7650 (3.86429 iter/s, 12.939s/50 iter), loss = 0.00516681, remaining 0 hours and 18 minutes
I0318 21:00:12.599051 24729 solver.cpp:337]     Train net output #0: loss = 0.00516693 (* 1 = 0.00516693 loss)
I0318 21:00:12.599057 24729 sgd_solver.cpp:152] Iteration 7650, lr = 1e-06
I0318 21:00:25.538112 24729 solver.cpp:316] Iteration 7700 (3.86442 iter/s, 12.9386s/50 iter), loss = 0.00211697, remaining 0 hours and 18 minutes
I0318 21:00:25.538292 24729 solver.cpp:337]     Train net output #0: loss = 0.00211709 (* 1 = 0.00211709 loss)
I0318 21:00:25.538316 24729 sgd_solver.cpp:152] Iteration 7700, lr = 1e-06
I0318 21:00:38.480226 24729 solver.cpp:316] Iteration 7750 (3.86356 iter/s, 12.9414s/50 iter), loss = 0.0106216, remaining 0 hours and 18 minutes
I0318 21:00:38.480255 24729 solver.cpp:337]     Train net output #0: loss = 0.0106217 (* 1 = 0.0106217 loss)
I0318 21:00:38.480262 24729 sgd_solver.cpp:152] Iteration 7750, lr = 1e-06
I0318 21:00:51.431843 24729 solver.cpp:316] Iteration 7800 (3.86068 iter/s, 12.9511s/50 iter), loss = 0.00263678, remaining 0 hours and 18 minutes
I0318 21:00:51.431869 24729 solver.cpp:337]     Train net output #0: loss = 0.0026369 (* 1 = 0.0026369 loss)
I0318 21:00:51.431875 24729 sgd_solver.cpp:152] Iteration 7800, lr = 1e-06
I0318 21:01:04.382766 24729 solver.cpp:316] Iteration 7850 (3.86089 iter/s, 12.9504s/50 iter), loss = 0.00393062, remaining 0 hours and 17 minutes
I0318 21:01:04.382894 24729 solver.cpp:337]     Train net output #0: loss = 0.00393074 (* 1 = 0.00393074 loss)
I0318 21:01:04.382902 24729 sgd_solver.cpp:152] Iteration 7850, lr = 1e-06
I0318 21:01:17.306818 24729 solver.cpp:316] Iteration 7900 (3.86894 iter/s, 12.9234s/50 iter), loss = 0.0380089, remaining 0 hours and 17 minutes
I0318 21:01:17.306846 24729 solver.cpp:337]     Train net output #0: loss = 0.038009 (* 1 = 0.038009 loss)
I0318 21:01:17.306869 24729 sgd_solver.cpp:152] Iteration 7900, lr = 1e-06
I0318 21:01:30.257174 24729 solver.cpp:316] Iteration 7950 (3.86106 iter/s, 12.9498s/50 iter), loss = 0.00821037, remaining 0 hours and 17 minutes
I0318 21:01:30.257202 24729 solver.cpp:337]     Train net output #0: loss = 0.00821049 (* 1 = 0.00821049 loss)
I0318 21:01:30.257208 24729 sgd_solver.cpp:152] Iteration 7950, lr = 1e-06
I0318 21:01:42.943104 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_8000.caffemodel
I0318 21:01:45.276715 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_8000.solverstate
I0318 21:01:45.706588 24729 solver.cpp:470] Iteration 8000, Testing net (#0)
I0318 21:01:47.247220 24729 solver.cpp:569]     Test net output #0: accuracy = 0.95425
I0318 21:01:47.247244 24729 solver.cpp:569]     Test net output #1: loss = 0.213146 (* 1 = 0.213146 loss)
I0318 21:01:47.247247 24729 solver.cpp:569]     Test net output #2: top-1 = 0.95425
I0318 21:01:47.497274 24729 solver.cpp:316] Iteration 8000 (2.90033 iter/s, 17.2394s/50 iter), loss = 0.00106506, remaining 0 hours and 22 minutes
I0318 21:01:47.497298 24729 solver.cpp:337]     Train net output #0: loss = 0.00106519 (* 1 = 0.00106519 loss)
I0318 21:01:47.497306 24729 sgd_solver.cpp:152] Iteration 8000, lr = 1e-06
I0318 21:02:00.373242 24729 solver.cpp:316] Iteration 8050 (3.88336 iter/s, 12.8754s/50 iter), loss = 0.00725587, remaining 0 hours and 16 minutes
I0318 21:02:00.373268 24729 solver.cpp:337]     Train net output #0: loss = 0.00725599 (* 1 = 0.00725599 loss)
I0318 21:02:00.373275 24729 sgd_solver.cpp:152] Iteration 8050, lr = 1e-06
I0318 21:02:13.285292 24729 solver.cpp:316] Iteration 8100 (3.87251 iter/s, 12.9115s/50 iter), loss = 0.00196212, remaining 0 hours and 16 minutes
I0318 21:02:13.285459 24729 solver.cpp:337]     Train net output #0: loss = 0.00196224 (* 1 = 0.00196224 loss)
I0318 21:02:13.285467 24729 sgd_solver.cpp:152] Iteration 8100, lr = 1e-06
I0318 21:02:26.242455 24729 solver.cpp:316] Iteration 8150 (3.85907 iter/s, 12.9565s/50 iter), loss = 0.016983, remaining 0 hours and 16 minutes
I0318 21:02:26.242481 24729 solver.cpp:337]     Train net output #0: loss = 0.0169831 (* 1 = 0.0169831 loss)
I0318 21:02:26.242487 24729 sgd_solver.cpp:152] Iteration 8150, lr = 1e-06
I0318 21:02:39.189860 24729 solver.cpp:316] Iteration 8200 (3.86194 iter/s, 12.9469s/50 iter), loss = 0.00331268, remaining 0 hours and 16 minutes
I0318 21:02:39.189890 24729 solver.cpp:337]     Train net output #0: loss = 0.0033128 (* 1 = 0.0033128 loss)
I0318 21:02:39.189898 24729 sgd_solver.cpp:152] Iteration 8200, lr = 1e-06
I0318 21:02:52.155433 24729 solver.cpp:316] Iteration 8250 (3.85653 iter/s, 12.965s/50 iter), loss = 0.0113713, remaining 0 hours and 16 minutes
I0318 21:02:52.155570 24729 solver.cpp:337]     Train net output #0: loss = 0.0113714 (* 1 = 0.0113714 loss)
I0318 21:02:52.155578 24729 sgd_solver.cpp:152] Iteration 8250, lr = 1e-06
I0318 21:03:05.095335 24729 solver.cpp:316] Iteration 8300 (3.86421 iter/s, 12.9393s/50 iter), loss = 0.0102339, remaining 0 hours and 15 minutes
I0318 21:03:05.095365 24729 solver.cpp:337]     Train net output #0: loss = 0.0102341 (* 1 = 0.0102341 loss)
I0318 21:03:05.095371 24729 sgd_solver.cpp:152] Iteration 8300, lr = 1e-06
I0318 21:03:18.051328 24729 solver.cpp:316] Iteration 8350 (3.85938 iter/s, 12.9555s/50 iter), loss = 0.0251152, remaining 0 hours and 15 minutes
I0318 21:03:18.051357 24729 solver.cpp:337]     Train net output #0: loss = 0.0251153 (* 1 = 0.0251153 loss)
I0318 21:03:18.051362 24729 sgd_solver.cpp:152] Iteration 8350, lr = 1e-06
I0318 21:03:30.980854 24729 solver.cpp:316] Iteration 8400 (3.86728 iter/s, 12.929s/50 iter), loss = 0.0124007, remaining 0 hours and 15 minutes
I0318 21:03:30.982374 24729 solver.cpp:337]     Train net output #0: loss = 0.0124008 (* 1 = 0.0124008 loss)
I0318 21:03:30.982383 24729 sgd_solver.cpp:152] Iteration 8400, lr = 1e-06
I0318 21:03:43.920282 24729 solver.cpp:316] Iteration 8450 (3.86476 iter/s, 12.9374s/50 iter), loss = 0.0172765, remaining 0 hours and 15 minutes
I0318 21:03:43.920310 24729 solver.cpp:337]     Train net output #0: loss = 0.0172766 (* 1 = 0.0172766 loss)
I0318 21:03:43.920316 24729 sgd_solver.cpp:152] Iteration 8450, lr = 1e-06
I0318 21:03:56.603374 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_8500.caffemodel
I0318 21:03:58.927309 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_8500.solverstate
I0318 21:03:59.613092 24729 solver.cpp:316] Iteration 8500 (3.1863 iter/s, 15.6922s/50 iter), loss = 0.0260801, remaining 0 hours and 18 minutes
I0318 21:03:59.613121 24729 solver.cpp:337]     Train net output #0: loss = 0.0260803 (* 1 = 0.0260803 loss)
I0318 21:03:59.613128 24729 sgd_solver.cpp:152] Iteration 8500, lr = 1e-06
I0318 21:04:12.514858 24729 solver.cpp:316] Iteration 8550 (3.8756 iter/s, 12.9012s/50 iter), loss = 0.0255255, remaining 0 hours and 14 minutes
I0318 21:04:12.515013 24729 solver.cpp:337]     Train net output #0: loss = 0.0255256 (* 1 = 0.0255256 loss)
I0318 21:04:12.515022 24729 sgd_solver.cpp:152] Iteration 8550, lr = 1e-06
I0318 21:04:25.462219 24729 solver.cpp:316] Iteration 8600 (3.86199 iter/s, 12.9467s/50 iter), loss = 0.0060219, remaining 0 hours and 14 minutes
I0318 21:04:25.462249 24729 solver.cpp:337]     Train net output #0: loss = 0.00602203 (* 1 = 0.00602203 loss)
I0318 21:04:25.462255 24729 sgd_solver.cpp:152] Iteration 8600, lr = 1e-06
I0318 21:04:38.418717 24729 solver.cpp:316] Iteration 8650 (3.85923 iter/s, 12.956s/50 iter), loss = 0.00761727, remaining 0 hours and 14 minutes
I0318 21:04:38.418747 24729 solver.cpp:337]     Train net output #0: loss = 0.0076174 (* 1 = 0.0076174 loss)
I0318 21:04:38.418754 24729 sgd_solver.cpp:152] Iteration 8650, lr = 1e-06
I0318 21:04:51.357388 24729 solver.cpp:316] Iteration 8700 (3.86454 iter/s, 12.9381s/50 iter), loss = 0.0163685, remaining 0 hours and 14 minutes
I0318 21:04:51.357523 24729 solver.cpp:337]     Train net output #0: loss = 0.0163686 (* 1 = 0.0163686 loss)
I0318 21:04:51.357532 24729 sgd_solver.cpp:152] Iteration 8700, lr = 1e-06
I0318 21:05:04.311359 24729 solver.cpp:316] Iteration 8750 (3.86001 iter/s, 12.9533s/50 iter), loss = 0.00147936, remaining 0 hours and 13 minutes
I0318 21:05:04.311388 24729 solver.cpp:337]     Train net output #0: loss = 0.00147948 (* 1 = 0.00147948 loss)
I0318 21:05:04.311393 24729 sgd_solver.cpp:152] Iteration 8750, lr = 1e-06
I0318 21:05:17.259179 24729 solver.cpp:316] Iteration 8800 (3.86181 iter/s, 12.9473s/50 iter), loss = 0.00689692, remaining 0 hours and 13 minutes
I0318 21:05:17.259208 24729 solver.cpp:337]     Train net output #0: loss = 0.00689704 (* 1 = 0.00689704 loss)
I0318 21:05:17.259214 24729 sgd_solver.cpp:152] Iteration 8800, lr = 1e-06
I0318 21:05:30.203510 24729 solver.cpp:316] Iteration 8850 (3.86285 iter/s, 12.9438s/50 iter), loss = 0.00426272, remaining 0 hours and 13 minutes
I0318 21:05:30.203665 24729 solver.cpp:337]     Train net output #0: loss = 0.00426284 (* 1 = 0.00426284 loss)
I0318 21:05:30.203672 24729 sgd_solver.cpp:152] Iteration 8850, lr = 1e-06
I0318 21:05:43.127851 24729 solver.cpp:316] Iteration 8900 (3.86887 iter/s, 12.9237s/50 iter), loss = 0.00429074, remaining 0 hours and 13 minutes
I0318 21:05:43.127880 24729 solver.cpp:337]     Train net output #0: loss = 0.00429086 (* 1 = 0.00429086 loss)
I0318 21:05:43.127887 24729 sgd_solver.cpp:152] Iteration 8900, lr = 1e-06
I0318 21:05:56.051132 24729 solver.cpp:316] Iteration 8950 (3.86915 iter/s, 12.9227s/50 iter), loss = 0.0139703, remaining 0 hours and 12 minutes
I0318 21:05:56.051159 24729 solver.cpp:337]     Train net output #0: loss = 0.0139704 (* 1 = 0.0139704 loss)
I0318 21:05:56.051165 24729 sgd_solver.cpp:152] Iteration 8950, lr = 1e-06
I0318 21:06:08.736941 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_9000.caffemodel
I0318 21:06:11.061960 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_9000.solverstate
I0318 21:06:11.505882 24729 solver.cpp:470] Iteration 9000, Testing net (#0)
I0318 21:06:13.045011 24729 solver.cpp:569]     Test net output #0: accuracy = 0.95425
I0318 21:06:13.045037 24729 solver.cpp:569]     Test net output #1: loss = 0.231263 (* 1 = 0.231263 loss)
I0318 21:06:13.045039 24729 solver.cpp:569]     Test net output #2: top-1 = 0.95425
I0318 21:06:13.293972 24729 solver.cpp:316] Iteration 9000 (2.89987 iter/s, 17.2421s/50 iter), loss = 0.00844762, remaining 0 hours and 17 minutes
I0318 21:06:13.293994 24729 solver.cpp:337]     Train net output #0: loss = 0.00844773 (* 1 = 0.00844773 loss)
I0318 21:06:13.294001 24729 sgd_solver.cpp:152] Iteration 9000, lr = 1e-06
I0318 21:06:26.189016 24729 solver.cpp:316] Iteration 9050 (3.87762 iter/s, 12.8945s/50 iter), loss = 0.00313218, remaining 0 hours and 12 minutes
I0318 21:06:26.189044 24729 solver.cpp:337]     Train net output #0: loss = 0.0031323 (* 1 = 0.0031323 loss)
I0318 21:06:26.189050 24729 sgd_solver.cpp:152] Iteration 9050, lr = 1e-06
I0318 21:06:39.115399 24729 solver.cpp:316] Iteration 9100 (3.86822 iter/s, 12.9258s/50 iter), loss = 0.0132725, remaining 0 hours and 12 minutes
I0318 21:06:39.115552 24729 solver.cpp:337]     Train net output #0: loss = 0.0132726 (* 1 = 0.0132726 loss)
I0318 21:06:39.115561 24729 sgd_solver.cpp:152] Iteration 9100, lr = 1e-06
I0318 21:06:52.041514 24729 solver.cpp:316] Iteration 9150 (3.86833 iter/s, 12.9255s/50 iter), loss = 0.0045326, remaining 0 hours and 12 minutes
I0318 21:06:52.041543 24729 solver.cpp:337]     Train net output #0: loss = 0.00453271 (* 1 = 0.00453271 loss)
I0318 21:06:52.041549 24729 sgd_solver.cpp:152] Iteration 9150, lr = 1e-06
I0318 21:07:04.986428 24729 solver.cpp:316] Iteration 9200 (3.86268 iter/s, 12.9444s/50 iter), loss = 0.00586797, remaining 0 hours and 11 minutes
I0318 21:07:04.986457 24729 solver.cpp:337]     Train net output #0: loss = 0.00586808 (* 1 = 0.00586808 loss)
I0318 21:07:04.986464 24729 sgd_solver.cpp:152] Iteration 9200, lr = 1e-06
I0318 21:07:17.934561 24729 solver.cpp:316] Iteration 9250 (3.86172 iter/s, 12.9476s/50 iter), loss = 0.00781689, remaining 0 hours and 11 minutes
I0318 21:07:17.934707 24729 solver.cpp:337]     Train net output #0: loss = 0.007817 (* 1 = 0.007817 loss)
I0318 21:07:17.934715 24729 sgd_solver.cpp:152] Iteration 9250, lr = 1e-06
I0318 21:07:30.876096 24729 solver.cpp:316] Iteration 9300 (3.86372 iter/s, 12.9409s/50 iter), loss = 0.00776618, remaining 0 hours and 11 minutes
I0318 21:07:30.876125 24729 solver.cpp:337]     Train net output #0: loss = 0.0077663 (* 1 = 0.0077663 loss)
I0318 21:07:30.876132 24729 sgd_solver.cpp:152] Iteration 9300, lr = 1e-06
I0318 21:07:43.812582 24729 solver.cpp:316] Iteration 9350 (3.8652 iter/s, 12.936s/50 iter), loss = 0.00660703, remaining 0 hours and 11 minutes
I0318 21:07:43.812611 24729 solver.cpp:337]     Train net output #0: loss = 0.00660714 (* 1 = 0.00660714 loss)
I0318 21:07:43.812616 24729 sgd_solver.cpp:152] Iteration 9350, lr = 1e-06
I0318 21:07:56.740377 24729 solver.cpp:316] Iteration 9400 (3.8678 iter/s, 12.9273s/50 iter), loss = 0.00601173, remaining 0 hours and 11 minutes
I0318 21:07:56.740586 24729 solver.cpp:337]     Train net output #0: loss = 0.00601185 (* 1 = 0.00601185 loss)
I0318 21:07:56.740609 24729 sgd_solver.cpp:152] Iteration 9400, lr = 1e-06
I0318 21:08:09.699311 24729 solver.cpp:316] Iteration 9450 (3.85855 iter/s, 12.9582s/50 iter), loss = 0.00326327, remaining 0 hours and 10 minutes
I0318 21:08:09.699340 24729 solver.cpp:337]     Train net output #0: loss = 0.00326338 (* 1 = 0.00326338 loss)
I0318 21:08:09.699347 24729 sgd_solver.cpp:152] Iteration 9450, lr = 1e-06
I0318 21:08:22.373711 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_9500.caffemodel
I0318 21:08:24.740386 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_9500.solverstate
I0318 21:08:25.423419 24729 solver.cpp:316] Iteration 9500 (3.17996 iter/s, 15.7235s/50 iter), loss = 0.00247551, remaining 0 hours and 12 minutes
I0318 21:08:25.423449 24729 solver.cpp:337]     Train net output #0: loss = 0.00247563 (* 1 = 0.00247563 loss)
I0318 21:08:25.423456 24729 sgd_solver.cpp:152] Iteration 9500, lr = 1e-06
I0318 21:08:38.297804 24729 solver.cpp:316] Iteration 9550 (3.88384 iter/s, 12.8739s/50 iter), loss = 0.00333822, remaining 0 hours and 10 minutes
I0318 21:08:38.297960 24729 solver.cpp:337]     Train net output #0: loss = 0.00333833 (* 1 = 0.00333833 loss)
I0318 21:08:38.297968 24729 sgd_solver.cpp:152] Iteration 9550, lr = 1e-06
I0318 21:08:51.220063 24729 solver.cpp:316] Iteration 9600 (3.86949 iter/s, 12.9216s/50 iter), loss = 0.00279446, remaining 0 hours and 10 minutes
I0318 21:08:51.220090 24729 solver.cpp:337]     Train net output #0: loss = 0.00279457 (* 1 = 0.00279457 loss)
I0318 21:08:51.220098 24729 sgd_solver.cpp:152] Iteration 9600, lr = 1e-06
I0318 21:09:04.147348 24729 solver.cpp:316] Iteration 9650 (3.86795 iter/s, 12.9268s/50 iter), loss = 0.0214349, remaining 0 hours and 10 minutes
I0318 21:09:04.147377 24729 solver.cpp:337]     Train net output #0: loss = 0.021435 (* 1 = 0.021435 loss)
I0318 21:09:04.147383 24729 sgd_solver.cpp:152] Iteration 9650, lr = 1e-06
I0318 21:09:17.092929 24729 solver.cpp:316] Iteration 9700 (3.86248 iter/s, 12.945s/50 iter), loss = 0.00474276, remaining 0 hours and 9 minutes
I0318 21:09:17.093102 24729 solver.cpp:337]     Train net output #0: loss = 0.00474287 (* 1 = 0.00474287 loss)
I0318 21:09:17.093111 24729 sgd_solver.cpp:152] Iteration 9700, lr = 1e-06
I0318 21:09:30.041590 24729 solver.cpp:316] Iteration 9750 (3.8616 iter/s, 12.948s/50 iter), loss = 0.00396481, remaining 0 hours and 9 minutes
I0318 21:09:30.041618 24729 solver.cpp:337]     Train net output #0: loss = 0.00396492 (* 1 = 0.00396492 loss)
I0318 21:09:30.041623 24729 sgd_solver.cpp:152] Iteration 9750, lr = 1e-06
I0318 21:09:42.982059 24729 solver.cpp:316] Iteration 9800 (3.86401 iter/s, 12.9399s/50 iter), loss = 0.0480195, remaining 0 hours and 9 minutes
I0318 21:09:42.982085 24729 solver.cpp:337]     Train net output #0: loss = 0.0480196 (* 1 = 0.0480196 loss)
I0318 21:09:42.982090 24729 sgd_solver.cpp:152] Iteration 9800, lr = 1e-06
I0318 21:09:55.908998 24729 solver.cpp:316] Iteration 9850 (3.86805 iter/s, 12.9264s/50 iter), loss = 0.0143797, remaining 0 hours and 9 minutes
I0318 21:09:55.909145 24729 solver.cpp:337]     Train net output #0: loss = 0.0143798 (* 1 = 0.0143798 loss)
I0318 21:09:55.909153 24729 sgd_solver.cpp:152] Iteration 9850, lr = 1e-06
I0318 21:10:08.866305 24729 solver.cpp:316] Iteration 9900 (3.85902 iter/s, 12.9567s/50 iter), loss = 0.0143424, remaining 0 hours and 9 minutes
I0318 21:10:08.866336 24729 solver.cpp:337]     Train net output #0: loss = 0.0143425 (* 1 = 0.0143425 loss)
I0318 21:10:08.866343 24729 sgd_solver.cpp:152] Iteration 9900, lr = 1e-06
I0318 21:10:21.840590 24729 solver.cpp:316] Iteration 9950 (3.85394 iter/s, 12.9737s/50 iter), loss = 0.00969651, remaining 0 hours and 8 minutes
I0318 21:10:21.840618 24729 solver.cpp:337]     Train net output #0: loss = 0.00969661 (* 1 = 0.00969661 loss)
I0318 21:10:21.840624 24729 sgd_solver.cpp:152] Iteration 9950, lr = 1e-06
I0318 21:10:34.511744 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_10000.caffemodel
I0318 21:10:36.834928 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_10000.solverstate
I0318 21:10:37.267014 24729 solver.cpp:470] Iteration 10000, Testing net (#0)
I0318 21:10:38.809381 24729 solver.cpp:569]     Test net output #0: accuracy = 0.954
I0318 21:10:38.809429 24729 solver.cpp:569]     Test net output #1: loss = 0.243927 (* 1 = 0.243927 loss)
I0318 21:10:38.809448 24729 solver.cpp:569]     Test net output #2: top-1 = 0.954
I0318 21:10:39.058465 24729 solver.cpp:316] Iteration 10000 (2.90408 iter/s, 17.2172s/50 iter), loss = 0.00402409, remaining 0 hours and 11 minutes
I0318 21:10:39.058493 24729 solver.cpp:337]     Train net output #0: loss = 0.0040242 (* 1 = 0.0040242 loss)
I0318 21:10:39.058501 24729 sgd_solver.cpp:152] Iteration 10000, lr = 1e-07
I0318 21:10:51.949877 24729 solver.cpp:316] Iteration 10050 (3.87871 iter/s, 12.8909s/50 iter), loss = 0.012655, remaining 0 hours and 8 minutes
I0318 21:10:51.949905 24729 solver.cpp:337]     Train net output #0: loss = 0.0126551 (* 1 = 0.0126551 loss)
I0318 21:10:51.949911 24729 sgd_solver.cpp:152] Iteration 10050, lr = 1e-07
I0318 21:11:04.875416 24729 solver.cpp:316] Iteration 10100 (3.86847 iter/s, 12.925s/50 iter), loss = 0.00389557, remaining 0 hours and 8 minutes
I0318 21:11:04.875567 24729 solver.cpp:337]     Train net output #0: loss = 0.00389568 (* 1 = 0.00389568 loss)
I0318 21:11:04.875574 24729 sgd_solver.cpp:152] Iteration 10100, lr = 1e-07
I0318 21:11:17.820364 24729 solver.cpp:316] Iteration 10150 (3.86271 iter/s, 12.9443s/50 iter), loss = 0.0113171, remaining 0 hours and 7 minutes
I0318 21:11:17.820394 24729 solver.cpp:337]     Train net output #0: loss = 0.0113172 (* 1 = 0.0113172 loss)
I0318 21:11:17.820399 24729 sgd_solver.cpp:152] Iteration 10150, lr = 1e-07
I0318 21:11:30.759951 24729 solver.cpp:316] Iteration 10200 (3.86427 iter/s, 12.9391s/50 iter), loss = 0.00490236, remaining 0 hours and 7 minutes
I0318 21:11:30.759979 24729 solver.cpp:337]     Train net output #0: loss = 0.00490246 (* 1 = 0.00490246 loss)
I0318 21:11:30.759985 24729 sgd_solver.cpp:152] Iteration 10200, lr = 1e-07
I0318 21:11:43.705158 24729 solver.cpp:316] Iteration 10250 (3.86259 iter/s, 12.9447s/50 iter), loss = 0.0145968, remaining 0 hours and 7 minutes
I0318 21:11:43.705323 24729 solver.cpp:337]     Train net output #0: loss = 0.0145969 (* 1 = 0.0145969 loss)
I0318 21:11:43.705332 24729 sgd_solver.cpp:152] Iteration 10250, lr = 1e-07
I0318 21:11:56.664948 24729 solver.cpp:316] Iteration 10300 (3.85829 iter/s, 12.9591s/50 iter), loss = 0.00221287, remaining 0 hours and 7 minutes
I0318 21:11:56.664976 24729 solver.cpp:337]     Train net output #0: loss = 0.00221296 (* 1 = 0.00221296 loss)
I0318 21:11:56.664983 24729 sgd_solver.cpp:152] Iteration 10300, lr = 1e-07
I0318 21:12:09.622205 24729 solver.cpp:316] Iteration 10350 (3.859 iter/s, 12.9567s/50 iter), loss = 0.00726611, remaining 0 hours and 6 minutes
I0318 21:12:09.622236 24729 solver.cpp:337]     Train net output #0: loss = 0.00726621 (* 1 = 0.00726621 loss)
I0318 21:12:09.622241 24729 sgd_solver.cpp:152] Iteration 10350, lr = 1e-07
I0318 21:12:22.559253 24729 solver.cpp:316] Iteration 10400 (3.86503 iter/s, 12.9365s/50 iter), loss = 0.0125671, remaining 0 hours and 6 minutes
I0318 21:12:22.559407 24729 solver.cpp:337]     Train net output #0: loss = 0.0125672 (* 1 = 0.0125672 loss)
I0318 21:12:22.559432 24729 sgd_solver.cpp:152] Iteration 10400, lr = 1e-07
I0318 21:12:35.490986 24729 solver.cpp:316] Iteration 10450 (3.86665 iter/s, 12.9311s/50 iter), loss = 0.00518914, remaining 0 hours and 6 minutes
I0318 21:12:35.491014 24729 solver.cpp:337]     Train net output #0: loss = 0.00518924 (* 1 = 0.00518924 loss)
I0318 21:12:35.491020 24729 sgd_solver.cpp:152] Iteration 10450, lr = 1e-07
I0318 21:12:48.179489 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_10500.caffemodel
I0318 21:12:50.525677 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_10500.solverstate
I0318 21:12:51.225232 24729 solver.cpp:316] Iteration 10500 (3.17791 iter/s, 15.7336s/50 iter), loss = 0.00259803, remaining 0 hours and 7 minutes
I0318 21:12:51.225263 24729 solver.cpp:337]     Train net output #0: loss = 0.00259813 (* 1 = 0.00259813 loss)
I0318 21:12:51.225270 24729 sgd_solver.cpp:152] Iteration 10500, lr = 1e-07
I0318 21:13:04.118811 24729 solver.cpp:316] Iteration 10550 (3.87806 iter/s, 12.893s/50 iter), loss = 0.0263548, remaining 0 hours and 6 minutes
I0318 21:13:04.118947 24729 solver.cpp:337]     Train net output #0: loss = 0.0263549 (* 1 = 0.0263549 loss)
I0318 21:13:04.118955 24729 sgd_solver.cpp:152] Iteration 10550, lr = 1e-07
I0318 21:13:17.070312 24729 solver.cpp:316] Iteration 10600 (3.86075 iter/s, 12.9509s/50 iter), loss = 0.000508543, remaining 0 hours and 5 minutes
I0318 21:13:17.070340 24729 solver.cpp:337]     Train net output #0: loss = 0.000508641 (* 1 = 0.000508641 loss)
I0318 21:13:17.070346 24729 sgd_solver.cpp:152] Iteration 10600, lr = 1e-07
I0318 21:13:29.998697 24729 solver.cpp:316] Iteration 10650 (3.86762 iter/s, 12.9279s/50 iter), loss = 0.000998916, remaining 0 hours and 5 minutes
I0318 21:13:29.998726 24729 solver.cpp:337]     Train net output #0: loss = 0.000999012 (* 1 = 0.000999012 loss)
I0318 21:13:29.998733 24729 sgd_solver.cpp:152] Iteration 10650, lr = 1e-07
I0318 21:13:42.931454 24729 solver.cpp:316] Iteration 10700 (3.86631 iter/s, 12.9322s/50 iter), loss = 0.00701126, remaining 0 hours and 5 minutes
I0318 21:13:42.931619 24729 solver.cpp:337]     Train net output #0: loss = 0.00701136 (* 1 = 0.00701136 loss)
I0318 21:13:42.931644 24729 sgd_solver.cpp:152] Iteration 10700, lr = 1e-07
I0318 21:13:55.876144 24729 solver.cpp:316] Iteration 10750 (3.86279 iter/s, 12.944s/50 iter), loss = 0.00985587, remaining 0 hours and 5 minutes
I0318 21:13:55.876174 24729 solver.cpp:337]     Train net output #0: loss = 0.00985596 (* 1 = 0.00985596 loss)
I0318 21:13:55.876181 24729 sgd_solver.cpp:152] Iteration 10750, lr = 1e-07
I0318 21:14:08.820696 24729 solver.cpp:316] Iteration 10800 (3.86279 iter/s, 12.944s/50 iter), loss = 0.0100273, remaining 0 hours and 5 minutes
I0318 21:14:08.820725 24729 solver.cpp:337]     Train net output #0: loss = 0.0100274 (* 1 = 0.0100274 loss)
I0318 21:14:08.820730 24729 sgd_solver.cpp:152] Iteration 10800, lr = 1e-07
I0318 21:14:21.759042 24729 solver.cpp:316] Iteration 10850 (3.86464 iter/s, 12.9378s/50 iter), loss = 0.00825906, remaining 0 hours and 4 minutes
I0318 21:14:21.760824 24729 solver.cpp:337]     Train net output #0: loss = 0.00825915 (* 1 = 0.00825915 loss)
I0318 21:14:21.760836 24729 sgd_solver.cpp:152] Iteration 10850, lr = 1e-07
I0318 21:14:34.699578 24729 solver.cpp:316] Iteration 10900 (3.8645 iter/s, 12.9383s/50 iter), loss = 0.00669735, remaining 0 hours and 4 minutes
I0318 21:14:34.699605 24729 solver.cpp:337]     Train net output #0: loss = 0.00669744 (* 1 = 0.00669744 loss)
I0318 21:14:34.699612 24729 sgd_solver.cpp:152] Iteration 10900, lr = 1e-07
I0318 21:14:47.659992 24729 solver.cpp:316] Iteration 10950 (3.85806 iter/s, 12.9599s/50 iter), loss = 0.0103355, remaining 0 hours and 4 minutes
I0318 21:14:47.660022 24729 solver.cpp:337]     Train net output #0: loss = 0.0103356 (* 1 = 0.0103356 loss)
I0318 21:14:47.660027 24729 sgd_solver.cpp:152] Iteration 10950, lr = 1e-07
I0318 21:15:00.346571 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_11000.caffemodel
I0318 21:15:02.659276 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_11000.solverstate
I0318 21:15:03.084487 24729 solver.cpp:470] Iteration 11000, Testing net (#0)
I0318 21:15:04.549475 24729 solver.cpp:569]     Test net output #0: accuracy = 0.95425
I0318 21:15:04.549500 24729 solver.cpp:569]     Test net output #1: loss = 0.250781 (* 1 = 0.250781 loss)
I0318 21:15:04.549504 24729 solver.cpp:569]     Test net output #2: top-1 = 0.95425
I0318 21:15:04.796589 24729 solver.cpp:316] Iteration 11000 (2.91785 iter/s, 17.1359s/50 iter), loss = 0.0190165, remaining 0 hours and 5 minutes
I0318 21:15:04.796615 24729 solver.cpp:337]     Train net output #0: loss = 0.0190166 (* 1 = 0.0190166 loss)
I0318 21:15:04.796623 24729 sgd_solver.cpp:152] Iteration 11000, lr = 1e-07
I0318 21:15:17.713235 24729 solver.cpp:316] Iteration 11050 (3.87113 iter/s, 12.9161s/50 iter), loss = 0.0226318, remaining 0 hours and 3 minutes
I0318 21:15:17.713263 24729 solver.cpp:337]     Train net output #0: loss = 0.0226319 (* 1 = 0.0226319 loss)
I0318 21:15:17.713269 24729 sgd_solver.cpp:152] Iteration 11050, lr = 1e-07
I0318 21:15:30.632644 24729 solver.cpp:316] Iteration 11100 (3.87031 iter/s, 12.9189s/50 iter), loss = 0.00435487, remaining 0 hours and 3 minutes
I0318 21:15:30.632781 24729 solver.cpp:337]     Train net output #0: loss = 0.00435495 (* 1 = 0.00435495 loss)
I0318 21:15:30.632788 24729 sgd_solver.cpp:152] Iteration 11100, lr = 1e-07
I0318 21:15:43.567948 24729 solver.cpp:316] Iteration 11150 (3.86558 iter/s, 12.9347s/50 iter), loss = 0.00868953, remaining 0 hours and 3 minutes
I0318 21:15:43.567977 24729 solver.cpp:337]     Train net output #0: loss = 0.00868962 (* 1 = 0.00868962 loss)
I0318 21:15:43.567983 24729 sgd_solver.cpp:152] Iteration 11150, lr = 1e-07
I0318 21:15:56.492609 24729 solver.cpp:316] Iteration 11200 (3.86873 iter/s, 12.9241s/50 iter), loss = 0.0240829, remaining 0 hours and 3 minutes
I0318 21:15:56.492637 24729 solver.cpp:337]     Train net output #0: loss = 0.024083 (* 1 = 0.024083 loss)
I0318 21:15:56.492645 24729 sgd_solver.cpp:152] Iteration 11200, lr = 1e-07
I0318 21:16:09.441102 24729 solver.cpp:316] Iteration 11250 (3.86161 iter/s, 12.948s/50 iter), loss = 0.0182071, remaining 0 hours and 3 minutes
I0318 21:16:09.441262 24729 solver.cpp:337]     Train net output #0: loss = 0.0182072 (* 1 = 0.0182072 loss)
I0318 21:16:09.441272 24729 sgd_solver.cpp:152] Iteration 11250, lr = 1e-07
I0318 21:16:22.405323 24729 solver.cpp:316] Iteration 11300 (3.85697 iter/s, 12.9636s/50 iter), loss = 0.00243724, remaining 0 hours and 2 minutes
I0318 21:16:22.405354 24729 solver.cpp:337]     Train net output #0: loss = 0.00243734 (* 1 = 0.00243734 loss)
I0318 21:16:22.405361 24729 sgd_solver.cpp:152] Iteration 11300, lr = 1e-07
I0318 21:16:35.333297 24729 solver.cpp:316] Iteration 11350 (3.86774 iter/s, 12.9274s/50 iter), loss = 0.0156946, remaining 0 hours and 2 minutes
I0318 21:16:35.333328 24729 solver.cpp:337]     Train net output #0: loss = 0.0156947 (* 1 = 0.0156947 loss)
I0318 21:16:35.333335 24729 sgd_solver.cpp:152] Iteration 11350, lr = 1e-07
I0318 21:16:48.299492 24729 solver.cpp:316] Iteration 11400 (3.85634 iter/s, 12.9657s/50 iter), loss = 0.00135334, remaining 0 hours and 2 minutes
I0318 21:16:48.299635 24729 solver.cpp:337]     Train net output #0: loss = 0.00135344 (* 1 = 0.00135344 loss)
I0318 21:16:48.299645 24729 sgd_solver.cpp:152] Iteration 11400, lr = 1e-07
I0318 21:17:01.256922 24729 solver.cpp:316] Iteration 11450 (3.85898 iter/s, 12.9568s/50 iter), loss = 0.0109496, remaining 0 hours and 2 minutes
I0318 21:17:01.256947 24729 solver.cpp:337]     Train net output #0: loss = 0.0109497 (* 1 = 0.0109497 loss)
I0318 21:17:01.256953 24729 sgd_solver.cpp:152] Iteration 11450, lr = 1e-07
I0318 21:17:13.946687 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_11500.caffemodel
I0318 21:17:16.260581 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_11500.solverstate
I0318 21:17:16.943019 24729 solver.cpp:316] Iteration 11500 (3.18767 iter/s, 15.6855s/50 iter), loss = 0.00169444, remaining 0 hours and 2 minutes
I0318 21:17:16.943048 24729 solver.cpp:337]     Train net output #0: loss = 0.00169455 (* 1 = 0.00169455 loss)
I0318 21:17:16.943054 24729 sgd_solver.cpp:152] Iteration 11500, lr = 1e-07
I0318 21:17:29.812111 24729 solver.cpp:316] Iteration 11550 (3.88544 iter/s, 12.8686s/50 iter), loss = 0.00511632, remaining 0 hours and 1 minutes
I0318 21:17:29.812258 24729 solver.cpp:337]     Train net output #0: loss = 0.00511643 (* 1 = 0.00511643 loss)
I0318 21:17:29.812266 24729 sgd_solver.cpp:152] Iteration 11550, lr = 1e-07
I0318 21:17:42.739087 24729 solver.cpp:316] Iteration 11600 (3.86808 iter/s, 12.9263s/50 iter), loss = 0.0150795, remaining 0 hours and 1 minutes
I0318 21:17:42.739114 24729 solver.cpp:337]     Train net output #0: loss = 0.0150796 (* 1 = 0.0150796 loss)
I0318 21:17:42.739120 24729 sgd_solver.cpp:152] Iteration 11600, lr = 1e-07
I0318 21:17:55.688942 24729 solver.cpp:316] Iteration 11650 (3.86121 iter/s, 12.9493s/50 iter), loss = 0.0158929, remaining 0 hours and 1 minutes
I0318 21:17:55.688971 24729 solver.cpp:337]     Train net output #0: loss = 0.015893 (* 1 = 0.015893 loss)
I0318 21:17:55.688977 24729 sgd_solver.cpp:152] Iteration 11650, lr = 1e-07
I0318 21:18:08.639324 24729 solver.cpp:316] Iteration 11700 (3.86105 iter/s, 12.9498s/50 iter), loss = 0.00265551, remaining 0 hours and 1 minutes
I0318 21:18:08.639461 24729 solver.cpp:337]     Train net output #0: loss = 0.0026556 (* 1 = 0.0026556 loss)
I0318 21:18:08.639469 24729 sgd_solver.cpp:152] Iteration 11700, lr = 1e-07
I0318 21:18:21.597033 24729 solver.cpp:316] Iteration 11750 (3.8589 iter/s, 12.9571s/50 iter), loss = 0.00237095, remaining 0 hours and 1 minutes
I0318 21:18:21.597061 24729 solver.cpp:337]     Train net output #0: loss = 0.00237105 (* 1 = 0.00237105 loss)
I0318 21:18:21.597067 24729 sgd_solver.cpp:152] Iteration 11750, lr = 1e-07
I0318 21:18:34.555346 24729 solver.cpp:316] Iteration 11800 (3.85869 iter/s, 12.9578s/50 iter), loss = 0.0200984, remaining 0 hours and 0 minutes
I0318 21:18:34.555375 24729 solver.cpp:337]     Train net output #0: loss = 0.0200985 (* 1 = 0.0200985 loss)
I0318 21:18:34.555382 24729 sgd_solver.cpp:152] Iteration 11800, lr = 1e-07
I0318 21:18:47.522125 24729 solver.cpp:316] Iteration 11850 (3.85617 iter/s, 12.9662s/50 iter), loss = 0.00124189, remaining 0 hours and 0 minutes
I0318 21:18:47.522306 24729 solver.cpp:337]     Train net output #0: loss = 0.00124199 (* 1 = 0.00124199 loss)
I0318 21:18:47.522315 24729 sgd_solver.cpp:152] Iteration 11850, lr = 1e-07
I0318 21:19:00.472342 24729 solver.cpp:316] Iteration 11900 (3.86114 iter/s, 12.9495s/50 iter), loss = 0.0067101, remaining 0 hours and 0 minutes
I0318 21:19:00.472369 24729 solver.cpp:337]     Train net output #0: loss = 0.00671019 (* 1 = 0.00671019 loss)
I0318 21:19:00.472376 24729 sgd_solver.cpp:152] Iteration 11900, lr = 1e-07
I0318 21:19:13.425416 24729 solver.cpp:316] Iteration 11950 (3.86025 iter/s, 12.9525s/50 iter), loss = 0.00566625, remaining 0 hours and 0 minutes
I0318 21:19:13.425443 24729 solver.cpp:337]     Train net output #0: loss = 0.00566634 (* 1 = 0.00566634 loss)
I0318 21:19:13.425449 24729 sgd_solver.cpp:152] Iteration 11950, lr = 1e-07
I0318 21:19:26.120352 24729 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_12000.caffemodel
I0318 21:19:28.424643 24729 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_12000.solverstate
I0318 21:19:28.949075 24729 solver.cpp:430] Iteration 12000, loss = 0.0042858
I0318 21:19:28.949098 24729 solver.cpp:470] Iteration 12000, Testing net (#0)
I0318 21:19:30.445291 24729 solver.cpp:569]     Test net output #0: accuracy = 0.954
I0318 21:19:30.445317 24729 solver.cpp:569]     Test net output #1: loss = 0.253602 (* 1 = 0.253602 loss)
I0318 21:19:30.445319 24729 solver.cpp:569]     Test net output #2: top-1 = 0.954
I0318 21:19:30.445323 24729 solver.cpp:438] Optimization Done (3.78274 iter/s).
I0318 21:19:30.445341 24729 caffe_interface.cpp:576] Optimization Done.
