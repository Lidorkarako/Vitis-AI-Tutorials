##
##* Â© Copyright (C) 2016-2020 Xilinx, Inc
##*
##* Licensed under the Apache License, Version 2.0 (the "License"). You may
##* not use this file except in compliance with the License. A copy of the
##* License is located at
##*
##*     http://www.apache.org/licenses/LICENSE-2.0
##*
##* Unless required by applicable law or agreed to in writing, software
##* distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
##* WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
##* License for the specific language governing permissions and limitations
##* under the License.
##*/

W0318 22:13:47.461159 27880 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 3, it will be converted to NVCaffe Format.
W0318 22:13:47.464138 27880 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 7, it will be converted to NVCaffe Format.
W0318 22:13:47.464184 27880 utils.cpp:207] BVLC BatchNormLayer without ScaleLayer detected: 21, it will be converted to NVCaffe Format.
I0318 22:13:47.468842 27880 decent_p.cpp:296] pruning/alexnetBNnoLRN/regular_rate_0.5/net_finetune.prototxt
I0318 22:13:47.579536 27880 gpu_memory.cpp:99] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0318 22:13:47.580274 27880 gpu_memory.cpp:101] Total memory: 25620447232, Free: 24555552768, dev_info[0]: total=25620447232 free=24555552768
I0318 22:13:47.580284 27880 caffe_interface.cpp:539] Using GPUs 0
I0318 22:13:47.580518 27880 caffe_interface.cpp:544] GPU 0: Quadro P6000
I0318 22:13:48.423099 27880 solver.cpp:97] Initializing solver from parameters:
test_iter: 80
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 12000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 500
snapshot_prefix: "pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/"
solver_mode: GPU
device_id: 0
random_seed: 1201
net: "pruning/alexnetBNnoLRN/regular_rate_0.5/net_finetune.prototxt"
type: "Adam"
I0318 22:13:48.423204 27880 solver.cpp:145] Creating training net from net file: pruning/alexnetBNnoLRN/regular_rate_0.5/net_finetune.prototxt
I0318 22:13:48.423394 27880 net.cpp:369] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0318 22:13:48.423403 27880 net.cpp:369] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0318 22:13:48.423406 27880 net.cpp:369] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0318 22:13:48.423537 27880 net.cpp:98] Initializing net from parameters:
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0318 22:13:48.423594 27880 layer_factory.hpp:123] Creating layer data
I0318 22:13:48.423686 27880 internal_thread.cpp:73] Starting internal thread(s) on GPU 0
I0318 22:13:48.424144 27880 net.cpp:140] Creating Layer data
I0318 22:13:48.424154 27880 net.cpp:455] data -> data
I0318 22:13:48.424163 27880 net.cpp:455] data -> label
I0318 22:13:48.426380 27919 db_lmdb.cpp:81] Opened lmdb input/lmdb/train_lmdb
I0318 22:13:48.426426 27919 data_reader.cpp:166] TRAIN: reading data using 1 channel(s)
I0318 22:13:48.426745 27880 data_layer.cpp:124] ReshapePrefetch 256, 3, 227, 227
I0318 22:13:48.426803 27880 data_layer.cpp:129] output data size: 256,3,227,227
I0318 22:13:48.805269 27880 internal_thread.cpp:73] Starting internal thread(s) on GPU 0
I0318 22:13:48.805330 27880 net.cpp:190] Setting up data
I0318 22:13:48.805337 27880 net.cpp:197] Top shape: 256 3 227 227 (39574272)
I0318 22:13:48.805341 27880 net.cpp:197] Top shape: 256 (256)
I0318 22:13:48.805342 27880 net.cpp:205] Memory required for data: 158298112
I0318 22:13:48.805349 27880 layer_factory.hpp:123] Creating layer conv1
I0318 22:13:48.805361 27880 net.cpp:140] Creating Layer conv1
I0318 22:13:48.805363 27880 net.cpp:481] conv1 <- data
I0318 22:13:48.805377 27880 net.cpp:455] conv1 -> conv1
I0318 22:13:48.805974 27880 net.cpp:190] Setting up conv1
I0318 22:13:48.805980 27880 net.cpp:197] Top shape: 256 96 55 55 (74342400)
I0318 22:13:48.805984 27880 net.cpp:205] Memory required for data: 455667712
I0318 22:13:48.805996 27880 layer_factory.hpp:123] Creating layer bn1
I0318 22:13:48.806006 27880 net.cpp:140] Creating Layer bn1
I0318 22:13:48.806008 27880 net.cpp:481] bn1 <- conv1
I0318 22:13:48.806012 27880 net.cpp:455] bn1 -> bn1
I0318 22:13:48.806468 27880 net.cpp:190] Setting up bn1
I0318 22:13:48.806474 27880 net.cpp:197] Top shape: 256 96 55 55 (74342400)
I0318 22:13:48.806478 27880 net.cpp:205] Memory required for data: 753037312
I0318 22:13:48.806489 27880 layer_factory.hpp:123] Creating layer relu1
I0318 22:13:48.806497 27880 net.cpp:140] Creating Layer relu1
I0318 22:13:48.806500 27880 net.cpp:481] relu1 <- bn1
I0318 22:13:48.806504 27880 net.cpp:455] relu1 -> relu1
I0318 22:13:48.806526 27880 net.cpp:190] Setting up relu1
I0318 22:13:48.806531 27880 net.cpp:197] Top shape: 256 96 55 55 (74342400)
I0318 22:13:48.806535 27880 net.cpp:205] Memory required for data: 1050406912
I0318 22:13:48.806536 27880 layer_factory.hpp:123] Creating layer pool1
I0318 22:13:48.806542 27880 net.cpp:140] Creating Layer pool1
I0318 22:13:48.806545 27880 net.cpp:481] pool1 <- relu1
I0318 22:13:48.806550 27880 net.cpp:455] pool1 -> pool1
I0318 22:13:48.806571 27880 net.cpp:190] Setting up pool1
I0318 22:13:48.806576 27880 net.cpp:197] Top shape: 256 96 27 27 (17915904)
I0318 22:13:48.806578 27880 net.cpp:205] Memory required for data: 1122070528
I0318 22:13:48.806581 27880 layer_factory.hpp:123] Creating layer conv2
I0318 22:13:48.806587 27880 net.cpp:140] Creating Layer conv2
I0318 22:13:48.806591 27880 net.cpp:481] conv2 <- pool1
I0318 22:13:48.806594 27880 net.cpp:455] conv2 -> conv2
I0318 22:13:48.821862 27880 net.cpp:190] Setting up conv2
I0318 22:13:48.821879 27880 net.cpp:197] Top shape: 256 256 27 27 (47775744)
I0318 22:13:48.821882 27880 net.cpp:205] Memory required for data: 1313173504
I0318 22:13:48.821890 27880 layer_factory.hpp:123] Creating layer bn2
I0318 22:13:48.821988 27880 net.cpp:140] Creating Layer bn2
I0318 22:13:48.821993 27880 net.cpp:481] bn2 <- conv2
I0318 22:13:48.822043 27880 net.cpp:455] bn2 -> bn2
I0318 22:13:48.822582 27880 net.cpp:190] Setting up bn2
I0318 22:13:48.822592 27880 net.cpp:197] Top shape: 256 256 27 27 (47775744)
I0318 22:13:48.822593 27880 net.cpp:205] Memory required for data: 1504276480
I0318 22:13:48.822600 27880 layer_factory.hpp:123] Creating layer relu2
I0318 22:13:48.822607 27880 net.cpp:140] Creating Layer relu2
I0318 22:13:48.822612 27880 net.cpp:481] relu2 <- bn2
I0318 22:13:48.822615 27880 net.cpp:455] relu2 -> relu2
I0318 22:13:48.822633 27880 net.cpp:190] Setting up relu2
I0318 22:13:48.822639 27880 net.cpp:197] Top shape: 256 256 27 27 (47775744)
I0318 22:13:48.822643 27880 net.cpp:205] Memory required for data: 1695379456
I0318 22:13:48.822645 27880 layer_factory.hpp:123] Creating layer pool2
I0318 22:13:48.822654 27880 net.cpp:140] Creating Layer pool2
I0318 22:13:48.822662 27880 net.cpp:481] pool2 <- relu2
I0318 22:13:48.822669 27880 net.cpp:455] pool2 -> pool2
I0318 22:13:48.822695 27880 net.cpp:190] Setting up pool2
I0318 22:13:48.822701 27880 net.cpp:197] Top shape: 256 256 13 13 (11075584)
I0318 22:13:48.822705 27880 net.cpp:205] Memory required for data: 1739681792
I0318 22:13:48.822707 27880 layer_factory.hpp:123] Creating layer conv3
I0318 22:13:48.822716 27880 net.cpp:140] Creating Layer conv3
I0318 22:13:48.822736 27880 net.cpp:481] conv3 <- pool2
I0318 22:13:48.822739 27880 net.cpp:455] conv3 -> conv3
I0318 22:13:48.835145 27880 net.cpp:190] Setting up conv3
I0318 22:13:48.835168 27880 net.cpp:197] Top shape: 256 384 13 13 (16613376)
I0318 22:13:48.835171 27880 net.cpp:205] Memory required for data: 1806135296
I0318 22:13:48.835178 27880 layer_factory.hpp:123] Creating layer relu3
I0318 22:13:48.835189 27880 net.cpp:140] Creating Layer relu3
I0318 22:13:48.835192 27880 net.cpp:481] relu3 <- conv3
I0318 22:13:48.835198 27880 net.cpp:455] relu3 -> relu3
I0318 22:13:48.835224 27880 net.cpp:190] Setting up relu3
I0318 22:13:48.835232 27880 net.cpp:197] Top shape: 256 384 13 13 (16613376)
I0318 22:13:48.835233 27880 net.cpp:205] Memory required for data: 1872588800
I0318 22:13:48.835235 27880 layer_factory.hpp:123] Creating layer conv4
I0318 22:13:48.835247 27880 net.cpp:140] Creating Layer conv4
I0318 22:13:48.835252 27880 net.cpp:481] conv4 <- relu3
I0318 22:13:48.835255 27880 net.cpp:455] conv4 -> conv4
I0318 22:13:48.853279 27880 net.cpp:190] Setting up conv4
I0318 22:13:48.853300 27880 net.cpp:197] Top shape: 256 384 13 13 (16613376)
I0318 22:13:48.853303 27880 net.cpp:205] Memory required for data: 1939042304
I0318 22:13:48.853315 27880 layer_factory.hpp:123] Creating layer relu4
I0318 22:13:48.853323 27880 net.cpp:140] Creating Layer relu4
I0318 22:13:48.853327 27880 net.cpp:481] relu4 <- conv4
I0318 22:13:48.853333 27880 net.cpp:455] relu4 -> relu4
I0318 22:13:48.853355 27880 net.cpp:190] Setting up relu4
I0318 22:13:48.853360 27880 net.cpp:197] Top shape: 256 384 13 13 (16613376)
I0318 22:13:48.853363 27880 net.cpp:205] Memory required for data: 2005495808
I0318 22:13:48.853366 27880 layer_factory.hpp:123] Creating layer conv5
I0318 22:13:48.853375 27880 net.cpp:140] Creating Layer conv5
I0318 22:13:48.853379 27880 net.cpp:481] conv5 <- relu4
I0318 22:13:48.853384 27880 net.cpp:455] conv5 -> conv5
I0318 22:13:48.871716 27880 net.cpp:190] Setting up conv5
I0318 22:13:48.871739 27880 net.cpp:197] Top shape: 256 256 13 13 (11075584)
I0318 22:13:48.871742 27880 net.cpp:205] Memory required for data: 2049798144
I0318 22:13:48.871749 27880 layer_factory.hpp:123] Creating layer relu5
I0318 22:13:48.871758 27880 net.cpp:140] Creating Layer relu5
I0318 22:13:48.871762 27880 net.cpp:481] relu5 <- conv5
I0318 22:13:48.871768 27880 net.cpp:455] relu5 -> relu5
I0318 22:13:48.871793 27880 net.cpp:190] Setting up relu5
I0318 22:13:48.871799 27880 net.cpp:197] Top shape: 256 256 13 13 (11075584)
I0318 22:13:48.871801 27880 net.cpp:205] Memory required for data: 2094100480
I0318 22:13:48.871803 27880 layer_factory.hpp:123] Creating layer pool5
I0318 22:13:48.871810 27880 net.cpp:140] Creating Layer pool5
I0318 22:13:48.871814 27880 net.cpp:481] pool5 <- relu5
I0318 22:13:48.871817 27880 net.cpp:455] pool5 -> pool5
I0318 22:13:48.871845 27880 net.cpp:190] Setting up pool5
I0318 22:13:48.871851 27880 net.cpp:197] Top shape: 256 256 6 6 (2359296)
I0318 22:13:48.871855 27880 net.cpp:205] Memory required for data: 2103537664
I0318 22:13:48.871856 27880 layer_factory.hpp:123] Creating layer fc6
I0318 22:13:48.871866 27880 net.cpp:140] Creating Layer fc6
I0318 22:13:48.871868 27880 net.cpp:481] fc6 <- pool5
I0318 22:13:48.871873 27880 net.cpp:455] fc6 -> fc6
I0318 22:13:49.212908 27880 net.cpp:190] Setting up fc6
I0318 22:13:49.212931 27880 net.cpp:197] Top shape: 256 4096 (1048576)
I0318 22:13:49.212934 27880 net.cpp:205] Memory required for data: 2107731968
I0318 22:13:49.212939 27880 layer_factory.hpp:123] Creating layer relu6
I0318 22:13:49.212947 27880 net.cpp:140] Creating Layer relu6
I0318 22:13:49.212950 27880 net.cpp:481] relu6 <- fc6
I0318 22:13:49.212955 27880 net.cpp:455] relu6 -> relu6
I0318 22:13:49.212970 27880 net.cpp:190] Setting up relu6
I0318 22:13:49.212973 27880 net.cpp:197] Top shape: 256 4096 (1048576)
I0318 22:13:49.212975 27880 net.cpp:205] Memory required for data: 2111926272
I0318 22:13:49.212976 27880 layer_factory.hpp:123] Creating layer drop6
I0318 22:13:49.212981 27880 net.cpp:140] Creating Layer drop6
I0318 22:13:49.213019 27880 net.cpp:481] drop6 <- relu6
I0318 22:13:49.213023 27880 net.cpp:455] drop6 -> drop6
I0318 22:13:49.213042 27880 net.cpp:190] Setting up drop6
I0318 22:13:49.213047 27880 net.cpp:197] Top shape: 256 4096 (1048576)
I0318 22:13:49.213048 27880 net.cpp:205] Memory required for data: 2116120576
I0318 22:13:49.213052 27880 layer_factory.hpp:123] Creating layer fc7
I0318 22:13:49.213063 27880 net.cpp:140] Creating Layer fc7
I0318 22:13:49.213066 27880 net.cpp:481] fc7 <- drop6
I0318 22:13:49.213070 27880 net.cpp:455] fc7 -> fc7
I0318 22:13:49.351219 27880 net.cpp:190] Setting up fc7
I0318 22:13:49.351243 27880 net.cpp:197] Top shape: 256 4096 (1048576)
I0318 22:13:49.351246 27880 net.cpp:205] Memory required for data: 2120314880
I0318 22:13:49.351253 27880 layer_factory.hpp:123] Creating layer bn7
I0318 22:13:49.351261 27880 net.cpp:140] Creating Layer bn7
I0318 22:13:49.351264 27880 net.cpp:481] bn7 <- fc7
I0318 22:13:49.351269 27880 net.cpp:455] bn7 -> bn7
I0318 22:13:49.351675 27880 net.cpp:190] Setting up bn7
I0318 22:13:49.351680 27880 net.cpp:197] Top shape: 256 4096 (1048576)
I0318 22:13:49.351682 27880 net.cpp:205] Memory required for data: 2124509184
I0318 22:13:49.351688 27880 layer_factory.hpp:123] Creating layer relu7
I0318 22:13:49.351692 27880 net.cpp:140] Creating Layer relu7
I0318 22:13:49.351696 27880 net.cpp:481] relu7 <- bn7
I0318 22:13:49.351699 27880 net.cpp:455] relu7 -> relu7
I0318 22:13:49.351714 27880 net.cpp:190] Setting up relu7
I0318 22:13:49.351718 27880 net.cpp:197] Top shape: 256 4096 (1048576)
I0318 22:13:49.351720 27880 net.cpp:205] Memory required for data: 2128703488
I0318 22:13:49.351722 27880 layer_factory.hpp:123] Creating layer drop7
I0318 22:13:49.351727 27880 net.cpp:140] Creating Layer drop7
I0318 22:13:49.351728 27880 net.cpp:481] drop7 <- relu7
I0318 22:13:49.351732 27880 net.cpp:455] drop7 -> drop7
I0318 22:13:49.351752 27880 net.cpp:190] Setting up drop7
I0318 22:13:49.351756 27880 net.cpp:197] Top shape: 256 4096 (1048576)
I0318 22:13:49.351758 27880 net.cpp:205] Memory required for data: 2132897792
I0318 22:13:49.351760 27880 layer_factory.hpp:123] Creating layer fc8
I0318 22:13:49.351765 27880 net.cpp:140] Creating Layer fc8
I0318 22:13:49.351768 27880 net.cpp:481] fc8 <- drop7
I0318 22:13:49.351773 27880 net.cpp:455] fc8 -> fc8
I0318 22:13:49.351897 27880 net.cpp:190] Setting up fc8
I0318 22:13:49.351900 27880 net.cpp:197] Top shape: 256 2 (512)
I0318 22:13:49.351903 27880 net.cpp:205] Memory required for data: 2132899840
I0318 22:13:49.351907 27880 layer_factory.hpp:123] Creating layer loss
I0318 22:13:49.351909 27880 net.cpp:140] Creating Layer loss
I0318 22:13:49.351912 27880 net.cpp:481] loss <- fc8
I0318 22:13:49.351915 27880 net.cpp:481] loss <- label
I0318 22:13:49.351919 27880 net.cpp:455] loss -> loss
I0318 22:13:49.351924 27880 layer_factory.hpp:123] Creating layer loss
I0318 22:13:49.351966 27880 net.cpp:190] Setting up loss
I0318 22:13:49.351971 27880 net.cpp:197] Top shape: (1)
I0318 22:13:49.351974 27880 net.cpp:200]     with loss weight 1
I0318 22:13:49.351982 27880 net.cpp:205] Memory required for data: 2132899844
I0318 22:13:49.351984 27880 net.cpp:266] loss needs backward computation.
I0318 22:13:49.351987 27880 net.cpp:266] fc8 needs backward computation.
I0318 22:13:49.351989 27880 net.cpp:266] drop7 needs backward computation.
I0318 22:13:49.351991 27880 net.cpp:266] relu7 needs backward computation.
I0318 22:13:49.351994 27880 net.cpp:266] bn7 needs backward computation.
I0318 22:13:49.351996 27880 net.cpp:266] fc7 needs backward computation.
I0318 22:13:49.351999 27880 net.cpp:266] drop6 needs backward computation.
I0318 22:13:49.352001 27880 net.cpp:266] relu6 needs backward computation.
I0318 22:13:49.352003 27880 net.cpp:266] fc6 needs backward computation.
I0318 22:13:49.352006 27880 net.cpp:266] pool5 needs backward computation.
I0318 22:13:49.352008 27880 net.cpp:266] relu5 needs backward computation.
I0318 22:13:49.352011 27880 net.cpp:266] conv5 needs backward computation.
I0318 22:13:49.352013 27880 net.cpp:266] relu4 needs backward computation.
I0318 22:13:49.352028 27880 net.cpp:266] conv4 needs backward computation.
I0318 22:13:49.352030 27880 net.cpp:266] relu3 needs backward computation.
I0318 22:13:49.352033 27880 net.cpp:266] conv3 needs backward computation.
I0318 22:13:49.352035 27880 net.cpp:266] pool2 needs backward computation.
I0318 22:13:49.352037 27880 net.cpp:266] relu2 needs backward computation.
I0318 22:13:49.352041 27880 net.cpp:266] bn2 needs backward computation.
I0318 22:13:49.352046 27880 net.cpp:266] conv2 needs backward computation.
I0318 22:13:49.352047 27880 net.cpp:266] pool1 needs backward computation.
I0318 22:13:49.352051 27880 net.cpp:266] relu1 needs backward computation.
I0318 22:13:49.352052 27880 net.cpp:266] bn1 needs backward computation.
I0318 22:13:49.352056 27880 net.cpp:266] conv1 needs backward computation.
I0318 22:13:49.352057 27880 net.cpp:268] data does not need backward computation.
I0318 22:13:49.352061 27880 net.cpp:310] This network produces output loss
I0318 22:13:49.352075 27880 net.cpp:330] Network initialization done.
I0318 22:13:49.352291 27880 solver.cpp:235] Creating test net (#0) specified by net file: pruning/alexnetBNnoLRN/regular_rate_0.5/net_finetune.prototxt
I0318 22:13:49.352313 27880 net.cpp:369] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0318 22:13:49.352435 27880 net.cpp:98] Initializing net from parameters:
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0318 22:13:49.352514 27880 layer_factory.hpp:123] Creating layer data
I0318 22:13:49.352546 27880 internal_thread.cpp:73] Starting internal thread(s) on GPU 0
I0318 22:13:49.352990 27880 net.cpp:140] Creating Layer data
I0318 22:13:49.353000 27880 net.cpp:455] data -> data
I0318 22:13:49.353009 27880 net.cpp:455] data -> label
I0318 22:13:49.355551 27951 db_lmdb.cpp:81] Opened lmdb input/lmdb/valid_lmdb
I0318 22:13:49.355585 27951 data_reader.cpp:166] TEST: reading data using 1 channel(s)
I0318 22:13:49.355907 27880 data_layer.cpp:124] ReshapePrefetch 50, 3, 227, 227
I0318 22:13:49.355985 27880 data_layer.cpp:129] output data size: 50,3,227,227
I0318 22:13:49.433023 27880 internal_thread.cpp:73] Starting internal thread(s) on GPU 0
I0318 22:13:49.433070 27880 net.cpp:190] Setting up data
I0318 22:13:49.433094 27880 net.cpp:197] Top shape: 50 3 227 227 (7729350)
I0318 22:13:49.433096 27880 net.cpp:197] Top shape: 50 (50)
I0318 22:13:49.433099 27880 net.cpp:205] Memory required for data: 30917600
I0318 22:13:49.433102 27880 layer_factory.hpp:123] Creating layer label_data_1_split
I0318 22:13:49.433111 27880 net.cpp:140] Creating Layer label_data_1_split
I0318 22:13:49.433135 27880 net.cpp:481] label_data_1_split <- label
I0318 22:13:49.433140 27880 net.cpp:455] label_data_1_split -> label_data_1_split_0
I0318 22:13:49.433147 27880 net.cpp:455] label_data_1_split -> label_data_1_split_1
I0318 22:13:49.433152 27880 net.cpp:455] label_data_1_split -> label_data_1_split_2
I0318 22:13:49.433204 27880 net.cpp:190] Setting up label_data_1_split
I0318 22:13:49.433209 27880 net.cpp:197] Top shape: 50 (50)
I0318 22:13:49.433212 27880 net.cpp:197] Top shape: 50 (50)
I0318 22:13:49.433218 27880 net.cpp:197] Top shape: 50 (50)
I0318 22:13:49.433220 27880 net.cpp:205] Memory required for data: 30918200
I0318 22:13:49.433223 27880 layer_factory.hpp:123] Creating layer conv1
I0318 22:13:49.433230 27880 net.cpp:140] Creating Layer conv1
I0318 22:13:49.433234 27880 net.cpp:481] conv1 <- data
I0318 22:13:49.433238 27880 net.cpp:455] conv1 -> conv1
I0318 22:13:49.433708 27880 net.cpp:190] Setting up conv1
I0318 22:13:49.433714 27880 net.cpp:197] Top shape: 50 96 55 55 (14520000)
I0318 22:13:49.433717 27880 net.cpp:205] Memory required for data: 88998200
I0318 22:13:49.433725 27880 layer_factory.hpp:123] Creating layer bn1
I0318 22:13:49.433730 27880 net.cpp:140] Creating Layer bn1
I0318 22:13:49.433732 27880 net.cpp:481] bn1 <- conv1
I0318 22:13:49.433737 27880 net.cpp:455] bn1 -> bn1
I0318 22:13:49.434154 27880 net.cpp:190] Setting up bn1
I0318 22:13:49.434159 27880 net.cpp:197] Top shape: 50 96 55 55 (14520000)
I0318 22:13:49.434161 27880 net.cpp:205] Memory required for data: 147078200
I0318 22:13:49.434170 27880 layer_factory.hpp:123] Creating layer relu1
I0318 22:13:49.434175 27880 net.cpp:140] Creating Layer relu1
I0318 22:13:49.434180 27880 net.cpp:481] relu1 <- bn1
I0318 22:13:49.434183 27880 net.cpp:455] relu1 -> relu1
I0318 22:13:49.434198 27880 net.cpp:190] Setting up relu1
I0318 22:13:49.434202 27880 net.cpp:197] Top shape: 50 96 55 55 (14520000)
I0318 22:13:49.434204 27880 net.cpp:205] Memory required for data: 205158200
I0318 22:13:49.434206 27880 layer_factory.hpp:123] Creating layer pool1
I0318 22:13:49.434211 27880 net.cpp:140] Creating Layer pool1
I0318 22:13:49.434214 27880 net.cpp:481] pool1 <- relu1
I0318 22:13:49.434217 27880 net.cpp:455] pool1 -> pool1
I0318 22:13:49.434239 27880 net.cpp:190] Setting up pool1
I0318 22:13:49.434244 27880 net.cpp:197] Top shape: 50 96 27 27 (3499200)
I0318 22:13:49.434245 27880 net.cpp:205] Memory required for data: 219155000
I0318 22:13:49.434247 27880 layer_factory.hpp:123] Creating layer conv2
I0318 22:13:49.434253 27880 net.cpp:140] Creating Layer conv2
I0318 22:13:49.434257 27880 net.cpp:481] conv2 <- pool1
I0318 22:13:49.434259 27880 net.cpp:455] conv2 -> conv2
I0318 22:13:49.440258 27880 net.cpp:190] Setting up conv2
I0318 22:13:49.440277 27880 net.cpp:197] Top shape: 50 256 27 27 (9331200)
I0318 22:13:49.440281 27880 net.cpp:205] Memory required for data: 256479800
I0318 22:13:49.440290 27880 layer_factory.hpp:123] Creating layer bn2
I0318 22:13:49.440299 27880 net.cpp:140] Creating Layer bn2
I0318 22:13:49.440301 27880 net.cpp:481] bn2 <- conv2
I0318 22:13:49.440346 27880 net.cpp:455] bn2 -> bn2
I0318 22:13:49.441704 27880 net.cpp:190] Setting up bn2
I0318 22:13:49.441723 27880 net.cpp:197] Top shape: 50 256 27 27 (9331200)
I0318 22:13:49.441730 27880 net.cpp:205] Memory required for data: 293804600
I0318 22:13:49.441745 27880 layer_factory.hpp:123] Creating layer relu2
I0318 22:13:49.441761 27880 net.cpp:140] Creating Layer relu2
I0318 22:13:49.441776 27880 net.cpp:481] relu2 <- bn2
I0318 22:13:49.441784 27880 net.cpp:455] relu2 -> relu2
I0318 22:13:49.441818 27880 net.cpp:190] Setting up relu2
I0318 22:13:49.441826 27880 net.cpp:197] Top shape: 50 256 27 27 (9331200)
I0318 22:13:49.441854 27880 net.cpp:205] Memory required for data: 331129400
I0318 22:13:49.441860 27880 layer_factory.hpp:123] Creating layer pool2
I0318 22:13:49.441872 27880 net.cpp:140] Creating Layer pool2
I0318 22:13:49.441880 27880 net.cpp:481] pool2 <- relu2
I0318 22:13:49.441887 27880 net.cpp:455] pool2 -> pool2
I0318 22:13:49.441934 27880 net.cpp:190] Setting up pool2
I0318 22:13:49.441943 27880 net.cpp:197] Top shape: 50 256 13 13 (2163200)
I0318 22:13:49.441947 27880 net.cpp:205] Memory required for data: 339782200
I0318 22:13:49.441952 27880 layer_factory.hpp:123] Creating layer conv3
I0318 22:13:49.441965 27880 net.cpp:140] Creating Layer conv3
I0318 22:13:49.441973 27880 net.cpp:481] conv3 <- pool2
I0318 22:13:49.441982 27880 net.cpp:455] conv3 -> conv3
I0318 22:13:49.460480 27880 net.cpp:190] Setting up conv3
I0318 22:13:49.460507 27880 net.cpp:197] Top shape: 50 384 13 13 (3244800)
I0318 22:13:49.460513 27880 net.cpp:205] Memory required for data: 352761400
I0318 22:13:49.460522 27880 layer_factory.hpp:123] Creating layer relu3
I0318 22:13:49.460536 27880 net.cpp:140] Creating Layer relu3
I0318 22:13:49.460541 27880 net.cpp:481] relu3 <- conv3
I0318 22:13:49.460549 27880 net.cpp:455] relu3 -> relu3
I0318 22:13:49.460583 27880 net.cpp:190] Setting up relu3
I0318 22:13:49.460593 27880 net.cpp:197] Top shape: 50 384 13 13 (3244800)
I0318 22:13:49.460597 27880 net.cpp:205] Memory required for data: 365740600
I0318 22:13:49.460602 27880 layer_factory.hpp:123] Creating layer conv4
I0318 22:13:49.460615 27880 net.cpp:140] Creating Layer conv4
I0318 22:13:49.460623 27880 net.cpp:481] conv4 <- relu3
I0318 22:13:49.460631 27880 net.cpp:455] conv4 -> conv4
I0318 22:13:49.479460 27880 net.cpp:190] Setting up conv4
I0318 22:13:49.479486 27880 net.cpp:197] Top shape: 50 384 13 13 (3244800)
I0318 22:13:49.479490 27880 net.cpp:205] Memory required for data: 378719800
I0318 22:13:49.479506 27880 layer_factory.hpp:123] Creating layer relu4
I0318 22:13:49.479521 27880 net.cpp:140] Creating Layer relu4
I0318 22:13:49.479526 27880 net.cpp:481] relu4 <- conv4
I0318 22:13:49.479537 27880 net.cpp:455] relu4 -> relu4
I0318 22:13:49.479574 27880 net.cpp:190] Setting up relu4
I0318 22:13:49.479601 27880 net.cpp:197] Top shape: 50 384 13 13 (3244800)
I0318 22:13:49.479614 27880 net.cpp:205] Memory required for data: 391699000
I0318 22:13:49.479626 27880 layer_factory.hpp:123] Creating layer conv5
I0318 22:13:49.479648 27880 net.cpp:140] Creating Layer conv5
I0318 22:13:49.479665 27880 net.cpp:481] conv5 <- relu4
I0318 22:13:49.479681 27880 net.cpp:455] conv5 -> conv5
I0318 22:13:49.490629 27880 net.cpp:190] Setting up conv5
I0318 22:13:49.490684 27880 net.cpp:197] Top shape: 50 256 13 13 (2163200)
I0318 22:13:49.490696 27880 net.cpp:205] Memory required for data: 400351800
I0318 22:13:49.490715 27880 layer_factory.hpp:123] Creating layer relu5
I0318 22:13:49.490739 27880 net.cpp:140] Creating Layer relu5
I0318 22:13:49.490753 27880 net.cpp:481] relu5 <- conv5
I0318 22:13:49.490770 27880 net.cpp:455] relu5 -> relu5
I0318 22:13:49.490820 27880 net.cpp:190] Setting up relu5
I0318 22:13:49.490835 27880 net.cpp:197] Top shape: 50 256 13 13 (2163200)
I0318 22:13:49.490847 27880 net.cpp:205] Memory required for data: 409004600
I0318 22:13:49.490859 27880 layer_factory.hpp:123] Creating layer pool5
I0318 22:13:49.490880 27880 net.cpp:140] Creating Layer pool5
I0318 22:13:49.490895 27880 net.cpp:481] pool5 <- relu5
I0318 22:13:49.490908 27880 net.cpp:455] pool5 -> pool5
I0318 22:13:49.490974 27880 net.cpp:190] Setting up pool5
I0318 22:13:49.490991 27880 net.cpp:197] Top shape: 50 256 6 6 (460800)
I0318 22:13:49.491003 27880 net.cpp:205] Memory required for data: 410847800
I0318 22:13:49.491014 27880 layer_factory.hpp:123] Creating layer fc6
I0318 22:13:49.491034 27880 net.cpp:140] Creating Layer fc6
I0318 22:13:49.491047 27880 net.cpp:481] fc6 <- pool5
I0318 22:13:49.491063 27880 net.cpp:455] fc6 -> fc6
I0318 22:13:49.804940 27880 net.cpp:190] Setting up fc6
I0318 22:13:49.804963 27880 net.cpp:197] Top shape: 50 4096 (204800)
I0318 22:13:49.804997 27880 net.cpp:205] Memory required for data: 411667000
I0318 22:13:49.805003 27880 layer_factory.hpp:123] Creating layer relu6
I0318 22:13:49.805011 27880 net.cpp:140] Creating Layer relu6
I0318 22:13:49.805013 27880 net.cpp:481] relu6 <- fc6
I0318 22:13:49.805018 27880 net.cpp:455] relu6 -> relu6
I0318 22:13:49.805042 27880 net.cpp:190] Setting up relu6
I0318 22:13:49.805047 27880 net.cpp:197] Top shape: 50 4096 (204800)
I0318 22:13:49.805049 27880 net.cpp:205] Memory required for data: 412486200
I0318 22:13:49.805052 27880 layer_factory.hpp:123] Creating layer drop6
I0318 22:13:49.805055 27880 net.cpp:140] Creating Layer drop6
I0318 22:13:49.805058 27880 net.cpp:481] drop6 <- relu6
I0318 22:13:49.805061 27880 net.cpp:455] drop6 -> drop6
I0318 22:13:49.805080 27880 net.cpp:190] Setting up drop6
I0318 22:13:49.805084 27880 net.cpp:197] Top shape: 50 4096 (204800)
I0318 22:13:49.805086 27880 net.cpp:205] Memory required for data: 413305400
I0318 22:13:49.805088 27880 layer_factory.hpp:123] Creating layer fc7
I0318 22:13:49.805094 27880 net.cpp:140] Creating Layer fc7
I0318 22:13:49.805095 27880 net.cpp:481] fc7 <- drop6
I0318 22:13:49.805114 27880 net.cpp:455] fc7 -> fc7
I0318 22:13:49.941488 27880 net.cpp:190] Setting up fc7
I0318 22:13:49.941512 27880 net.cpp:197] Top shape: 50 4096 (204800)
I0318 22:13:49.941514 27880 net.cpp:205] Memory required for data: 414124600
I0318 22:13:49.941535 27880 layer_factory.hpp:123] Creating layer bn7
I0318 22:13:49.941543 27880 net.cpp:140] Creating Layer bn7
I0318 22:13:49.941546 27880 net.cpp:481] bn7 <- fc7
I0318 22:13:49.941552 27880 net.cpp:455] bn7 -> bn7
I0318 22:13:49.941967 27880 net.cpp:190] Setting up bn7
I0318 22:13:49.941972 27880 net.cpp:197] Top shape: 50 4096 (204800)
I0318 22:13:49.941974 27880 net.cpp:205] Memory required for data: 414943800
I0318 22:13:49.941980 27880 layer_factory.hpp:123] Creating layer relu7
I0318 22:13:49.941987 27880 net.cpp:140] Creating Layer relu7
I0318 22:13:49.941990 27880 net.cpp:481] relu7 <- bn7
I0318 22:13:49.941993 27880 net.cpp:455] relu7 -> relu7
I0318 22:13:49.942008 27880 net.cpp:190] Setting up relu7
I0318 22:13:49.942013 27880 net.cpp:197] Top shape: 50 4096 (204800)
I0318 22:13:49.942014 27880 net.cpp:205] Memory required for data: 415763000
I0318 22:13:49.942016 27880 layer_factory.hpp:123] Creating layer drop7
I0318 22:13:49.942021 27880 net.cpp:140] Creating Layer drop7
I0318 22:13:49.942024 27880 net.cpp:481] drop7 <- relu7
I0318 22:13:49.942034 27880 net.cpp:455] drop7 -> drop7
I0318 22:13:49.942054 27880 net.cpp:190] Setting up drop7
I0318 22:13:49.942057 27880 net.cpp:197] Top shape: 50 4096 (204800)
I0318 22:13:49.942059 27880 net.cpp:205] Memory required for data: 416582200
I0318 22:13:49.942061 27880 layer_factory.hpp:123] Creating layer fc8
I0318 22:13:49.942068 27880 net.cpp:140] Creating Layer fc8
I0318 22:13:49.942070 27880 net.cpp:481] fc8 <- drop7
I0318 22:13:49.942073 27880 net.cpp:455] fc8 -> fc8
I0318 22:13:49.942209 27880 net.cpp:190] Setting up fc8
I0318 22:13:49.942212 27880 net.cpp:197] Top shape: 50 2 (100)
I0318 22:13:49.942214 27880 net.cpp:205] Memory required for data: 416582600
I0318 22:13:49.942217 27880 layer_factory.hpp:123] Creating layer fc8_fc8_0_split
I0318 22:13:49.942222 27880 net.cpp:140] Creating Layer fc8_fc8_0_split
I0318 22:13:49.942224 27880 net.cpp:481] fc8_fc8_0_split <- fc8
I0318 22:13:49.942227 27880 net.cpp:455] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0318 22:13:49.942231 27880 net.cpp:455] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0318 22:13:49.942235 27880 net.cpp:455] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0318 22:13:49.942260 27880 net.cpp:190] Setting up fc8_fc8_0_split
I0318 22:13:49.942265 27880 net.cpp:197] Top shape: 50 2 (100)
I0318 22:13:49.942266 27880 net.cpp:197] Top shape: 50 2 (100)
I0318 22:13:49.942270 27880 net.cpp:197] Top shape: 50 2 (100)
I0318 22:13:49.942271 27880 net.cpp:205] Memory required for data: 416583800
I0318 22:13:49.942273 27880 layer_factory.hpp:123] Creating layer accuracy
I0318 22:13:49.942277 27880 net.cpp:140] Creating Layer accuracy
I0318 22:13:49.942293 27880 net.cpp:481] accuracy <- fc8_fc8_0_split_0
I0318 22:13:49.942296 27880 net.cpp:481] accuracy <- label_data_1_split_0
I0318 22:13:49.942299 27880 net.cpp:455] accuracy -> accuracy
I0318 22:13:49.942304 27880 net.cpp:190] Setting up accuracy
I0318 22:13:49.942308 27880 net.cpp:197] Top shape: (1)
I0318 22:13:49.942309 27880 net.cpp:205] Memory required for data: 416583804
I0318 22:13:49.942312 27880 layer_factory.hpp:123] Creating layer loss
I0318 22:13:49.942317 27880 net.cpp:140] Creating Layer loss
I0318 22:13:49.942319 27880 net.cpp:481] loss <- fc8_fc8_0_split_1
I0318 22:13:49.942322 27880 net.cpp:481] loss <- label_data_1_split_1
I0318 22:13:49.942325 27880 net.cpp:455] loss -> loss
I0318 22:13:49.942333 27880 layer_factory.hpp:123] Creating layer loss
I0318 22:13:49.942392 27880 net.cpp:190] Setting up loss
I0318 22:13:49.942396 27880 net.cpp:197] Top shape: (1)
I0318 22:13:49.942399 27880 net.cpp:200]     with loss weight 1
I0318 22:13:49.942410 27880 net.cpp:205] Memory required for data: 416583808
I0318 22:13:49.942412 27880 layer_factory.hpp:123] Creating layer accuracy-top1
I0318 22:13:49.942416 27880 net.cpp:140] Creating Layer accuracy-top1
I0318 22:13:49.942418 27880 net.cpp:481] accuracy-top1 <- fc8_fc8_0_split_2
I0318 22:13:49.942421 27880 net.cpp:481] accuracy-top1 <- label_data_1_split_2
I0318 22:13:49.942425 27880 net.cpp:455] accuracy-top1 -> top-1
I0318 22:13:49.942430 27880 net.cpp:190] Setting up accuracy-top1
I0318 22:13:49.942432 27880 net.cpp:197] Top shape: (1)
I0318 22:13:49.942435 27880 net.cpp:205] Memory required for data: 416583812
I0318 22:13:49.942436 27880 net.cpp:268] accuracy-top1 does not need backward computation.
I0318 22:13:49.942440 27880 net.cpp:266] loss needs backward computation.
I0318 22:13:49.942442 27880 net.cpp:268] accuracy does not need backward computation.
I0318 22:13:49.942445 27880 net.cpp:266] fc8_fc8_0_split needs backward computation.
I0318 22:13:49.942447 27880 net.cpp:266] fc8 needs backward computation.
I0318 22:13:49.942450 27880 net.cpp:266] drop7 needs backward computation.
I0318 22:13:49.942451 27880 net.cpp:266] relu7 needs backward computation.
I0318 22:13:49.942453 27880 net.cpp:266] bn7 needs backward computation.
I0318 22:13:49.942456 27880 net.cpp:266] fc7 needs backward computation.
I0318 22:13:49.942458 27880 net.cpp:266] drop6 needs backward computation.
I0318 22:13:49.942461 27880 net.cpp:266] relu6 needs backward computation.
I0318 22:13:49.942463 27880 net.cpp:266] fc6 needs backward computation.
I0318 22:13:49.942466 27880 net.cpp:266] pool5 needs backward computation.
I0318 22:13:49.942468 27880 net.cpp:266] relu5 needs backward computation.
I0318 22:13:49.942471 27880 net.cpp:266] conv5 needs backward computation.
I0318 22:13:49.942472 27880 net.cpp:266] relu4 needs backward computation.
I0318 22:13:49.942476 27880 net.cpp:266] conv4 needs backward computation.
I0318 22:13:49.942477 27880 net.cpp:266] relu3 needs backward computation.
I0318 22:13:49.942481 27880 net.cpp:266] conv3 needs backward computation.
I0318 22:13:49.942482 27880 net.cpp:266] pool2 needs backward computation.
I0318 22:13:49.942485 27880 net.cpp:266] relu2 needs backward computation.
I0318 22:13:49.942487 27880 net.cpp:266] bn2 needs backward computation.
I0318 22:13:49.942489 27880 net.cpp:266] conv2 needs backward computation.
I0318 22:13:49.942492 27880 net.cpp:266] pool1 needs backward computation.
I0318 22:13:49.942494 27880 net.cpp:266] relu1 needs backward computation.
I0318 22:13:49.942497 27880 net.cpp:266] bn1 needs backward computation.
I0318 22:13:49.942499 27880 net.cpp:266] conv1 needs backward computation.
I0318 22:13:49.942502 27880 net.cpp:268] label_data_1_split does not need backward computation.
I0318 22:13:49.942505 27880 net.cpp:268] data does not need backward computation.
I0318 22:13:49.942507 27880 net.cpp:310] This network produces output accuracy
I0318 22:13:49.942509 27880 net.cpp:310] This network produces output loss
I0318 22:13:49.942512 27880 net.cpp:310] This network produces output top-1
I0318 22:13:49.942534 27880 net.cpp:330] Network initialization done.
I0318 22:13:49.942601 27880 solver.cpp:109] Solver scaffolding done.
I0318 22:13:49.943388 27880 caffe_interface.cpp:139] Finetuning from pruning/alexnetBNnoLRN/regular_rate_0.5/sparse.caffemodel
I0318 22:13:51.509380 27880 caffe_interface.cpp:573] Starting Optimization
I0318 22:13:51.509399 27880 solver.cpp:387] Solving
I0318 22:13:51.509402 27880 solver.cpp:388] Learning Rate Policy: step
I0318 22:13:51.510604 27880 solver.cpp:470] Iteration 0, Testing net (#0)
I0318 22:13:53.013154 27880 solver.cpp:569]     Test net output #0: accuracy = 0.94875
I0318 22:13:53.013180 27880 solver.cpp:569]     Test net output #1: loss = 0.291004 (* 1 = 0.291004 loss)
I0318 22:13:53.013182 27880 solver.cpp:569]     Test net output #2: top-1 = 0.94875
I0318 22:13:53.271631 27880 solver.cpp:316] Iteration 0 (0 iter/s, 1.76213s/50 iter), loss = 0.00149387, remaining 333333 hours and 20 minutes
I0318 22:13:53.271657 27880 solver.cpp:337]     Train net output #0: loss = 0.00149387 (* 1 = 0.00149387 loss)
I0318 22:13:53.271673 27880 sgd_solver.cpp:152] Iteration 0, lr = 0.001
I0318 22:14:05.913096 27880 solver.cpp:316] Iteration 50 (3.9554 iter/s, 12.641s/50 iter), loss = 0.0766772, remaining 0 hours and 50 minutes
I0318 22:14:05.913125 27880 solver.cpp:337]     Train net output #0: loss = 0.0766772 (* 1 = 0.0766772 loss)
I0318 22:14:05.913130 27880 sgd_solver.cpp:152] Iteration 50, lr = 0.001
I0318 22:14:18.557787 27880 solver.cpp:316] Iteration 100 (3.95439 iter/s, 12.6442s/50 iter), loss = 0.106839, remaining 0 hours and 50 minutes
I0318 22:14:18.557989 27880 solver.cpp:337]     Train net output #0: loss = 0.106839 (* 1 = 0.106839 loss)
I0318 22:14:18.557997 27880 sgd_solver.cpp:152] Iteration 100, lr = 0.001
I0318 22:14:31.315065 27880 solver.cpp:316] Iteration 150 (3.91954 iter/s, 12.7566s/50 iter), loss = 0.0699641, remaining 0 hours and 50 minutes
I0318 22:14:31.315093 27880 solver.cpp:337]     Train net output #0: loss = 0.0699641 (* 1 = 0.0699641 loss)
I0318 22:14:31.315098 27880 sgd_solver.cpp:152] Iteration 150, lr = 0.001
I0318 22:14:44.135860 27880 solver.cpp:316] Iteration 200 (3.90007 iter/s, 12.8203s/50 iter), loss = 0.119519, remaining 0 hours and 50 minutes
I0318 22:14:44.135887 27880 solver.cpp:337]     Train net output #0: loss = 0.119519 (* 1 = 0.119519 loss)
I0318 22:14:44.135895 27880 sgd_solver.cpp:152] Iteration 200, lr = 0.001
I0318 22:14:57.015208 27880 solver.cpp:316] Iteration 250 (3.88234 iter/s, 12.8788s/50 iter), loss = 0.0719912, remaining 0 hours and 50 minutes
I0318 22:14:57.015264 27880 solver.cpp:337]     Train net output #0: loss = 0.0719912 (* 1 = 0.0719912 loss)
I0318 22:14:57.015269 27880 sgd_solver.cpp:152] Iteration 250, lr = 0.001
I0318 22:15:09.938885 27880 solver.cpp:316] Iteration 300 (3.86903 iter/s, 12.9231s/50 iter), loss = 0.0663865, remaining 0 hours and 50 minutes
I0318 22:15:09.938913 27880 solver.cpp:337]     Train net output #0: loss = 0.0663865 (* 1 = 0.0663865 loss)
I0318 22:15:09.938920 27880 sgd_solver.cpp:152] Iteration 300, lr = 0.001
I0318 22:15:22.890558 27880 solver.cpp:316] Iteration 350 (3.86066 iter/s, 12.9511s/50 iter), loss = 0.0799132, remaining 0 hours and 50 minutes
I0318 22:15:22.890585 27880 solver.cpp:337]     Train net output #0: loss = 0.0799132 (* 1 = 0.0799132 loss)
I0318 22:15:22.890591 27880 sgd_solver.cpp:152] Iteration 350, lr = 0.001
I0318 22:15:35.849212 27880 solver.cpp:316] Iteration 400 (3.85858 iter/s, 12.9581s/50 iter), loss = 0.0834432, remaining 0 hours and 50 minutes
I0318 22:15:35.849355 27880 solver.cpp:337]     Train net output #0: loss = 0.0834432 (* 1 = 0.0834432 loss)
I0318 22:15:35.849364 27880 sgd_solver.cpp:152] Iteration 400, lr = 0.001
I0318 22:15:48.797413 27880 solver.cpp:316] Iteration 450 (3.86173 iter/s, 12.9476s/50 iter), loss = 0.106069, remaining 0 hours and 49 minutes
I0318 22:15:48.797441 27880 solver.cpp:337]     Train net output #0: loss = 0.106069 (* 1 = 0.106069 loss)
I0318 22:15:48.797447 27880 sgd_solver.cpp:152] Iteration 450, lr = 0.001
I0318 22:16:01.495448 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_500.caffemodel
I0318 22:16:03.825130 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_500.solverstate
I0318 22:16:04.501507 27880 solver.cpp:316] Iteration 500 (3.18401 iter/s, 15.7035s/50 iter), loss = 0.0465052, remaining 0 hours and 59 minutes
I0318 22:16:04.501535 27880 solver.cpp:337]     Train net output #0: loss = 0.0465052 (* 1 = 0.0465052 loss)
I0318 22:16:04.501541 27880 sgd_solver.cpp:152] Iteration 500, lr = 0.001
I0318 22:16:17.456310 27880 solver.cpp:316] Iteration 550 (3.85973 iter/s, 12.9543s/50 iter), loss = 0.149419, remaining 0 hours and 49 minutes
I0318 22:16:17.456480 27880 solver.cpp:337]     Train net output #0: loss = 0.149419 (* 1 = 0.149419 loss)
I0318 22:16:17.456488 27880 sgd_solver.cpp:152] Iteration 550, lr = 0.001
I0318 22:16:30.387917 27880 solver.cpp:316] Iteration 600 (3.8667 iter/s, 12.9309s/50 iter), loss = 0.0760812, remaining 0 hours and 49 minutes
I0318 22:16:30.387944 27880 solver.cpp:337]     Train net output #0: loss = 0.0760811 (* 1 = 0.0760811 loss)
I0318 22:16:30.387950 27880 sgd_solver.cpp:152] Iteration 600, lr = 0.001
I0318 22:16:43.332535 27880 solver.cpp:316] Iteration 650 (3.86277 iter/s, 12.9441s/50 iter), loss = 0.0876262, remaining 0 hours and 48 minutes
I0318 22:16:43.332563 27880 solver.cpp:337]     Train net output #0: loss = 0.0876261 (* 1 = 0.0876261 loss)
I0318 22:16:43.332568 27880 sgd_solver.cpp:152] Iteration 650, lr = 0.001
I0318 22:16:56.269604 27880 solver.cpp:316] Iteration 700 (3.86502 iter/s, 12.9365s/50 iter), loss = 0.0547005, remaining 0 hours and 48 minutes
I0318 22:16:56.269752 27880 solver.cpp:337]     Train net output #0: loss = 0.0547005 (* 1 = 0.0547005 loss)
I0318 22:16:56.269760 27880 sgd_solver.cpp:152] Iteration 700, lr = 0.001
I0318 22:17:09.205132 27880 solver.cpp:316] Iteration 750 (3.86552 iter/s, 12.9349s/50 iter), loss = 0.092543, remaining 0 hours and 48 minutes
I0318 22:17:09.205160 27880 solver.cpp:337]     Train net output #0: loss = 0.092543 (* 1 = 0.092543 loss)
I0318 22:17:09.205165 27880 sgd_solver.cpp:152] Iteration 750, lr = 0.001
I0318 22:17:22.141846 27880 solver.cpp:316] Iteration 800 (3.86513 iter/s, 12.9362s/50 iter), loss = 0.0747994, remaining 0 hours and 48 minutes
I0318 22:17:22.141872 27880 solver.cpp:337]     Train net output #0: loss = 0.0747994 (* 1 = 0.0747994 loss)
I0318 22:17:22.141878 27880 sgd_solver.cpp:152] Iteration 800, lr = 0.001
I0318 22:17:35.084249 27880 solver.cpp:316] Iteration 850 (3.86343 iter/s, 12.9419s/50 iter), loss = 0.0658131, remaining 0 hours and 47 minutes
I0318 22:17:35.084399 27880 solver.cpp:337]     Train net output #0: loss = 0.0658131 (* 1 = 0.0658131 loss)
I0318 22:17:35.084408 27880 sgd_solver.cpp:152] Iteration 850, lr = 0.001
I0318 22:17:48.020843 27880 solver.cpp:316] Iteration 900 (3.8652 iter/s, 12.9359s/50 iter), loss = 0.102167, remaining 0 hours and 47 minutes
I0318 22:17:48.020870 27880 solver.cpp:337]     Train net output #0: loss = 0.102167 (* 1 = 0.102167 loss)
I0318 22:17:48.020876 27880 sgd_solver.cpp:152] Iteration 900, lr = 0.001
I0318 22:18:00.947858 27880 solver.cpp:316] Iteration 950 (3.86803 iter/s, 12.9265s/50 iter), loss = 0.120357, remaining 0 hours and 47 minutes
I0318 22:18:00.947885 27880 solver.cpp:337]     Train net output #0: loss = 0.120357 (* 1 = 0.120357 loss)
I0318 22:18:00.947891 27880 sgd_solver.cpp:152] Iteration 950, lr = 0.001
I0318 22:18:13.620304 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_1000.caffemodel
I0318 22:18:15.849404 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_1000.solverstate
I0318 22:18:16.281358 27880 solver.cpp:470] Iteration 1000, Testing net (#0)
I0318 22:18:17.738260 27880 solver.cpp:569]     Test net output #0: accuracy = 0.84375
I0318 22:18:17.738286 27880 solver.cpp:569]     Test net output #1: loss = 0.750946 (* 1 = 0.750946 loss)
I0318 22:18:17.738289 27880 solver.cpp:569]     Test net output #2: top-1 = 0.84375
I0318 22:18:17.984380 27880 solver.cpp:316] Iteration 1000 (2.93499 iter/s, 17.0358s/50 iter), loss = 0.0434018, remaining 1 hours and 2 minutes
I0318 22:18:17.984402 27880 solver.cpp:337]     Train net output #0: loss = 0.0434018 (* 1 = 0.0434018 loss)
I0318 22:18:17.984409 27880 sgd_solver.cpp:152] Iteration 1000, lr = 0.001
I0318 22:18:30.842381 27880 solver.cpp:316] Iteration 1050 (3.88879 iter/s, 12.8575s/50 iter), loss = 0.15545, remaining 0 hours and 46 minutes
I0318 22:18:30.842408 27880 solver.cpp:337]     Train net output #0: loss = 0.15545 (* 1 = 0.15545 loss)
I0318 22:18:30.842413 27880 sgd_solver.cpp:152] Iteration 1050, lr = 0.001
I0318 22:18:43.751219 27880 solver.cpp:316] Iteration 1100 (3.87347 iter/s, 12.9083s/50 iter), loss = 0.0707498, remaining 0 hours and 46 minutes
I0318 22:18:43.751389 27880 solver.cpp:337]     Train net output #0: loss = 0.0707498 (* 1 = 0.0707498 loss)
I0318 22:18:43.751397 27880 sgd_solver.cpp:152] Iteration 1100, lr = 0.001
I0318 22:18:56.687336 27880 solver.cpp:316] Iteration 1150 (3.86535 iter/s, 12.9354s/50 iter), loss = 0.0738435, remaining 0 hours and 46 minutes
I0318 22:18:56.687362 27880 solver.cpp:337]     Train net output #0: loss = 0.0738434 (* 1 = 0.0738434 loss)
I0318 22:18:56.687367 27880 sgd_solver.cpp:152] Iteration 1150, lr = 0.001
I0318 22:19:09.617466 27880 solver.cpp:316] Iteration 1200 (3.8671 iter/s, 12.9296s/50 iter), loss = 0.0984433, remaining 0 hours and 46 minutes
I0318 22:19:09.617493 27880 solver.cpp:337]     Train net output #0: loss = 0.0984432 (* 1 = 0.0984432 loss)
I0318 22:19:09.617499 27880 sgd_solver.cpp:152] Iteration 1200, lr = 0.001
I0318 22:19:22.569434 27880 solver.cpp:316] Iteration 1250 (3.86058 iter/s, 12.9514s/50 iter), loss = 0.101183, remaining 0 hours and 46 minutes
I0318 22:19:22.569568 27880 solver.cpp:337]     Train net output #0: loss = 0.101183 (* 1 = 0.101183 loss)
I0318 22:19:22.569576 27880 sgd_solver.cpp:152] Iteration 1250, lr = 0.001
I0318 22:19:35.507465 27880 solver.cpp:316] Iteration 1300 (3.86477 iter/s, 12.9374s/50 iter), loss = 0.0798089, remaining 0 hours and 46 minutes
I0318 22:19:35.507493 27880 solver.cpp:337]     Train net output #0: loss = 0.0798089 (* 1 = 0.0798089 loss)
I0318 22:19:35.507499 27880 sgd_solver.cpp:152] Iteration 1300, lr = 0.001
I0318 22:19:48.455437 27880 solver.cpp:316] Iteration 1350 (3.86177 iter/s, 12.9474s/50 iter), loss = 0.0898116, remaining 0 hours and 45 minutes
I0318 22:19:48.455467 27880 solver.cpp:337]     Train net output #0: loss = 0.0898116 (* 1 = 0.0898116 loss)
I0318 22:19:48.455473 27880 sgd_solver.cpp:152] Iteration 1350, lr = 0.001
I0318 22:20:01.391137 27880 solver.cpp:316] Iteration 1400 (3.86543 iter/s, 12.9352s/50 iter), loss = 0.0947844, remaining 0 hours and 45 minutes
I0318 22:20:01.391274 27880 solver.cpp:337]     Train net output #0: loss = 0.0947843 (* 1 = 0.0947843 loss)
I0318 22:20:01.391283 27880 sgd_solver.cpp:152] Iteration 1400, lr = 0.001
I0318 22:20:14.355744 27880 solver.cpp:316] Iteration 1450 (3.85685 iter/s, 12.964s/50 iter), loss = 0.0938576, remaining 0 hours and 45 minutes
I0318 22:20:14.355772 27880 solver.cpp:337]     Train net output #0: loss = 0.0938576 (* 1 = 0.0938576 loss)
I0318 22:20:14.355777 27880 sgd_solver.cpp:152] Iteration 1450, lr = 0.001
I0318 22:20:27.034669 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_1500.caffemodel
I0318 22:20:29.321059 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_1500.solverstate
I0318 22:20:30.005941 27880 solver.cpp:316] Iteration 1500 (3.19498 iter/s, 15.6496s/50 iter), loss = 0.11986, remaining 0 hours and 54 minutes
I0318 22:20:30.005968 27880 solver.cpp:337]     Train net output #0: loss = 0.11986 (* 1 = 0.11986 loss)
I0318 22:20:30.005975 27880 sgd_solver.cpp:152] Iteration 1500, lr = 0.001
I0318 22:20:42.873841 27880 solver.cpp:316] Iteration 1550 (3.8858 iter/s, 12.8674s/50 iter), loss = 0.100946, remaining 0 hours and 44 minutes
I0318 22:20:42.874008 27880 solver.cpp:337]     Train net output #0: loss = 0.100946 (* 1 = 0.100946 loss)
I0318 22:20:42.874017 27880 sgd_solver.cpp:152] Iteration 1550, lr = 0.001
I0318 22:20:55.806818 27880 solver.cpp:316] Iteration 1600 (3.86629 iter/s, 12.9323s/50 iter), loss = 0.0405704, remaining 0 hours and 44 minutes
I0318 22:20:55.806849 27880 solver.cpp:337]     Train net output #0: loss = 0.0405704 (* 1 = 0.0405704 loss)
I0318 22:20:55.806854 27880 sgd_solver.cpp:152] Iteration 1600, lr = 0.001
I0318 22:21:08.740273 27880 solver.cpp:316] Iteration 1650 (3.8661 iter/s, 12.9329s/50 iter), loss = 0.093115, remaining 0 hours and 44 minutes
I0318 22:21:08.740303 27880 solver.cpp:337]     Train net output #0: loss = 0.0931149 (* 1 = 0.0931149 loss)
I0318 22:21:08.740309 27880 sgd_solver.cpp:152] Iteration 1650, lr = 0.001
I0318 22:21:21.666640 27880 solver.cpp:316] Iteration 1700 (3.86822 iter/s, 12.9258s/50 iter), loss = 0.0982241, remaining 0 hours and 44 minutes
I0318 22:21:21.666797 27880 solver.cpp:337]     Train net output #0: loss = 0.0982241 (* 1 = 0.0982241 loss)
I0318 22:21:21.666806 27880 sgd_solver.cpp:152] Iteration 1700, lr = 0.001
I0318 22:21:34.595803 27880 solver.cpp:316] Iteration 1750 (3.86742 iter/s, 12.9285s/50 iter), loss = 0.0680076, remaining 0 hours and 43 minutes
I0318 22:21:34.595831 27880 solver.cpp:337]     Train net output #0: loss = 0.0680076 (* 1 = 0.0680076 loss)
I0318 22:21:34.595837 27880 sgd_solver.cpp:152] Iteration 1750, lr = 0.001
I0318 22:21:47.567097 27880 solver.cpp:316] Iteration 1800 (3.85483 iter/s, 12.9708s/50 iter), loss = 0.0811865, remaining 0 hours and 44 minutes
I0318 22:21:47.567126 27880 solver.cpp:337]     Train net output #0: loss = 0.0811864 (* 1 = 0.0811864 loss)
I0318 22:21:47.567132 27880 sgd_solver.cpp:152] Iteration 1800, lr = 0.001
I0318 22:22:00.528453 27880 solver.cpp:316] Iteration 1850 (3.85778 iter/s, 12.9608s/50 iter), loss = 0.0362328, remaining 0 hours and 43 minutes
I0318 22:22:00.528594 27880 solver.cpp:337]     Train net output #0: loss = 0.0362328 (* 1 = 0.0362328 loss)
I0318 22:22:00.528618 27880 sgd_solver.cpp:152] Iteration 1850, lr = 0.001
I0318 22:22:13.460625 27880 solver.cpp:316] Iteration 1900 (3.86652 iter/s, 12.9315s/50 iter), loss = 0.100954, remaining 0 hours and 43 minutes
I0318 22:22:13.460652 27880 solver.cpp:337]     Train net output #0: loss = 0.100953 (* 1 = 0.100953 loss)
I0318 22:22:13.460675 27880 sgd_solver.cpp:152] Iteration 1900, lr = 0.001
I0318 22:22:26.398429 27880 solver.cpp:316] Iteration 1950 (3.8648 iter/s, 12.9373s/50 iter), loss = 0.0616113, remaining 0 hours and 43 minutes
I0318 22:22:26.398458 27880 solver.cpp:337]     Train net output #0: loss = 0.0616112 (* 1 = 0.0616112 loss)
I0318 22:22:26.398464 27880 sgd_solver.cpp:152] Iteration 1950, lr = 0.001
I0318 22:22:39.082594 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_2000.caffemodel
I0318 22:22:41.329213 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_2000.solverstate
I0318 22:22:41.753494 27880 solver.cpp:470] Iteration 2000, Testing net (#0)
I0318 22:22:43.211769 27880 solver.cpp:569]     Test net output #0: accuracy = 0.907
I0318 22:22:43.211794 27880 solver.cpp:569]     Test net output #1: loss = 0.258018 (* 1 = 0.258018 loss)
I0318 22:22:43.211797 27880 solver.cpp:569]     Test net output #2: top-1 = 0.907
I0318 22:22:43.458088 27880 solver.cpp:316] Iteration 2000 (2.93101 iter/s, 17.059s/50 iter), loss = 0.0760213, remaining 0 hours and 56 minutes
I0318 22:22:43.458112 27880 solver.cpp:337]     Train net output #0: loss = 0.0760213 (* 1 = 0.0760213 loss)
I0318 22:22:43.458118 27880 sgd_solver.cpp:152] Iteration 2000, lr = 0.001
I0318 22:22:56.329962 27880 solver.cpp:316] Iteration 2050 (3.8846 iter/s, 12.8713s/50 iter), loss = 0.0763076, remaining 0 hours and 42 minutes
I0318 22:22:56.329989 27880 solver.cpp:337]     Train net output #0: loss = 0.0763076 (* 1 = 0.0763076 loss)
I0318 22:22:56.329996 27880 sgd_solver.cpp:152] Iteration 2050, lr = 0.001
I0318 22:23:09.271400 27880 solver.cpp:316] Iteration 2100 (3.86372 iter/s, 12.9409s/50 iter), loss = 0.0789283, remaining 0 hours and 42 minutes
I0318 22:23:09.271584 27880 solver.cpp:337]     Train net output #0: loss = 0.0789282 (* 1 = 0.0789282 loss)
I0318 22:23:09.271593 27880 sgd_solver.cpp:152] Iteration 2100, lr = 0.001
I0318 22:23:22.209174 27880 solver.cpp:316] Iteration 2150 (3.86486 iter/s, 12.9371s/50 iter), loss = 0.0885793, remaining 0 hours and 42 minutes
I0318 22:23:22.209201 27880 solver.cpp:337]     Train net output #0: loss = 0.0885792 (* 1 = 0.0885792 loss)
I0318 22:23:22.209208 27880 sgd_solver.cpp:152] Iteration 2150, lr = 0.001
I0318 22:23:35.145220 27880 solver.cpp:316] Iteration 2200 (3.86533 iter/s, 12.9355s/50 iter), loss = 0.0731258, remaining 0 hours and 42 minutes
I0318 22:23:35.145247 27880 solver.cpp:337]     Train net output #0: loss = 0.0731258 (* 1 = 0.0731258 loss)
I0318 22:23:35.145253 27880 sgd_solver.cpp:152] Iteration 2200, lr = 0.001
I0318 22:23:48.101090 27880 solver.cpp:316] Iteration 2250 (3.85941 iter/s, 12.9553s/50 iter), loss = 0.0672516, remaining 0 hours and 41 minutes
I0318 22:23:48.101235 27880 solver.cpp:337]     Train net output #0: loss = 0.0672516 (* 1 = 0.0672516 loss)
I0318 22:23:48.101243 27880 sgd_solver.cpp:152] Iteration 2250, lr = 0.001
I0318 22:24:01.040738 27880 solver.cpp:316] Iteration 2300 (3.86429 iter/s, 12.939s/50 iter), loss = 0.118376, remaining 0 hours and 41 minutes
I0318 22:24:01.040766 27880 solver.cpp:337]     Train net output #0: loss = 0.118376 (* 1 = 0.118376 loss)
I0318 22:24:01.040772 27880 sgd_solver.cpp:152] Iteration 2300, lr = 0.001
I0318 22:24:13.988381 27880 solver.cpp:316] Iteration 2350 (3.86187 iter/s, 12.9471s/50 iter), loss = 0.0581906, remaining 0 hours and 41 minutes
I0318 22:24:13.988410 27880 solver.cpp:337]     Train net output #0: loss = 0.0581906 (* 1 = 0.0581906 loss)
I0318 22:24:13.988416 27880 sgd_solver.cpp:152] Iteration 2350, lr = 0.001
I0318 22:24:26.938652 27880 solver.cpp:316] Iteration 2400 (3.86108 iter/s, 12.9497s/50 iter), loss = 0.103424, remaining 0 hours and 41 minutes
I0318 22:24:26.938802 27880 solver.cpp:337]     Train net output #0: loss = 0.103424 (* 1 = 0.103424 loss)
I0318 22:24:26.938812 27880 sgd_solver.cpp:152] Iteration 2400, lr = 0.001
I0318 22:24:39.872150 27880 solver.cpp:316] Iteration 2450 (3.86613 iter/s, 12.9328s/50 iter), loss = 0.0942281, remaining 0 hours and 41 minutes
I0318 22:24:39.872177 27880 solver.cpp:337]     Train net output #0: loss = 0.094228 (* 1 = 0.094228 loss)
I0318 22:24:39.872184 27880 sgd_solver.cpp:152] Iteration 2450, lr = 0.001
I0318 22:24:52.562491 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_2500.caffemodel
I0318 22:24:54.821532 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_2500.solverstate
I0318 22:24:55.511440 27880 solver.cpp:316] Iteration 2500 (3.19721 iter/s, 15.6387s/50 iter), loss = 0.105442, remaining 0 hours and 49 minutes
I0318 22:24:55.511468 27880 solver.cpp:337]     Train net output #0: loss = 0.105442 (* 1 = 0.105442 loss)
I0318 22:24:55.511476 27880 sgd_solver.cpp:152] Iteration 2500, lr = 0.0001
I0318 22:25:08.380918 27880 solver.cpp:316] Iteration 2550 (3.88532 iter/s, 12.8689s/50 iter), loss = 0.0550412, remaining 0 hours and 40 minutes
I0318 22:25:08.381053 27880 solver.cpp:337]     Train net output #0: loss = 0.0550412 (* 1 = 0.0550412 loss)
I0318 22:25:08.381060 27880 sgd_solver.cpp:152] Iteration 2550, lr = 0.0001
I0318 22:25:21.307030 27880 solver.cpp:316] Iteration 2600 (3.86833 iter/s, 12.9255s/50 iter), loss = 0.0341139, remaining 0 hours and 40 minutes
I0318 22:25:21.307060 27880 solver.cpp:337]     Train net output #0: loss = 0.0341139 (* 1 = 0.0341139 loss)
I0318 22:25:21.307065 27880 sgd_solver.cpp:152] Iteration 2600, lr = 0.0001
I0318 22:25:34.247202 27880 solver.cpp:316] Iteration 2650 (3.8641 iter/s, 12.9396s/50 iter), loss = 0.0655684, remaining 0 hours and 40 minutes
I0318 22:25:34.247231 27880 solver.cpp:337]     Train net output #0: loss = 0.0655684 (* 1 = 0.0655684 loss)
I0318 22:25:34.247237 27880 sgd_solver.cpp:152] Iteration 2650, lr = 0.0001
I0318 22:25:47.202075 27880 solver.cpp:316] Iteration 2700 (3.85971 iter/s, 12.9543s/50 iter), loss = 0.0244952, remaining 0 hours and 40 minutes
I0318 22:25:47.202239 27880 solver.cpp:337]     Train net output #0: loss = 0.0244952 (* 1 = 0.0244952 loss)
I0318 22:25:47.202248 27880 sgd_solver.cpp:152] Iteration 2700, lr = 0.0001
I0318 22:26:00.153028 27880 solver.cpp:316] Iteration 2750 (3.86092 iter/s, 12.9503s/50 iter), loss = 0.0363586, remaining 0 hours and 39 minutes
I0318 22:26:00.153054 27880 solver.cpp:337]     Train net output #0: loss = 0.0363586 (* 1 = 0.0363586 loss)
I0318 22:26:00.153061 27880 sgd_solver.cpp:152] Iteration 2750, lr = 0.0001
I0318 22:26:13.097661 27880 solver.cpp:316] Iteration 2800 (3.86276 iter/s, 12.9441s/50 iter), loss = 0.0407087, remaining 0 hours and 39 minutes
I0318 22:26:13.097688 27880 solver.cpp:337]     Train net output #0: loss = 0.0407087 (* 1 = 0.0407087 loss)
I0318 22:26:13.097693 27880 sgd_solver.cpp:152] Iteration 2800, lr = 0.0001
I0318 22:26:26.035620 27880 solver.cpp:316] Iteration 2850 (3.86476 iter/s, 12.9374s/50 iter), loss = 0.0441432, remaining 0 hours and 39 minutes
I0318 22:26:26.035756 27880 solver.cpp:337]     Train net output #0: loss = 0.0441432 (* 1 = 0.0441432 loss)
I0318 22:26:26.035764 27880 sgd_solver.cpp:152] Iteration 2850, lr = 0.0001
I0318 22:26:38.972048 27880 solver.cpp:316] Iteration 2900 (3.86525 iter/s, 12.9358s/50 iter), loss = 0.080529, remaining 0 hours and 39 minutes
I0318 22:26:38.972074 27880 solver.cpp:337]     Train net output #0: loss = 0.080529 (* 1 = 0.080529 loss)
I0318 22:26:38.972080 27880 sgd_solver.cpp:152] Iteration 2900, lr = 0.0001
I0318 22:26:51.915747 27880 solver.cpp:316] Iteration 2950 (3.86304 iter/s, 12.9432s/50 iter), loss = 0.0570422, remaining 0 hours and 38 minutes
I0318 22:26:51.915774 27880 solver.cpp:337]     Train net output #0: loss = 0.0570422 (* 1 = 0.0570422 loss)
I0318 22:26:51.915781 27880 sgd_solver.cpp:152] Iteration 2950, lr = 0.0001
I0318 22:27:04.600620 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_3000.caffemodel
I0318 22:27:06.883441 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_3000.solverstate
I0318 22:27:07.318159 27880 solver.cpp:470] Iteration 3000, Testing net (#0)
I0318 22:27:08.792479 27880 solver.cpp:569]     Test net output #0: accuracy = 0.9435
I0318 22:27:08.792506 27880 solver.cpp:569]     Test net output #1: loss = 0.14294 (* 1 = 0.14294 loss)
I0318 22:27:08.792510 27880 solver.cpp:569]     Test net output #2: top-1 = 0.9435
I0318 22:27:09.040197 27880 solver.cpp:316] Iteration 3000 (2.91992 iter/s, 17.1238s/50 iter), loss = 0.0485584, remaining 0 hours and 51 minutes
I0318 22:27:09.040221 27880 solver.cpp:337]     Train net output #0: loss = 0.0485584 (* 1 = 0.0485584 loss)
I0318 22:27:09.040228 27880 sgd_solver.cpp:152] Iteration 3000, lr = 0.0001
I0318 22:27:21.924192 27880 solver.cpp:316] Iteration 3050 (3.88094 iter/s, 12.8835s/50 iter), loss = 0.0169409, remaining 0 hours and 38 minutes
I0318 22:27:21.924219 27880 solver.cpp:337]     Train net output #0: loss = 0.0169408 (* 1 = 0.0169408 loss)
I0318 22:27:21.924226 27880 sgd_solver.cpp:152] Iteration 3050, lr = 0.0001
I0318 22:27:34.857622 27880 solver.cpp:316] Iteration 3100 (3.86611 iter/s, 12.9329s/50 iter), loss = 0.0102027, remaining 0 hours and 38 minutes
I0318 22:27:34.859872 27880 solver.cpp:337]     Train net output #0: loss = 0.0102026 (* 1 = 0.0102026 loss)
I0318 22:27:34.859879 27880 sgd_solver.cpp:152] Iteration 3100, lr = 0.0001
I0318 22:27:47.798596 27880 solver.cpp:316] Iteration 3150 (3.86452 iter/s, 12.9382s/50 iter), loss = 0.0583167, remaining 0 hours and 38 minutes
I0318 22:27:47.798626 27880 solver.cpp:337]     Train net output #0: loss = 0.0583167 (* 1 = 0.0583167 loss)
I0318 22:27:47.798632 27880 sgd_solver.cpp:152] Iteration 3150, lr = 0.0001
I0318 22:28:00.756345 27880 solver.cpp:316] Iteration 3200 (3.85885 iter/s, 12.9572s/50 iter), loss = 0.0386666, remaining 0 hours and 37 minutes
I0318 22:28:00.756374 27880 solver.cpp:337]     Train net output #0: loss = 0.0386666 (* 1 = 0.0386666 loss)
I0318 22:28:00.756381 27880 sgd_solver.cpp:152] Iteration 3200, lr = 0.0001
I0318 22:28:13.700937 27880 solver.cpp:316] Iteration 3250 (3.86278 iter/s, 12.9441s/50 iter), loss = 0.024141, remaining 0 hours and 37 minutes
I0318 22:28:13.701115 27880 solver.cpp:337]     Train net output #0: loss = 0.0241409 (* 1 = 0.0241409 loss)
I0318 22:28:13.701123 27880 sgd_solver.cpp:152] Iteration 3250, lr = 0.0001
I0318 22:28:26.635524 27880 solver.cpp:316] Iteration 3300 (3.86581 iter/s, 12.9339s/50 iter), loss = 0.0245676, remaining 0 hours and 37 minutes
I0318 22:28:26.635551 27880 solver.cpp:337]     Train net output #0: loss = 0.0245676 (* 1 = 0.0245676 loss)
I0318 22:28:26.635557 27880 sgd_solver.cpp:152] Iteration 3300, lr = 0.0001
I0318 22:28:39.567678 27880 solver.cpp:316] Iteration 3350 (3.86649 iter/s, 12.9316s/50 iter), loss = 0.0141896, remaining 0 hours and 37 minutes
I0318 22:28:39.567708 27880 solver.cpp:337]     Train net output #0: loss = 0.0141896 (* 1 = 0.0141896 loss)
I0318 22:28:39.567713 27880 sgd_solver.cpp:152] Iteration 3350, lr = 0.0001
I0318 22:28:52.508266 27880 solver.cpp:316] Iteration 3400 (3.86397 iter/s, 12.9401s/50 iter), loss = 0.0277978, remaining 0 hours and 37 minutes
I0318 22:28:52.508405 27880 solver.cpp:337]     Train net output #0: loss = 0.0277978 (* 1 = 0.0277978 loss)
I0318 22:28:52.508414 27880 sgd_solver.cpp:152] Iteration 3400, lr = 0.0001
I0318 22:29:05.461354 27880 solver.cpp:316] Iteration 3450 (3.86028 iter/s, 12.9524s/50 iter), loss = 0.0344752, remaining 0 hours and 36 minutes
I0318 22:29:05.461383 27880 solver.cpp:337]     Train net output #0: loss = 0.0344752 (* 1 = 0.0344752 loss)
I0318 22:29:05.461388 27880 sgd_solver.cpp:152] Iteration 3450, lr = 0.0001
I0318 22:29:18.144724 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_3500.caffemodel
I0318 22:29:20.467988 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_3500.solverstate
I0318 22:29:21.154119 27880 solver.cpp:316] Iteration 3500 (3.18631 iter/s, 15.6921s/50 iter), loss = 0.0434563, remaining 0 hours and 44 minutes
I0318 22:29:21.154145 27880 solver.cpp:337]     Train net output #0: loss = 0.0434563 (* 1 = 0.0434563 loss)
I0318 22:29:21.154152 27880 sgd_solver.cpp:152] Iteration 3500, lr = 0.0001
I0318 22:29:33.992182 27880 solver.cpp:316] Iteration 3550 (3.89483 iter/s, 12.8375s/50 iter), loss = 0.0362136, remaining 0 hours and 35 minutes
I0318 22:29:33.992319 27880 solver.cpp:337]     Train net output #0: loss = 0.0362136 (* 1 = 0.0362136 loss)
I0318 22:29:33.992327 27880 sgd_solver.cpp:152] Iteration 3550, lr = 0.0001
I0318 22:29:46.934116 27880 solver.cpp:316] Iteration 3600 (3.8636 iter/s, 12.9413s/50 iter), loss = 0.0156259, remaining 0 hours and 36 minutes
I0318 22:29:46.934144 27880 solver.cpp:337]     Train net output #0: loss = 0.0156258 (* 1 = 0.0156258 loss)
I0318 22:29:46.934150 27880 sgd_solver.cpp:152] Iteration 3600, lr = 0.0001
I0318 22:29:59.872207 27880 solver.cpp:316] Iteration 3650 (3.86472 iter/s, 12.9376s/50 iter), loss = 0.0260915, remaining 0 hours and 35 minutes
I0318 22:29:59.872234 27880 solver.cpp:337]     Train net output #0: loss = 0.0260915 (* 1 = 0.0260915 loss)
I0318 22:29:59.872239 27880 sgd_solver.cpp:152] Iteration 3650, lr = 0.0001
I0318 22:30:12.819058 27880 solver.cpp:316] Iteration 3700 (3.8621 iter/s, 12.9463s/50 iter), loss = 0.021333, remaining 0 hours and 35 minutes
I0318 22:30:12.821544 27880 solver.cpp:337]     Train net output #0: loss = 0.021333 (* 1 = 0.021333 loss)
I0318 22:30:12.821552 27880 sgd_solver.cpp:152] Iteration 3700, lr = 0.0001
I0318 22:30:25.764441 27880 solver.cpp:316] Iteration 3750 (3.86327 iter/s, 12.9424s/50 iter), loss = 0.00815179, remaining 0 hours and 35 minutes
I0318 22:30:25.764469 27880 solver.cpp:337]     Train net output #0: loss = 0.00815176 (* 1 = 0.00815176 loss)
I0318 22:30:25.764475 27880 sgd_solver.cpp:152] Iteration 3750, lr = 0.0001
I0318 22:30:38.705844 27880 solver.cpp:316] Iteration 3800 (3.86373 iter/s, 12.9409s/50 iter), loss = 0.0140896, remaining 0 hours and 35 minutes
I0318 22:30:38.705870 27880 solver.cpp:337]     Train net output #0: loss = 0.0140896 (* 1 = 0.0140896 loss)
I0318 22:30:38.705876 27880 sgd_solver.cpp:152] Iteration 3800, lr = 0.0001
I0318 22:30:51.656994 27880 solver.cpp:316] Iteration 3850 (3.86082 iter/s, 12.9506s/50 iter), loss = 0.0137785, remaining 0 hours and 34 minutes
I0318 22:30:51.657137 27880 solver.cpp:337]     Train net output #0: loss = 0.0137784 (* 1 = 0.0137784 loss)
I0318 22:30:51.657145 27880 sgd_solver.cpp:152] Iteration 3850, lr = 0.0001
I0318 22:31:04.592650 27880 solver.cpp:316] Iteration 3900 (3.86548 iter/s, 12.935s/50 iter), loss = 0.0135123, remaining 0 hours and 34 minutes
I0318 22:31:04.592677 27880 solver.cpp:337]     Train net output #0: loss = 0.0135123 (* 1 = 0.0135123 loss)
I0318 22:31:04.592684 27880 sgd_solver.cpp:152] Iteration 3900, lr = 0.0001
I0318 22:31:17.528553 27880 solver.cpp:316] Iteration 3950 (3.86537 iter/s, 12.9354s/50 iter), loss = 0.0110792, remaining 0 hours and 34 minutes
I0318 22:31:17.528581 27880 solver.cpp:337]     Train net output #0: loss = 0.0110791 (* 1 = 0.0110791 loss)
I0318 22:31:17.528587 27880 sgd_solver.cpp:152] Iteration 3950, lr = 0.0001
I0318 22:31:30.208238 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_4000.caffemodel
I0318 22:31:32.491571 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_4000.solverstate
I0318 22:31:32.918642 27880 solver.cpp:470] Iteration 4000, Testing net (#0)
I0318 22:31:34.459908 27880 solver.cpp:569]     Test net output #0: accuracy = 0.94425
I0318 22:31:34.459934 27880 solver.cpp:569]     Test net output #1: loss = 0.138267 (* 1 = 0.138267 loss)
I0318 22:31:34.459937 27880 solver.cpp:569]     Test net output #2: top-1 = 0.94425
I0318 22:31:34.710978 27880 solver.cpp:316] Iteration 4000 (2.91007 iter/s, 17.1817s/50 iter), loss = 0.0268072, remaining 0 hours and 45 minutes
I0318 22:31:34.711001 27880 solver.cpp:337]     Train net output #0: loss = 0.0268071 (* 1 = 0.0268071 loss)
I0318 22:31:34.711009 27880 sgd_solver.cpp:152] Iteration 4000, lr = 0.0001
I0318 22:31:47.559696 27880 solver.cpp:316] Iteration 4050 (3.8916 iter/s, 12.8482s/50 iter), loss = 0.00910577, remaining 0 hours and 33 minutes
I0318 22:31:47.559723 27880 solver.cpp:337]     Train net output #0: loss = 0.00910574 (* 1 = 0.00910574 loss)
I0318 22:31:47.559731 27880 sgd_solver.cpp:152] Iteration 4050, lr = 0.0001
I0318 22:32:00.462949 27880 solver.cpp:316] Iteration 4100 (3.87515 iter/s, 12.9027s/50 iter), loss = 0.0121185, remaining 0 hours and 33 minutes
I0318 22:32:00.463075 27880 solver.cpp:337]     Train net output #0: loss = 0.0121184 (* 1 = 0.0121184 loss)
I0318 22:32:00.463084 27880 sgd_solver.cpp:152] Iteration 4100, lr = 0.0001
I0318 22:32:13.407673 27880 solver.cpp:316] Iteration 4150 (3.86277 iter/s, 12.9441s/50 iter), loss = 0.0165129, remaining 0 hours and 33 minutes
I0318 22:32:13.407701 27880 solver.cpp:337]     Train net output #0: loss = 0.0165129 (* 1 = 0.0165129 loss)
I0318 22:32:13.407707 27880 sgd_solver.cpp:152] Iteration 4150, lr = 0.0001
I0318 22:32:26.351073 27880 solver.cpp:316] Iteration 4200 (3.86313 iter/s, 12.9429s/50 iter), loss = 0.026778, remaining 0 hours and 33 minutes
I0318 22:32:26.351099 27880 solver.cpp:337]     Train net output #0: loss = 0.026778 (* 1 = 0.026778 loss)
I0318 22:32:26.351104 27880 sgd_solver.cpp:152] Iteration 4200, lr = 0.0001
I0318 22:32:39.270372 27880 solver.cpp:316] Iteration 4250 (3.87034 iter/s, 12.9188s/50 iter), loss = 0.0132263, remaining 0 hours and 33 minutes
I0318 22:32:39.270540 27880 solver.cpp:337]     Train net output #0: loss = 0.0132263 (* 1 = 0.0132263 loss)
I0318 22:32:39.270548 27880 sgd_solver.cpp:152] Iteration 4250, lr = 0.0001
I0318 22:32:52.220064 27880 solver.cpp:316] Iteration 4300 (3.8613 iter/s, 12.949s/50 iter), loss = 0.00986692, remaining 0 hours and 33 minutes
I0318 22:32:52.220093 27880 solver.cpp:337]     Train net output #0: loss = 0.00986688 (* 1 = 0.00986688 loss)
I0318 22:32:52.220098 27880 sgd_solver.cpp:152] Iteration 4300, lr = 0.0001
I0318 22:33:05.137416 27880 solver.cpp:316] Iteration 4350 (3.87092 iter/s, 12.9168s/50 iter), loss = 0.00273074, remaining 0 hours and 32 minutes
I0318 22:33:05.137445 27880 solver.cpp:337]     Train net output #0: loss = 0.00273069 (* 1 = 0.00273069 loss)
I0318 22:33:05.137451 27880 sgd_solver.cpp:152] Iteration 4350, lr = 0.0001
I0318 22:33:18.095886 27880 solver.cpp:316] Iteration 4400 (3.85864 iter/s, 12.9579s/50 iter), loss = 0.0374584, remaining 0 hours and 32 minutes
I0318 22:33:18.096035 27880 solver.cpp:337]     Train net output #0: loss = 0.0374583 (* 1 = 0.0374583 loss)
I0318 22:33:18.096043 27880 sgd_solver.cpp:152] Iteration 4400, lr = 0.0001
I0318 22:33:31.032280 27880 solver.cpp:316] Iteration 4450 (3.86526 iter/s, 12.9357s/50 iter), loss = 0.00365342, remaining 0 hours and 32 minutes
I0318 22:33:31.032306 27880 solver.cpp:337]     Train net output #0: loss = 0.00365336 (* 1 = 0.00365336 loss)
I0318 22:33:31.032312 27880 sgd_solver.cpp:152] Iteration 4450, lr = 0.0001
I0318 22:33:43.724967 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_4500.caffemodel
I0318 22:33:46.005513 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_4500.solverstate
I0318 22:33:46.684330 27880 solver.cpp:316] Iteration 4500 (3.1946 iter/s, 15.6514s/50 iter), loss = 0.0101943, remaining 0 hours and 39 minutes
I0318 22:33:46.684358 27880 solver.cpp:337]     Train net output #0: loss = 0.0101942 (* 1 = 0.0101942 loss)
I0318 22:33:46.684366 27880 sgd_solver.cpp:152] Iteration 4500, lr = 0.0001
I0318 22:33:59.526799 27880 solver.cpp:316] Iteration 4550 (3.89349 iter/s, 12.8419s/50 iter), loss = 0.013143, remaining 0 hours and 31 minutes
I0318 22:33:59.526931 27880 solver.cpp:337]     Train net output #0: loss = 0.0131429 (* 1 = 0.0131429 loss)
I0318 22:33:59.526938 27880 sgd_solver.cpp:152] Iteration 4550, lr = 0.0001
I0318 22:34:12.438323 27880 solver.cpp:316] Iteration 4600 (3.8727 iter/s, 12.9109s/50 iter), loss = 0.0354935, remaining 0 hours and 31 minutes
I0318 22:34:12.438351 27880 solver.cpp:337]     Train net output #0: loss = 0.0354934 (* 1 = 0.0354934 loss)
I0318 22:34:12.438357 27880 sgd_solver.cpp:152] Iteration 4600, lr = 0.0001
I0318 22:34:25.378269 27880 solver.cpp:316] Iteration 4650 (3.86416 iter/s, 12.9394s/50 iter), loss = 0.0372832, remaining 0 hours and 31 minutes
I0318 22:34:25.378296 27880 solver.cpp:337]     Train net output #0: loss = 0.0372831 (* 1 = 0.0372831 loss)
I0318 22:34:25.378302 27880 sgd_solver.cpp:152] Iteration 4650, lr = 0.0001
I0318 22:34:38.309561 27880 solver.cpp:316] Iteration 4700 (3.86675 iter/s, 12.9308s/50 iter), loss = 0.0185098, remaining 0 hours and 31 minutes
I0318 22:34:38.309707 27880 solver.cpp:337]     Train net output #0: loss = 0.0185097 (* 1 = 0.0185097 loss)
I0318 22:34:38.309716 27880 sgd_solver.cpp:152] Iteration 4700, lr = 0.0001
I0318 22:34:51.239387 27880 solver.cpp:316] Iteration 4750 (3.86722 iter/s, 12.9292s/50 iter), loss = 0.0154681, remaining 0 hours and 31 minutes
I0318 22:34:51.239415 27880 solver.cpp:337]     Train net output #0: loss = 0.0154681 (* 1 = 0.0154681 loss)
I0318 22:34:51.239421 27880 sgd_solver.cpp:152] Iteration 4750, lr = 0.0001
I0318 22:35:04.186543 27880 solver.cpp:316] Iteration 4800 (3.86201 iter/s, 12.9466s/50 iter), loss = 0.0334392, remaining 0 hours and 31 minutes
I0318 22:35:04.186573 27880 solver.cpp:337]     Train net output #0: loss = 0.0334391 (* 1 = 0.0334391 loss)
I0318 22:35:04.186578 27880 sgd_solver.cpp:152] Iteration 4800, lr = 0.0001
I0318 22:35:17.127024 27880 solver.cpp:316] Iteration 4850 (3.864 iter/s, 12.9399s/50 iter), loss = 0.0286051, remaining 0 hours and 30 minutes
I0318 22:35:17.127188 27880 solver.cpp:337]     Train net output #0: loss = 0.028605 (* 1 = 0.028605 loss)
I0318 22:35:17.127197 27880 sgd_solver.cpp:152] Iteration 4850, lr = 0.0001
I0318 22:35:30.052675 27880 solver.cpp:316] Iteration 4900 (3.86848 iter/s, 12.925s/50 iter), loss = 0.00756035, remaining 0 hours and 30 minutes
I0318 22:35:30.052702 27880 solver.cpp:337]     Train net output #0: loss = 0.00756028 (* 1 = 0.00756028 loss)
I0318 22:35:30.052709 27880 sgd_solver.cpp:152] Iteration 4900, lr = 0.0001
I0318 22:35:42.992863 27880 solver.cpp:316] Iteration 4950 (3.86409 iter/s, 12.9397s/50 iter), loss = 0.0216541, remaining 0 hours and 30 minutes
I0318 22:35:42.992892 27880 solver.cpp:337]     Train net output #0: loss = 0.021654 (* 1 = 0.021654 loss)
I0318 22:35:42.992897 27880 sgd_solver.cpp:152] Iteration 4950, lr = 0.0001
I0318 22:35:55.685668 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_5000.caffemodel
I0318 22:35:58.013816 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_5000.solverstate
I0318 22:35:58.447860 27880 solver.cpp:470] Iteration 5000, Testing net (#0)
I0318 22:35:59.908634 27880 solver.cpp:569]     Test net output #0: accuracy = 0.94525
I0318 22:35:59.908661 27880 solver.cpp:569]     Test net output #1: loss = 0.152897 (* 1 = 0.152897 loss)
I0318 22:35:59.908664 27880 solver.cpp:569]     Test net output #2: top-1 = 0.94525
I0318 22:36:00.161250 27880 solver.cpp:316] Iteration 5000 (2.91245 iter/s, 17.1677s/50 iter), loss = 0.00556658, remaining 0 hours and 39 minutes
I0318 22:36:00.161274 27880 solver.cpp:337]     Train net output #0: loss = 0.00556651 (* 1 = 0.00556651 loss)
I0318 22:36:00.161281 27880 sgd_solver.cpp:152] Iteration 5000, lr = 1e-05
I0318 22:36:12.997951 27880 solver.cpp:316] Iteration 5050 (3.89524 iter/s, 12.8362s/50 iter), loss = 0.00974352, remaining 0 hours and 29 minutes
I0318 22:36:12.997978 27880 solver.cpp:337]     Train net output #0: loss = 0.00974346 (* 1 = 0.00974346 loss)
I0318 22:36:12.997983 27880 sgd_solver.cpp:152] Iteration 5050, lr = 1e-05
I0318 22:36:25.924073 27880 solver.cpp:316] Iteration 5100 (3.8683 iter/s, 12.9256s/50 iter), loss = 0.0116707, remaining 0 hours and 29 minutes
I0318 22:36:25.924214 27880 solver.cpp:337]     Train net output #0: loss = 0.0116706 (* 1 = 0.0116706 loss)
I0318 22:36:25.924222 27880 sgd_solver.cpp:152] Iteration 5100, lr = 1e-05
I0318 22:36:38.863447 27880 solver.cpp:316] Iteration 5150 (3.86437 iter/s, 12.9387s/50 iter), loss = 0.00320254, remaining 0 hours and 29 minutes
I0318 22:36:38.863478 27880 solver.cpp:337]     Train net output #0: loss = 0.00320248 (* 1 = 0.00320248 loss)
I0318 22:36:38.863484 27880 sgd_solver.cpp:152] Iteration 5150, lr = 1e-05
I0318 22:36:51.790269 27880 solver.cpp:316] Iteration 5200 (3.86809 iter/s, 12.9263s/50 iter), loss = 0.00507052, remaining 0 hours and 29 minutes
I0318 22:36:51.790295 27880 solver.cpp:337]     Train net output #0: loss = 0.00507046 (* 1 = 0.00507046 loss)
I0318 22:36:51.790302 27880 sgd_solver.cpp:152] Iteration 5200, lr = 1e-05
I0318 22:37:04.726663 27880 solver.cpp:316] Iteration 5250 (3.86522 iter/s, 12.9359s/50 iter), loss = 0.00449283, remaining 0 hours and 28 minutes
I0318 22:37:04.726792 27880 solver.cpp:337]     Train net output #0: loss = 0.00449278 (* 1 = 0.00449278 loss)
I0318 22:37:04.726799 27880 sgd_solver.cpp:152] Iteration 5250, lr = 1e-05
I0318 22:37:17.662139 27880 solver.cpp:316] Iteration 5300 (3.86553 iter/s, 12.9348s/50 iter), loss = 0.0332723, remaining 0 hours and 28 minutes
I0318 22:37:17.662169 27880 solver.cpp:337]     Train net output #0: loss = 0.0332722 (* 1 = 0.0332722 loss)
I0318 22:37:17.662175 27880 sgd_solver.cpp:152] Iteration 5300, lr = 1e-05
I0318 22:37:30.595214 27880 solver.cpp:316] Iteration 5350 (3.86622 iter/s, 12.9325s/50 iter), loss = 0.0114361, remaining 0 hours and 28 minutes
I0318 22:37:30.595244 27880 solver.cpp:337]     Train net output #0: loss = 0.0114361 (* 1 = 0.0114361 loss)
I0318 22:37:30.595250 27880 sgd_solver.cpp:152] Iteration 5350, lr = 1e-05
I0318 22:37:43.550503 27880 solver.cpp:316] Iteration 5400 (3.85959 iter/s, 12.9548s/50 iter), loss = 0.0157993, remaining 0 hours and 28 minutes
I0318 22:37:43.550676 27880 solver.cpp:337]     Train net output #0: loss = 0.0157993 (* 1 = 0.0157993 loss)
I0318 22:37:43.550686 27880 sgd_solver.cpp:152] Iteration 5400, lr = 1e-05
I0318 22:37:56.472043 27880 solver.cpp:316] Iteration 5450 (3.86971 iter/s, 12.9209s/50 iter), loss = 0.0166528, remaining 0 hours and 28 minutes
I0318 22:37:56.472071 27880 solver.cpp:337]     Train net output #0: loss = 0.0166528 (* 1 = 0.0166528 loss)
I0318 22:37:56.472076 27880 sgd_solver.cpp:152] Iteration 5450, lr = 1e-05
I0318 22:38:09.150234 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_5500.caffemodel
I0318 22:38:11.474295 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_5500.solverstate
I0318 22:38:12.156221 27880 solver.cpp:316] Iteration 5500 (3.18806 iter/s, 15.6835s/50 iter), loss = 0.0007874, remaining 0 hours and 33 minutes
I0318 22:38:12.156250 27880 solver.cpp:337]     Train net output #0: loss = 0.00078734 (* 1 = 0.00078734 loss)
I0318 22:38:12.156257 27880 sgd_solver.cpp:152] Iteration 5500, lr = 1e-05
I0318 22:38:25.014669 27880 solver.cpp:316] Iteration 5550 (3.88865 iter/s, 12.8579s/50 iter), loss = 0.0107021, remaining 0 hours and 27 minutes
I0318 22:38:25.014802 27880 solver.cpp:337]     Train net output #0: loss = 0.010702 (* 1 = 0.010702 loss)
I0318 22:38:25.014811 27880 sgd_solver.cpp:152] Iteration 5550, lr = 1e-05
I0318 22:38:37.934434 27880 solver.cpp:316] Iteration 5600 (3.87023 iter/s, 12.9191s/50 iter), loss = 0.000870966, remaining 0 hours and 27 minutes
I0318 22:38:37.934464 27880 solver.cpp:337]     Train net output #0: loss = 0.000870906 (* 1 = 0.000870906 loss)
I0318 22:38:37.934470 27880 sgd_solver.cpp:152] Iteration 5600, lr = 1e-05
I0318 22:38:50.854447 27880 solver.cpp:316] Iteration 5650 (3.87013 iter/s, 12.9195s/50 iter), loss = 0.0054318, remaining 0 hours and 27 minutes
I0318 22:38:50.854476 27880 solver.cpp:337]     Train net output #0: loss = 0.00543174 (* 1 = 0.00543174 loss)
I0318 22:38:50.854482 27880 sgd_solver.cpp:152] Iteration 5650, lr = 1e-05
I0318 22:39:03.784147 27880 solver.cpp:316] Iteration 5700 (3.86723 iter/s, 12.9292s/50 iter), loss = 0.00396012, remaining 0 hours and 27 minutes
I0318 22:39:03.784307 27880 solver.cpp:337]     Train net output #0: loss = 0.00396006 (* 1 = 0.00396006 loss)
I0318 22:39:03.784315 27880 sgd_solver.cpp:152] Iteration 5700, lr = 1e-05
I0318 22:39:16.722275 27880 solver.cpp:316] Iteration 5750 (3.86475 iter/s, 12.9375s/50 iter), loss = 0.00417834, remaining 0 hours and 26 minutes
I0318 22:39:16.722302 27880 solver.cpp:337]     Train net output #0: loss = 0.00417828 (* 1 = 0.00417828 loss)
I0318 22:39:16.722309 27880 sgd_solver.cpp:152] Iteration 5750, lr = 1e-05
I0318 22:39:29.683492 27880 solver.cpp:316] Iteration 5800 (3.85782 iter/s, 12.9607s/50 iter), loss = 0.0043572, remaining 0 hours and 26 minutes
I0318 22:39:29.683519 27880 solver.cpp:337]     Train net output #0: loss = 0.00435713 (* 1 = 0.00435713 loss)
I0318 22:39:29.683526 27880 sgd_solver.cpp:152] Iteration 5800, lr = 1e-05
I0318 22:39:42.645298 27880 solver.cpp:316] Iteration 5850 (3.85765 iter/s, 12.9613s/50 iter), loss = 0.00659537, remaining 0 hours and 26 minutes
I0318 22:39:42.645462 27880 solver.cpp:337]     Train net output #0: loss = 0.0065953 (* 1 = 0.0065953 loss)
I0318 22:39:42.645485 27880 sgd_solver.cpp:152] Iteration 5850, lr = 1e-05
I0318 22:39:55.581853 27880 solver.cpp:316] Iteration 5900 (3.86522 iter/s, 12.9359s/50 iter), loss = 0.00512655, remaining 0 hours and 26 minutes
I0318 22:39:55.581882 27880 solver.cpp:337]     Train net output #0: loss = 0.00512648 (* 1 = 0.00512648 loss)
I0318 22:39:55.581889 27880 sgd_solver.cpp:152] Iteration 5900, lr = 1e-05
I0318 22:40:08.529651 27880 solver.cpp:316] Iteration 5950 (3.86182 iter/s, 12.9473s/50 iter), loss = 0.0101512, remaining 0 hours and 25 minutes
I0318 22:40:08.529680 27880 solver.cpp:337]     Train net output #0: loss = 0.0101511 (* 1 = 0.0101511 loss)
I0318 22:40:08.529685 27880 sgd_solver.cpp:152] Iteration 5950, lr = 1e-05
I0318 22:40:21.228608 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_6000.caffemodel
I0318 22:40:23.539186 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_6000.solverstate
I0318 22:40:23.969496 27880 solver.cpp:470] Iteration 6000, Testing net (#0)
I0318 22:40:25.425209 27880 solver.cpp:569]     Test net output #0: accuracy = 0.95025
I0318 22:40:25.425233 27880 solver.cpp:569]     Test net output #1: loss = 0.179643 (* 1 = 0.179643 loss)
I0318 22:40:25.425236 27880 solver.cpp:569]     Test net output #2: top-1 = 0.95025
I0318 22:40:25.673147 27880 solver.cpp:316] Iteration 6000 (2.91668 iter/s, 17.1428s/50 iter), loss = 0.0291128, remaining 0 hours and 34 minutes
I0318 22:40:25.673171 27880 solver.cpp:337]     Train net output #0: loss = 0.0291127 (* 1 = 0.0291127 loss)
I0318 22:40:25.673177 27880 sgd_solver.cpp:152] Iteration 6000, lr = 1e-05
I0318 22:40:38.544162 27880 solver.cpp:316] Iteration 6050 (3.88486 iter/s, 12.8705s/50 iter), loss = 0.00524031, remaining 0 hours and 25 minutes
I0318 22:40:38.544190 27880 solver.cpp:337]     Train net output #0: loss = 0.00524024 (* 1 = 0.00524024 loss)
I0318 22:40:38.544198 27880 sgd_solver.cpp:152] Iteration 6050, lr = 1e-05
I0318 22:40:51.478540 27880 solver.cpp:316] Iteration 6100 (3.86583 iter/s, 12.9338s/50 iter), loss = 0.0105848, remaining 0 hours and 25 minutes
I0318 22:40:51.478686 27880 solver.cpp:337]     Train net output #0: loss = 0.0105848 (* 1 = 0.0105848 loss)
I0318 22:40:51.478695 27880 sgd_solver.cpp:152] Iteration 6100, lr = 1e-05
I0318 22:41:04.411252 27880 solver.cpp:316] Iteration 6150 (3.86636 iter/s, 12.9321s/50 iter), loss = 0.00268045, remaining 0 hours and 25 minutes
I0318 22:41:04.411281 27880 solver.cpp:337]     Train net output #0: loss = 0.00268038 (* 1 = 0.00268038 loss)
I0318 22:41:04.411288 27880 sgd_solver.cpp:152] Iteration 6150, lr = 1e-05
I0318 22:41:17.350728 27880 solver.cpp:316] Iteration 6200 (3.8643 iter/s, 12.9389s/50 iter), loss = 0.0166685, remaining 0 hours and 24 minutes
I0318 22:41:17.350755 27880 solver.cpp:337]     Train net output #0: loss = 0.0166685 (* 1 = 0.0166685 loss)
I0318 22:41:17.350761 27880 sgd_solver.cpp:152] Iteration 6200, lr = 1e-05
I0318 22:41:30.285151 27880 solver.cpp:316] Iteration 6250 (3.86581 iter/s, 12.9339s/50 iter), loss = 0.0167171, remaining 0 hours and 24 minutes
I0318 22:41:30.285303 27880 solver.cpp:337]     Train net output #0: loss = 0.016717 (* 1 = 0.016717 loss)
I0318 22:41:30.285311 27880 sgd_solver.cpp:152] Iteration 6250, lr = 1e-05
I0318 22:41:43.239347 27880 solver.cpp:316] Iteration 6300 (3.85995 iter/s, 12.9535s/50 iter), loss = 0.00293004, remaining 0 hours and 24 minutes
I0318 22:41:43.239375 27880 solver.cpp:337]     Train net output #0: loss = 0.00292996 (* 1 = 0.00292996 loss)
I0318 22:41:43.239382 27880 sgd_solver.cpp:152] Iteration 6300, lr = 1e-05
I0318 22:41:56.182839 27880 solver.cpp:316] Iteration 6350 (3.8631 iter/s, 12.943s/50 iter), loss = 0.0271305, remaining 0 hours and 24 minutes
I0318 22:41:56.182868 27880 solver.cpp:337]     Train net output #0: loss = 0.0271304 (* 1 = 0.0271304 loss)
I0318 22:41:56.182873 27880 sgd_solver.cpp:152] Iteration 6350, lr = 1e-05
I0318 22:42:09.130127 27880 solver.cpp:316] Iteration 6400 (3.86197 iter/s, 12.9468s/50 iter), loss = 0.00552039, remaining 0 hours and 24 minutes
I0318 22:42:09.130293 27880 solver.cpp:337]     Train net output #0: loss = 0.00552031 (* 1 = 0.00552031 loss)
I0318 22:42:09.130303 27880 sgd_solver.cpp:152] Iteration 6400, lr = 1e-05
I0318 22:42:22.065415 27880 solver.cpp:316] Iteration 6450 (3.8656 iter/s, 12.9346s/50 iter), loss = 0.0155194, remaining 0 hours and 23 minutes
I0318 22:42:22.065445 27880 solver.cpp:337]     Train net output #0: loss = 0.0155193 (* 1 = 0.0155193 loss)
I0318 22:42:22.065450 27880 sgd_solver.cpp:152] Iteration 6450, lr = 1e-05
I0318 22:42:34.746119 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_6500.caffemodel
I0318 22:42:37.086644 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_6500.solverstate
I0318 22:42:37.776443 27880 solver.cpp:316] Iteration 6500 (3.18261 iter/s, 15.7104s/50 iter), loss = 0.00288862, remaining 0 hours and 28 minutes
I0318 22:42:37.776471 27880 solver.cpp:337]     Train net output #0: loss = 0.00288855 (* 1 = 0.00288855 loss)
I0318 22:42:37.776479 27880 sgd_solver.cpp:152] Iteration 6500, lr = 1e-05
I0318 22:42:50.599895 27880 solver.cpp:316] Iteration 6550 (3.89927 iter/s, 12.8229s/50 iter), loss = 0.00305484, remaining 0 hours and 23 minutes
I0318 22:42:50.600037 27880 solver.cpp:337]     Train net output #0: loss = 0.00305476 (* 1 = 0.00305476 loss)
I0318 22:42:50.600044 27880 sgd_solver.cpp:152] Iteration 6550, lr = 1e-05
I0318 22:43:03.535132 27880 solver.cpp:316] Iteration 6600 (3.8656 iter/s, 12.9346s/50 iter), loss = 0.0167769, remaining 0 hours and 23 minutes
I0318 22:43:03.535161 27880 solver.cpp:337]     Train net output #0: loss = 0.0167769 (* 1 = 0.0167769 loss)
I0318 22:43:03.535167 27880 sgd_solver.cpp:152] Iteration 6600, lr = 1e-05
I0318 22:43:16.489312 27880 solver.cpp:316] Iteration 6650 (3.85992 iter/s, 12.9536s/50 iter), loss = 0.00165762, remaining 0 hours and 23 minutes
I0318 22:43:16.489341 27880 solver.cpp:337]     Train net output #0: loss = 0.00165755 (* 1 = 0.00165755 loss)
I0318 22:43:16.489346 27880 sgd_solver.cpp:152] Iteration 6650, lr = 1e-05
I0318 22:43:29.428750 27880 solver.cpp:316] Iteration 6700 (3.86432 iter/s, 12.9389s/50 iter), loss = 0.00085853, remaining 0 hours and 22 minutes
I0318 22:43:29.428890 27880 solver.cpp:337]     Train net output #0: loss = 0.000858452 (* 1 = 0.000858452 loss)
I0318 22:43:29.428900 27880 sgd_solver.cpp:152] Iteration 6700, lr = 1e-05
I0318 22:43:42.360428 27880 solver.cpp:316] Iteration 6750 (3.86667 iter/s, 12.931s/50 iter), loss = 0.00284273, remaining 0 hours and 22 minutes
I0318 22:43:42.360456 27880 solver.cpp:337]     Train net output #0: loss = 0.00284265 (* 1 = 0.00284265 loss)
I0318 22:43:42.360462 27880 sgd_solver.cpp:152] Iteration 6750, lr = 1e-05
I0318 22:43:55.293964 27880 solver.cpp:316] Iteration 6800 (3.86608 iter/s, 12.933s/50 iter), loss = 0.0130978, remaining 0 hours and 22 minutes
I0318 22:43:55.293992 27880 solver.cpp:337]     Train net output #0: loss = 0.0130977 (* 1 = 0.0130977 loss)
I0318 22:43:55.293998 27880 sgd_solver.cpp:152] Iteration 6800, lr = 1e-05
I0318 22:44:08.238857 27880 solver.cpp:316] Iteration 6850 (3.86269 iter/s, 12.9444s/50 iter), loss = 0.000917483, remaining 0 hours and 22 minutes
I0318 22:44:08.239001 27880 solver.cpp:337]     Train net output #0: loss = 0.000917404 (* 1 = 0.000917404 loss)
I0318 22:44:08.239008 27880 sgd_solver.cpp:152] Iteration 6850, lr = 1e-05
I0318 22:44:21.189497 27880 solver.cpp:316] Iteration 6900 (3.86101 iter/s, 12.95s/50 iter), loss = 0.0149948, remaining 0 hours and 22 minutes
I0318 22:44:21.189523 27880 solver.cpp:337]     Train net output #0: loss = 0.0149947 (* 1 = 0.0149947 loss)
I0318 22:44:21.189529 27880 sgd_solver.cpp:152] Iteration 6900, lr = 1e-05
I0318 22:44:34.138846 27880 solver.cpp:316] Iteration 6950 (3.86136 iter/s, 12.9488s/50 iter), loss = 0.00297185, remaining 0 hours and 21 minutes
I0318 22:44:34.138875 27880 solver.cpp:337]     Train net output #0: loss = 0.00297177 (* 1 = 0.00297177 loss)
I0318 22:44:34.138881 27880 sgd_solver.cpp:152] Iteration 6950, lr = 1e-05
I0318 22:44:46.809284 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_7000.caffemodel
I0318 22:44:49.103963 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_7000.solverstate
I0318 22:44:49.541630 27880 solver.cpp:470] Iteration 7000, Testing net (#0)
I0318 22:44:51.001219 27880 solver.cpp:569]     Test net output #0: accuracy = 0.95
I0318 22:44:51.001245 27880 solver.cpp:569]     Test net output #1: loss = 0.20943 (* 1 = 0.20943 loss)
I0318 22:44:51.001248 27880 solver.cpp:569]     Test net output #2: top-1 = 0.95
I0318 22:44:51.249040 27880 solver.cpp:316] Iteration 7000 (2.92235 iter/s, 17.1095s/50 iter), loss = 0.0391158, remaining 0 hours and 28 minutes
I0318 22:44:51.249065 27880 solver.cpp:337]     Train net output #0: loss = 0.0391157 (* 1 = 0.0391157 loss)
I0318 22:44:51.249071 27880 sgd_solver.cpp:152] Iteration 7000, lr = 1e-05
I0318 22:45:04.103111 27880 solver.cpp:316] Iteration 7050 (3.88998 iter/s, 12.8535s/50 iter), loss = 0.00144064, remaining 0 hours and 21 minutes
I0318 22:45:04.103138 27880 solver.cpp:337]     Train net output #0: loss = 0.00144057 (* 1 = 0.00144057 loss)
I0318 22:45:04.103144 27880 sgd_solver.cpp:152] Iteration 7050, lr = 1e-05
I0318 22:45:17.022696 27880 solver.cpp:316] Iteration 7100 (3.87025 iter/s, 12.9191s/50 iter), loss = 0.00314609, remaining 0 hours and 20 minutes
I0318 22:45:17.022838 27880 solver.cpp:337]     Train net output #0: loss = 0.00314602 (* 1 = 0.00314602 loss)
I0318 22:45:17.022846 27880 sgd_solver.cpp:152] Iteration 7100, lr = 1e-05
I0318 22:45:29.947144 27880 solver.cpp:316] Iteration 7150 (3.86883 iter/s, 12.9238s/50 iter), loss = 0.0051794, remaining 0 hours and 20 minutes
I0318 22:45:29.947171 27880 solver.cpp:337]     Train net output #0: loss = 0.00517933 (* 1 = 0.00517933 loss)
I0318 22:45:29.947176 27880 sgd_solver.cpp:152] Iteration 7150, lr = 1e-05
I0318 22:45:42.894035 27880 solver.cpp:316] Iteration 7200 (3.86209 iter/s, 12.9464s/50 iter), loss = 0.0116821, remaining 0 hours and 20 minutes
I0318 22:45:42.894063 27880 solver.cpp:337]     Train net output #0: loss = 0.011682 (* 1 = 0.011682 loss)
I0318 22:45:42.894069 27880 sgd_solver.cpp:152] Iteration 7200, lr = 1e-05
I0318 22:45:55.834668 27880 solver.cpp:316] Iteration 7250 (3.86396 iter/s, 12.9401s/50 iter), loss = 0.00950489, remaining 0 hours and 20 minutes
I0318 22:45:55.834820 27880 solver.cpp:337]     Train net output #0: loss = 0.00950481 (* 1 = 0.00950481 loss)
I0318 22:45:55.834828 27880 sgd_solver.cpp:152] Iteration 7250, lr = 1e-05
I0318 22:46:08.770167 27880 solver.cpp:316] Iteration 7300 (3.86553 iter/s, 12.9348s/50 iter), loss = 0.0044015, remaining 0 hours and 20 minutes
I0318 22:46:08.770192 27880 solver.cpp:337]     Train net output #0: loss = 0.00440143 (* 1 = 0.00440143 loss)
I0318 22:46:08.770197 27880 sgd_solver.cpp:152] Iteration 7300, lr = 1e-05
I0318 22:46:21.713569 27880 solver.cpp:316] Iteration 7350 (3.86313 iter/s, 12.9429s/50 iter), loss = 0.00862438, remaining 0 hours and 19 minutes
I0318 22:46:21.713596 27880 solver.cpp:337]     Train net output #0: loss = 0.0086243 (* 1 = 0.0086243 loss)
I0318 22:46:21.713603 27880 sgd_solver.cpp:152] Iteration 7350, lr = 1e-05
I0318 22:46:34.652793 27880 solver.cpp:316] Iteration 7400 (3.86438 iter/s, 12.9387s/50 iter), loss = 0.0037693, remaining 0 hours and 19 minutes
I0318 22:46:34.652923 27880 solver.cpp:337]     Train net output #0: loss = 0.00376922 (* 1 = 0.00376922 loss)
I0318 22:46:34.652931 27880 sgd_solver.cpp:152] Iteration 7400, lr = 1e-05
I0318 22:46:47.601924 27880 solver.cpp:316] Iteration 7450 (3.86145 iter/s, 12.9485s/50 iter), loss = 0.00285877, remaining 0 hours and 19 minutes
I0318 22:46:47.601951 27880 solver.cpp:337]     Train net output #0: loss = 0.0028587 (* 1 = 0.0028587 loss)
I0318 22:46:47.601956 27880 sgd_solver.cpp:152] Iteration 7450, lr = 1e-05
I0318 22:47:00.286556 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_7500.caffemodel
I0318 22:47:02.570866 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_7500.solverstate
I0318 22:47:03.258836 27880 solver.cpp:316] Iteration 7500 (3.19361 iter/s, 15.6563s/50 iter), loss = 0.00138073, remaining 0 hours and 23 minutes
I0318 22:47:03.258862 27880 solver.cpp:337]     Train net output #0: loss = 0.00138066 (* 1 = 0.00138066 loss)
I0318 22:47:03.258870 27880 sgd_solver.cpp:152] Iteration 7500, lr = 1e-06
I0318 22:47:16.099802 27880 solver.cpp:316] Iteration 7550 (3.89395 iter/s, 12.8404s/50 iter), loss = 0.0117674, remaining 0 hours and 19 minutes
I0318 22:47:16.099977 27880 solver.cpp:337]     Train net output #0: loss = 0.0117673 (* 1 = 0.0117673 loss)
I0318 22:47:16.099987 27880 sgd_solver.cpp:152] Iteration 7550, lr = 1e-06
I0318 22:47:29.004650 27880 solver.cpp:316] Iteration 7600 (3.87472 iter/s, 12.9042s/50 iter), loss = 0.00151661, remaining 0 hours and 18 minutes
I0318 22:47:29.004678 27880 solver.cpp:337]     Train net output #0: loss = 0.00151654 (* 1 = 0.00151654 loss)
I0318 22:47:29.004684 27880 sgd_solver.cpp:152] Iteration 7600, lr = 1e-06
I0318 22:47:41.914680 27880 solver.cpp:316] Iteration 7650 (3.87312 iter/s, 12.9095s/50 iter), loss = 0.00291659, remaining 0 hours and 18 minutes
I0318 22:47:41.914708 27880 solver.cpp:337]     Train net output #0: loss = 0.00291652 (* 1 = 0.00291652 loss)
I0318 22:47:41.914714 27880 sgd_solver.cpp:152] Iteration 7650, lr = 1e-06
I0318 22:47:54.864049 27880 solver.cpp:316] Iteration 7700 (3.86135 iter/s, 12.9488s/50 iter), loss = 0.0136204, remaining 0 hours and 18 minutes
I0318 22:47:54.864176 27880 solver.cpp:337]     Train net output #0: loss = 0.0136203 (* 1 = 0.0136203 loss)
I0318 22:47:54.864199 27880 sgd_solver.cpp:152] Iteration 7700, lr = 1e-06
I0318 22:48:07.789178 27880 solver.cpp:316] Iteration 7750 (3.86862 iter/s, 12.9245s/50 iter), loss = 0.00128666, remaining 0 hours and 18 minutes
I0318 22:48:07.789206 27880 solver.cpp:337]     Train net output #0: loss = 0.00128659 (* 1 = 0.00128659 loss)
I0318 22:48:07.789212 27880 sgd_solver.cpp:152] Iteration 7750, lr = 1e-06
I0318 22:48:20.713431 27880 solver.cpp:316] Iteration 7800 (3.86886 iter/s, 12.9237s/50 iter), loss = 0.007936, remaining 0 hours and 18 minutes
I0318 22:48:20.713459 27880 solver.cpp:337]     Train net output #0: loss = 0.00793593 (* 1 = 0.00793593 loss)
I0318 22:48:20.713465 27880 sgd_solver.cpp:152] Iteration 7800, lr = 1e-06
I0318 22:48:33.626600 27880 solver.cpp:316] Iteration 7850 (3.87218 iter/s, 12.9126s/50 iter), loss = 0.00204725, remaining 0 hours and 17 minutes
I0318 22:48:33.626757 27880 solver.cpp:337]     Train net output #0: loss = 0.00204718 (* 1 = 0.00204718 loss)
I0318 22:48:33.626765 27880 sgd_solver.cpp:152] Iteration 7850, lr = 1e-06
I0318 22:48:46.561290 27880 solver.cpp:316] Iteration 7900 (3.86577 iter/s, 12.934s/50 iter), loss = 0.0360321, remaining 0 hours and 17 minutes
I0318 22:48:46.561318 27880 solver.cpp:337]     Train net output #0: loss = 0.0360321 (* 1 = 0.0360321 loss)
I0318 22:48:46.561324 27880 sgd_solver.cpp:152] Iteration 7900, lr = 1e-06
I0318 22:48:59.510120 27880 solver.cpp:316] Iteration 7950 (3.86151 iter/s, 12.9483s/50 iter), loss = 0.00753121, remaining 0 hours and 17 minutes
I0318 22:48:59.510147 27880 solver.cpp:337]     Train net output #0: loss = 0.00753114 (* 1 = 0.00753114 loss)
I0318 22:48:59.510154 27880 sgd_solver.cpp:152] Iteration 7950, lr = 1e-06
I0318 22:49:12.189106 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_8000.caffemodel
I0318 22:49:14.489270 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_8000.solverstate
I0318 22:49:14.917824 27880 solver.cpp:470] Iteration 8000, Testing net (#0)
I0318 22:49:16.373308 27880 solver.cpp:569]     Test net output #0: accuracy = 0.95025
I0318 22:49:16.373334 27880 solver.cpp:569]     Test net output #1: loss = 0.23584 (* 1 = 0.23584 loss)
I0318 22:49:16.373338 27880 solver.cpp:569]     Test net output #2: top-1 = 0.95025
I0318 22:49:16.617537 27880 solver.cpp:316] Iteration 8000 (2.92283 iter/s, 17.1067s/50 iter), loss = 0.00375114, remaining 0 hours and 22 minutes
I0318 22:49:16.617559 27880 solver.cpp:337]     Train net output #0: loss = 0.00375106 (* 1 = 0.00375106 loss)
I0318 22:49:16.617568 27880 sgd_solver.cpp:152] Iteration 8000, lr = 1e-06
I0318 22:49:29.471189 27880 solver.cpp:316] Iteration 8050 (3.8901 iter/s, 12.8531s/50 iter), loss = 0.00320064, remaining 0 hours and 16 minutes
I0318 22:49:29.471216 27880 solver.cpp:337]     Train net output #0: loss = 0.00320056 (* 1 = 0.00320056 loss)
I0318 22:49:29.471222 27880 sgd_solver.cpp:152] Iteration 8050, lr = 1e-06
I0318 22:49:42.399590 27880 solver.cpp:316] Iteration 8100 (3.86761 iter/s, 12.9279s/50 iter), loss = 0.0029221, remaining 0 hours and 16 minutes
I0318 22:49:42.400389 27880 solver.cpp:337]     Train net output #0: loss = 0.00292203 (* 1 = 0.00292203 loss)
I0318 22:49:42.400398 27880 sgd_solver.cpp:152] Iteration 8100, lr = 1e-06
I0318 22:49:55.313351 27880 solver.cpp:316] Iteration 8150 (3.87223 iter/s, 12.9125s/50 iter), loss = 0.010762, remaining 0 hours and 16 minutes
I0318 22:49:55.313381 27880 solver.cpp:337]     Train net output #0: loss = 0.0107619 (* 1 = 0.0107619 loss)
I0318 22:49:55.313387 27880 sgd_solver.cpp:152] Iteration 8150, lr = 1e-06
I0318 22:50:08.234149 27880 solver.cpp:316] Iteration 8200 (3.86989 iter/s, 12.9203s/50 iter), loss = 0.00203255, remaining 0 hours and 16 minutes
I0318 22:50:08.234177 27880 solver.cpp:337]     Train net output #0: loss = 0.00203248 (* 1 = 0.00203248 loss)
I0318 22:50:08.234184 27880 sgd_solver.cpp:152] Iteration 8200, lr = 1e-06
I0318 22:50:21.170641 27880 solver.cpp:316] Iteration 8250 (3.86519 iter/s, 12.936s/50 iter), loss = 0.0151557, remaining 0 hours and 16 minutes
I0318 22:50:21.170780 27880 solver.cpp:337]     Train net output #0: loss = 0.0151556 (* 1 = 0.0151556 loss)
I0318 22:50:21.170789 27880 sgd_solver.cpp:152] Iteration 8250, lr = 1e-06
I0318 22:50:34.108527 27880 solver.cpp:316] Iteration 8300 (3.86481 iter/s, 12.9372s/50 iter), loss = 0.0130311, remaining 0 hours and 15 minutes
I0318 22:50:34.108556 27880 solver.cpp:337]     Train net output #0: loss = 0.013031 (* 1 = 0.013031 loss)
I0318 22:50:34.108561 27880 sgd_solver.cpp:152] Iteration 8300, lr = 1e-06
I0318 22:50:47.019973 27880 solver.cpp:316] Iteration 8350 (3.87269 iter/s, 12.9109s/50 iter), loss = 0.00365191, remaining 0 hours and 15 minutes
I0318 22:50:47.020004 27880 solver.cpp:337]     Train net output #0: loss = 0.00365184 (* 1 = 0.00365184 loss)
I0318 22:50:47.020010 27880 sgd_solver.cpp:152] Iteration 8350, lr = 1e-06
I0318 22:50:59.948935 27880 solver.cpp:316] Iteration 8400 (3.86745 iter/s, 12.9284s/50 iter), loss = 0.0107539, remaining 0 hours and 15 minutes
I0318 22:50:59.949079 27880 solver.cpp:337]     Train net output #0: loss = 0.0107539 (* 1 = 0.0107539 loss)
I0318 22:50:59.949090 27880 sgd_solver.cpp:152] Iteration 8400, lr = 1e-06
I0318 22:51:12.873471 27880 solver.cpp:316] Iteration 8450 (3.8688 iter/s, 12.9239s/50 iter), loss = 0.0094155, remaining 0 hours and 15 minutes
I0318 22:51:12.873500 27880 solver.cpp:337]     Train net output #0: loss = 0.00941543 (* 1 = 0.00941543 loss)
I0318 22:51:12.873507 27880 sgd_solver.cpp:152] Iteration 8450, lr = 1e-06
I0318 22:51:25.566259 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_8500.caffemodel
I0318 22:51:27.901785 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_8500.solverstate
I0318 22:51:28.606734 27880 solver.cpp:316] Iteration 8500 (3.17811 iter/s, 15.7326s/50 iter), loss = 0.017581, remaining 0 hours and 18 minutes
I0318 22:51:28.606762 27880 solver.cpp:337]     Train net output #0: loss = 0.0175809 (* 1 = 0.0175809 loss)
I0318 22:51:28.606770 27880 sgd_solver.cpp:152] Iteration 8500, lr = 1e-06
I0318 22:51:41.462817 27880 solver.cpp:316] Iteration 8550 (3.88937 iter/s, 12.8556s/50 iter), loss = 0.00838934, remaining 0 hours and 14 minutes
I0318 22:51:41.462988 27880 solver.cpp:337]     Train net output #0: loss = 0.00838927 (* 1 = 0.00838927 loss)
I0318 22:51:41.462997 27880 sgd_solver.cpp:152] Iteration 8550, lr = 1e-06
I0318 22:51:54.359004 27880 solver.cpp:316] Iteration 8600 (3.87732 iter/s, 12.8955s/50 iter), loss = 0.00660369, remaining 0 hours and 14 minutes
I0318 22:51:54.359032 27880 solver.cpp:337]     Train net output #0: loss = 0.00660361 (* 1 = 0.00660361 loss)
I0318 22:51:54.359038 27880 sgd_solver.cpp:152] Iteration 8600, lr = 1e-06
I0318 22:52:07.299662 27880 solver.cpp:316] Iteration 8650 (3.86395 iter/s, 12.9401s/50 iter), loss = 0.00127623, remaining 0 hours and 14 minutes
I0318 22:52:07.299690 27880 solver.cpp:337]     Train net output #0: loss = 0.00127615 (* 1 = 0.00127615 loss)
I0318 22:52:07.299697 27880 sgd_solver.cpp:152] Iteration 8650, lr = 1e-06
I0318 22:52:20.247609 27880 solver.cpp:316] Iteration 8700 (3.86178 iter/s, 12.9474s/50 iter), loss = 0.0152832, remaining 0 hours and 14 minutes
I0318 22:52:20.249894 27880 solver.cpp:337]     Train net output #0: loss = 0.0152831 (* 1 = 0.0152831 loss)
I0318 22:52:20.249909 27880 sgd_solver.cpp:152] Iteration 8700, lr = 1e-06
I0318 22:52:33.172597 27880 solver.cpp:316] Iteration 8750 (3.86931 iter/s, 12.9222s/50 iter), loss = 0.00281938, remaining 0 hours and 13 minutes
I0318 22:52:33.172626 27880 solver.cpp:337]     Train net output #0: loss = 0.0028193 (* 1 = 0.0028193 loss)
I0318 22:52:33.172632 27880 sgd_solver.cpp:152] Iteration 8750, lr = 1e-06
I0318 22:52:46.096951 27880 solver.cpp:316] Iteration 8800 (3.86882 iter/s, 12.9238s/50 iter), loss = 0.00890101, remaining 0 hours and 13 minutes
I0318 22:52:46.096978 27880 solver.cpp:337]     Train net output #0: loss = 0.00890093 (* 1 = 0.00890093 loss)
I0318 22:52:46.096985 27880 sgd_solver.cpp:152] Iteration 8800, lr = 1e-06
I0318 22:52:59.038321 27880 solver.cpp:316] Iteration 8850 (3.86374 iter/s, 12.9408s/50 iter), loss = 0.00410784, remaining 0 hours and 13 minutes
I0318 22:52:59.038446 27880 solver.cpp:337]     Train net output #0: loss = 0.00410774 (* 1 = 0.00410774 loss)
I0318 22:52:59.038470 27880 sgd_solver.cpp:152] Iteration 8850, lr = 1e-06
I0318 22:53:11.966825 27880 solver.cpp:316] Iteration 8900 (3.86761 iter/s, 12.9279s/50 iter), loss = 0.0139697, remaining 0 hours and 13 minutes
I0318 22:53:11.966850 27880 solver.cpp:337]     Train net output #0: loss = 0.0139696 (* 1 = 0.0139696 loss)
I0318 22:53:11.966857 27880 sgd_solver.cpp:152] Iteration 8900, lr = 1e-06
I0318 22:53:24.917971 27880 solver.cpp:316] Iteration 8950 (3.86082 iter/s, 12.9506s/50 iter), loss = 0.00403372, remaining 0 hours and 12 minutes
I0318 22:53:24.918000 27880 solver.cpp:337]     Train net output #0: loss = 0.00403362 (* 1 = 0.00403362 loss)
I0318 22:53:24.918006 27880 sgd_solver.cpp:152] Iteration 8950, lr = 1e-06
I0318 22:53:37.589166 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_9000.caffemodel
I0318 22:53:39.943742 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_9000.solverstate
I0318 22:53:40.389623 27880 solver.cpp:470] Iteration 9000, Testing net (#0)
I0318 22:53:41.874673 27880 solver.cpp:569]     Test net output #0: accuracy = 0.952
I0318 22:53:41.874701 27880 solver.cpp:569]     Test net output #1: loss = 0.254345 (* 1 = 0.254345 loss)
I0318 22:53:41.874704 27880 solver.cpp:569]     Test net output #2: top-1 = 0.952
I0318 22:53:42.121755 27880 solver.cpp:316] Iteration 9000 (2.90645 iter/s, 17.2031s/50 iter), loss = 0.00265366, remaining 0 hours and 17 minutes
I0318 22:53:42.121780 27880 solver.cpp:337]     Train net output #0: loss = 0.00265356 (* 1 = 0.00265356 loss)
I0318 22:53:42.121788 27880 sgd_solver.cpp:152] Iteration 9000, lr = 1e-06
I0318 22:53:54.979694 27880 solver.cpp:316] Iteration 9050 (3.88881 iter/s, 12.8574s/50 iter), loss = 0.000738801, remaining 0 hours and 12 minutes
I0318 22:53:54.979722 27880 solver.cpp:337]     Train net output #0: loss = 0.000738703 (* 1 = 0.000738703 loss)
I0318 22:53:54.979727 27880 sgd_solver.cpp:152] Iteration 9050, lr = 1e-06
I0318 22:54:07.915369 27880 solver.cpp:316] Iteration 9100 (3.86544 iter/s, 12.9351s/50 iter), loss = 0.00820183, remaining 0 hours and 12 minutes
I0318 22:54:07.915529 27880 solver.cpp:337]     Train net output #0: loss = 0.00820173 (* 1 = 0.00820173 loss)
I0318 22:54:07.915537 27880 sgd_solver.cpp:152] Iteration 9100, lr = 1e-06
I0318 22:54:20.859441 27880 solver.cpp:316] Iteration 9150 (3.86297 iter/s, 12.9434s/50 iter), loss = 0.00193051, remaining 0 hours and 12 minutes
I0318 22:54:20.859469 27880 solver.cpp:337]     Train net output #0: loss = 0.00193041 (* 1 = 0.00193041 loss)
I0318 22:54:20.859475 27880 sgd_solver.cpp:152] Iteration 9150, lr = 1e-06
I0318 22:54:33.795965 27880 solver.cpp:316] Iteration 9200 (3.86519 iter/s, 12.936s/50 iter), loss = 0.000534137, remaining 0 hours and 11 minutes
I0318 22:54:33.795992 27880 solver.cpp:337]     Train net output #0: loss = 0.000534041 (* 1 = 0.000534041 loss)
I0318 22:54:33.795998 27880 sgd_solver.cpp:152] Iteration 9200, lr = 1e-06
I0318 22:54:46.723531 27880 solver.cpp:316] Iteration 9250 (3.86786 iter/s, 12.927s/50 iter), loss = 0.00466264, remaining 0 hours and 11 minutes
I0318 22:54:46.723664 27880 solver.cpp:337]     Train net output #0: loss = 0.00466255 (* 1 = 0.00466255 loss)
I0318 22:54:46.723688 27880 sgd_solver.cpp:152] Iteration 9250, lr = 1e-06
I0318 22:54:59.667492 27880 solver.cpp:316] Iteration 9300 (3.863 iter/s, 12.9433s/50 iter), loss = 0.00115325, remaining 0 hours and 11 minutes
I0318 22:54:59.667521 27880 solver.cpp:337]     Train net output #0: loss = 0.00115316 (* 1 = 0.00115316 loss)
I0318 22:54:59.667527 27880 sgd_solver.cpp:152] Iteration 9300, lr = 1e-06
I0318 22:55:12.601454 27880 solver.cpp:316] Iteration 9350 (3.86595 iter/s, 12.9334s/50 iter), loss = 0.00247142, remaining 0 hours and 11 minutes
I0318 22:55:12.601483 27880 solver.cpp:337]     Train net output #0: loss = 0.00247132 (* 1 = 0.00247132 loss)
I0318 22:55:12.601490 27880 sgd_solver.cpp:152] Iteration 9350, lr = 1e-06
I0318 22:55:25.535181 27880 solver.cpp:316] Iteration 9400 (3.86602 iter/s, 12.9332s/50 iter), loss = 0.00172776, remaining 0 hours and 11 minutes
I0318 22:55:25.537822 27880 solver.cpp:337]     Train net output #0: loss = 0.00172766 (* 1 = 0.00172766 loss)
I0318 22:55:25.537830 27880 sgd_solver.cpp:152] Iteration 9400, lr = 1e-06
I0318 22:55:38.463513 27880 solver.cpp:316] Iteration 9450 (3.86842 iter/s, 12.9252s/50 iter), loss = 0.00106769, remaining 0 hours and 10 minutes
I0318 22:55:38.463542 27880 solver.cpp:337]     Train net output #0: loss = 0.00106759 (* 1 = 0.00106759 loss)
I0318 22:55:38.463549 27880 sgd_solver.cpp:152] Iteration 9450, lr = 1e-06
I0318 22:55:51.147927 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_9500.caffemodel
I0318 22:55:53.460707 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_9500.solverstate
I0318 22:55:54.145205 27880 solver.cpp:316] Iteration 9500 (3.18856 iter/s, 15.6811s/50 iter), loss = 0.00386025, remaining 0 hours and 12 minutes
I0318 22:55:54.145232 27880 solver.cpp:337]     Train net output #0: loss = 0.00386015 (* 1 = 0.00386015 loss)
I0318 22:55:54.145239 27880 sgd_solver.cpp:152] Iteration 9500, lr = 1e-06
I0318 22:56:06.992609 27880 solver.cpp:316] Iteration 9550 (3.892 iter/s, 12.8469s/50 iter), loss = 0.0021806, remaining 0 hours and 10 minutes
I0318 22:56:06.992749 27880 solver.cpp:337]     Train net output #0: loss = 0.0021805 (* 1 = 0.0021805 loss)
I0318 22:56:06.992758 27880 sgd_solver.cpp:152] Iteration 9550, lr = 1e-06
I0318 22:56:19.949193 27880 solver.cpp:316] Iteration 9600 (3.85923 iter/s, 12.9559s/50 iter), loss = 0.00365603, remaining 0 hours and 10 minutes
I0318 22:56:19.949220 27880 solver.cpp:337]     Train net output #0: loss = 0.00365593 (* 1 = 0.00365593 loss)
I0318 22:56:19.949226 27880 sgd_solver.cpp:152] Iteration 9600, lr = 1e-06
I0318 22:56:32.876191 27880 solver.cpp:316] Iteration 9650 (3.86803 iter/s, 12.9265s/50 iter), loss = 0.0311544, remaining 0 hours and 10 minutes
I0318 22:56:32.876220 27880 solver.cpp:337]     Train net output #0: loss = 0.0311543 (* 1 = 0.0311543 loss)
I0318 22:56:32.876226 27880 sgd_solver.cpp:152] Iteration 9650, lr = 1e-06
I0318 22:56:45.805231 27880 solver.cpp:316] Iteration 9700 (3.86742 iter/s, 12.9285s/50 iter), loss = 0.0121277, remaining 0 hours and 9 minutes
I0318 22:56:45.805398 27880 solver.cpp:337]     Train net output #0: loss = 0.0121276 (* 1 = 0.0121276 loss)
I0318 22:56:45.805423 27880 sgd_solver.cpp:152] Iteration 9700, lr = 1e-06
I0318 22:56:58.763821 27880 solver.cpp:316] Iteration 9750 (3.85864 iter/s, 12.9579s/50 iter), loss = 0.00463365, remaining 0 hours and 9 minutes
I0318 22:56:58.763849 27880 solver.cpp:337]     Train net output #0: loss = 0.00463356 (* 1 = 0.00463356 loss)
I0318 22:56:58.763855 27880 sgd_solver.cpp:152] Iteration 9750, lr = 1e-06
I0318 22:57:11.702124 27880 solver.cpp:316] Iteration 9800 (3.86465 iter/s, 12.9378s/50 iter), loss = 0.0266669, remaining 0 hours and 9 minutes
I0318 22:57:11.702153 27880 solver.cpp:337]     Train net output #0: loss = 0.0266668 (* 1 = 0.0266668 loss)
I0318 22:57:11.702162 27880 sgd_solver.cpp:152] Iteration 9800, lr = 1e-06
I0318 22:57:24.634332 27880 solver.cpp:316] Iteration 9850 (3.86648 iter/s, 12.9317s/50 iter), loss = 0.0152497, remaining 0 hours and 9 minutes
I0318 22:57:24.634486 27880 solver.cpp:337]     Train net output #0: loss = 0.0152496 (* 1 = 0.0152496 loss)
I0318 22:57:24.634495 27880 sgd_solver.cpp:152] Iteration 9850, lr = 1e-06
I0318 22:57:37.573398 27880 solver.cpp:316] Iteration 9900 (3.86446 iter/s, 12.9384s/50 iter), loss = 0.00517092, remaining 0 hours and 9 minutes
I0318 22:57:37.573428 27880 solver.cpp:337]     Train net output #0: loss = 0.00517084 (* 1 = 0.00517084 loss)
I0318 22:57:37.573436 27880 sgd_solver.cpp:152] Iteration 9900, lr = 1e-06
I0318 22:57:50.511123 27880 solver.cpp:316] Iteration 9950 (3.86483 iter/s, 12.9372s/50 iter), loss = 0.0176131, remaining 0 hours and 8 minutes
I0318 22:57:50.511152 27880 solver.cpp:337]     Train net output #0: loss = 0.017613 (* 1 = 0.017613 loss)
I0318 22:57:50.511158 27880 sgd_solver.cpp:152] Iteration 9950, lr = 1e-06
I0318 22:58:03.191476 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_10000.caffemodel
I0318 22:58:05.511508 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_10000.solverstate
I0318 22:58:05.943190 27880 solver.cpp:470] Iteration 10000, Testing net (#0)
I0318 22:58:07.474198 27880 solver.cpp:569]     Test net output #0: accuracy = 0.953
I0318 22:58:07.474226 27880 solver.cpp:569]     Test net output #1: loss = 0.265429 (* 1 = 0.265429 loss)
I0318 22:58:07.474229 27880 solver.cpp:569]     Test net output #2: top-1 = 0.953
I0318 22:58:07.722684 27880 solver.cpp:316] Iteration 10000 (2.90514 iter/s, 17.2109s/50 iter), loss = 0.00615264, remaining 0 hours and 11 minutes
I0318 22:58:07.722708 27880 solver.cpp:337]     Train net output #0: loss = 0.00615255 (* 1 = 0.00615255 loss)
I0318 22:58:07.722715 27880 sgd_solver.cpp:152] Iteration 10000, lr = 1e-07
I0318 22:58:20.563879 27880 solver.cpp:316] Iteration 10050 (3.89388 iter/s, 12.8407s/50 iter), loss = 0.00395145, remaining 0 hours and 8 minutes
I0318 22:58:20.563905 27880 solver.cpp:337]     Train net output #0: loss = 0.00395137 (* 1 = 0.00395137 loss)
I0318 22:58:20.563911 27880 sgd_solver.cpp:152] Iteration 10050, lr = 1e-07
I0318 22:58:33.500857 27880 solver.cpp:316] Iteration 10100 (3.86505 iter/s, 12.9364s/50 iter), loss = 0.0062765, remaining 0 hours and 8 minutes
I0318 22:58:33.501021 27880 solver.cpp:337]     Train net output #0: loss = 0.00627641 (* 1 = 0.00627641 loss)
I0318 22:58:33.501029 27880 sgd_solver.cpp:152] Iteration 10100, lr = 1e-07
I0318 22:58:46.445456 27880 solver.cpp:316] Iteration 10150 (3.86281 iter/s, 12.9439s/50 iter), loss = 0.0236417, remaining 0 hours and 7 minutes
I0318 22:58:46.445485 27880 solver.cpp:337]     Train net output #0: loss = 0.0236416 (* 1 = 0.0236416 loss)
I0318 22:58:46.445492 27880 sgd_solver.cpp:152] Iteration 10150, lr = 1e-07
I0318 22:58:59.367204 27880 solver.cpp:316] Iteration 10200 (3.86961 iter/s, 12.9212s/50 iter), loss = 0.00344422, remaining 0 hours and 7 minutes
I0318 22:58:59.367233 27880 solver.cpp:337]     Train net output #0: loss = 0.00344414 (* 1 = 0.00344414 loss)
I0318 22:58:59.367239 27880 sgd_solver.cpp:152] Iteration 10200, lr = 1e-07
I0318 22:59:12.295739 27880 solver.cpp:316] Iteration 10250 (3.86757 iter/s, 12.928s/50 iter), loss = 0.0224441, remaining 0 hours and 7 minutes
I0318 22:59:12.295872 27880 solver.cpp:337]     Train net output #0: loss = 0.022444 (* 1 = 0.022444 loss)
I0318 22:59:12.295881 27880 sgd_solver.cpp:152] Iteration 10250, lr = 1e-07
I0318 22:59:25.235219 27880 solver.cpp:316] Iteration 10300 (3.86433 iter/s, 12.9388s/50 iter), loss = 0.00668709, remaining 0 hours and 7 minutes
I0318 22:59:25.235246 27880 solver.cpp:337]     Train net output #0: loss = 0.00668701 (* 1 = 0.00668701 loss)
I0318 22:59:25.235252 27880 sgd_solver.cpp:152] Iteration 10300, lr = 1e-07
I0318 22:59:38.166019 27880 solver.cpp:316] Iteration 10350 (3.8669 iter/s, 12.9303s/50 iter), loss = 0.00347316, remaining 0 hours and 6 minutes
I0318 22:59:38.166050 27880 solver.cpp:337]     Train net output #0: loss = 0.00347308 (* 1 = 0.00347308 loss)
I0318 22:59:38.166056 27880 sgd_solver.cpp:152] Iteration 10350, lr = 1e-07
I0318 22:59:51.106308 27880 solver.cpp:316] Iteration 10400 (3.86406 iter/s, 12.9398s/50 iter), loss = 0.00302699, remaining 0 hours and 6 minutes
I0318 22:59:51.106449 27880 solver.cpp:337]     Train net output #0: loss = 0.00302691 (* 1 = 0.00302691 loss)
I0318 22:59:51.106457 27880 sgd_solver.cpp:152] Iteration 10400, lr = 1e-07
I0318 23:00:04.051399 27880 solver.cpp:316] Iteration 10450 (3.86266 iter/s, 12.9444s/50 iter), loss = 0.00640637, remaining 0 hours and 6 minutes
I0318 23:00:04.051429 27880 solver.cpp:337]     Train net output #0: loss = 0.00640629 (* 1 = 0.00640629 loss)
I0318 23:00:04.051435 27880 sgd_solver.cpp:152] Iteration 10450, lr = 1e-07
I0318 23:00:16.736248 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_10500.caffemodel
I0318 23:00:19.070384 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_10500.solverstate
I0318 23:00:19.772004 27880 solver.cpp:316] Iteration 10500 (3.18067 iter/s, 15.72s/50 iter), loss = 0.000596346, remaining 0 hours and 7 minutes
I0318 23:00:19.772033 27880 solver.cpp:337]     Train net output #0: loss = 0.000596268 (* 1 = 0.000596268 loss)
I0318 23:00:19.772040 27880 sgd_solver.cpp:152] Iteration 10500, lr = 1e-07
I0318 23:00:32.656441 27880 solver.cpp:316] Iteration 10550 (3.88081 iter/s, 12.8839s/50 iter), loss = 0.0018425, remaining 0 hours and 6 minutes
I0318 23:00:32.656585 27880 solver.cpp:337]     Train net output #0: loss = 0.00184242 (* 1 = 0.00184242 loss)
I0318 23:00:32.656594 27880 sgd_solver.cpp:152] Iteration 10550, lr = 1e-07
I0318 23:00:45.568166 27880 solver.cpp:316] Iteration 10600 (3.87264 iter/s, 12.9111s/50 iter), loss = 0.0054654, remaining 0 hours and 5 minutes
I0318 23:00:45.568197 27880 solver.cpp:337]     Train net output #0: loss = 0.00546532 (* 1 = 0.00546532 loss)
I0318 23:00:45.568203 27880 sgd_solver.cpp:152] Iteration 10600, lr = 1e-07
I0318 23:00:58.494426 27880 solver.cpp:316] Iteration 10650 (3.86826 iter/s, 12.9257s/50 iter), loss = 0.00126672, remaining 0 hours and 5 minutes
I0318 23:00:58.494453 27880 solver.cpp:337]     Train net output #0: loss = 0.00126664 (* 1 = 0.00126664 loss)
I0318 23:00:58.494459 27880 sgd_solver.cpp:152] Iteration 10650, lr = 1e-07
I0318 23:01:11.423571 27880 solver.cpp:316] Iteration 10700 (3.86739 iter/s, 12.9286s/50 iter), loss = 0.00374911, remaining 0 hours and 5 minutes
I0318 23:01:11.423766 27880 solver.cpp:337]     Train net output #0: loss = 0.00374903 (* 1 = 0.00374903 loss)
I0318 23:01:11.423776 27880 sgd_solver.cpp:152] Iteration 10700, lr = 1e-07
I0318 23:01:24.367938 27880 solver.cpp:316] Iteration 10750 (3.86289 iter/s, 12.9437s/50 iter), loss = 0.015546, remaining 0 hours and 5 minutes
I0318 23:01:24.367965 27880 solver.cpp:337]     Train net output #0: loss = 0.0155459 (* 1 = 0.0155459 loss)
I0318 23:01:24.367971 27880 sgd_solver.cpp:152] Iteration 10750, lr = 1e-07
I0318 23:01:37.300642 27880 solver.cpp:316] Iteration 10800 (3.86633 iter/s, 12.9322s/50 iter), loss = 0.00270366, remaining 0 hours and 5 minutes
I0318 23:01:37.300670 27880 solver.cpp:337]     Train net output #0: loss = 0.00270358 (* 1 = 0.00270358 loss)
I0318 23:01:37.300678 27880 sgd_solver.cpp:152] Iteration 10800, lr = 1e-07
I0318 23:01:50.233701 27880 solver.cpp:316] Iteration 10850 (3.86622 iter/s, 12.9325s/50 iter), loss = 0.00399806, remaining 0 hours and 4 minutes
I0318 23:01:50.233839 27880 solver.cpp:337]     Train net output #0: loss = 0.00399798 (* 1 = 0.00399798 loss)
I0318 23:01:50.233846 27880 sgd_solver.cpp:152] Iteration 10850, lr = 1e-07
I0318 23:02:03.160450 27880 solver.cpp:316] Iteration 10900 (3.86814 iter/s, 12.9261s/50 iter), loss = 0.00332232, remaining 0 hours and 4 minutes
I0318 23:02:03.160480 27880 solver.cpp:337]     Train net output #0: loss = 0.00332224 (* 1 = 0.00332224 loss)
I0318 23:02:03.160486 27880 sgd_solver.cpp:152] Iteration 10900, lr = 1e-07
I0318 23:02:16.086648 27880 solver.cpp:316] Iteration 10950 (3.86827 iter/s, 12.9257s/50 iter), loss = 0.0130703, remaining 0 hours and 4 minutes
I0318 23:02:16.086674 27880 solver.cpp:337]     Train net output #0: loss = 0.0130702 (* 1 = 0.0130702 loss)
I0318 23:02:16.086681 27880 sgd_solver.cpp:152] Iteration 10950, lr = 1e-07
I0318 23:02:28.764274 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_11000.caffemodel
I0318 23:02:31.094838 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_11000.solverstate
I0318 23:02:31.534430 27880 solver.cpp:470] Iteration 11000, Testing net (#0)
I0318 23:02:32.994511 27880 solver.cpp:569]     Test net output #0: accuracy = 0.95325
I0318 23:02:32.994535 27880 solver.cpp:569]     Test net output #1: loss = 0.271807 (* 1 = 0.271807 loss)
I0318 23:02:32.994539 27880 solver.cpp:569]     Test net output #2: top-1 = 0.95325
I0318 23:02:33.240386 27880 solver.cpp:316] Iteration 11000 (2.91493 iter/s, 17.153s/50 iter), loss = 0.00564631, remaining 0 hours and 5 minutes
I0318 23:02:33.240411 27880 solver.cpp:337]     Train net output #0: loss = 0.00564622 (* 1 = 0.00564622 loss)
I0318 23:02:33.240418 27880 sgd_solver.cpp:152] Iteration 11000, lr = 1e-07
I0318 23:02:46.095476 27880 solver.cpp:316] Iteration 11050 (3.88967 iter/s, 12.8546s/50 iter), loss = 0.0109306, remaining 0 hours and 3 minutes
I0318 23:02:46.095504 27880 solver.cpp:337]     Train net output #0: loss = 0.0109306 (* 1 = 0.0109306 loss)
I0318 23:02:46.095511 27880 sgd_solver.cpp:152] Iteration 11050, lr = 1e-07
I0318 23:02:59.014763 27880 solver.cpp:316] Iteration 11100 (3.87034 iter/s, 12.9188s/50 iter), loss = 0.00892306, remaining 0 hours and 3 minutes
I0318 23:02:59.014897 27880 solver.cpp:337]     Train net output #0: loss = 0.00892297 (* 1 = 0.00892297 loss)
I0318 23:02:59.014905 27880 sgd_solver.cpp:152] Iteration 11100, lr = 1e-07
I0318 23:03:11.944264 27880 solver.cpp:316] Iteration 11150 (3.86732 iter/s, 12.9289s/50 iter), loss = 0.00170281, remaining 0 hours and 3 minutes
I0318 23:03:11.944294 27880 solver.cpp:337]     Train net output #0: loss = 0.00170272 (* 1 = 0.00170272 loss)
I0318 23:03:11.944300 27880 sgd_solver.cpp:152] Iteration 11150, lr = 1e-07
I0318 23:03:24.865278 27880 solver.cpp:316] Iteration 11200 (3.86983 iter/s, 12.9205s/50 iter), loss = 0.0131268, remaining 0 hours and 3 minutes
I0318 23:03:24.865304 27880 solver.cpp:337]     Train net output #0: loss = 0.0131268 (* 1 = 0.0131268 loss)
I0318 23:03:24.865311 27880 sgd_solver.cpp:152] Iteration 11200, lr = 1e-07
I0318 23:03:37.802415 27880 solver.cpp:316] Iteration 11250 (3.865 iter/s, 12.9366s/50 iter), loss = 0.00321645, remaining 0 hours and 3 minutes
I0318 23:03:37.802567 27880 solver.cpp:337]     Train net output #0: loss = 0.00321635 (* 1 = 0.00321635 loss)
I0318 23:03:37.802575 27880 sgd_solver.cpp:152] Iteration 11250, lr = 1e-07
I0318 23:03:50.742739 27880 solver.cpp:316] Iteration 11300 (3.86409 iter/s, 12.9397s/50 iter), loss = 0.00278382, remaining 0 hours and 2 minutes
I0318 23:03:50.742767 27880 solver.cpp:337]     Train net output #0: loss = 0.00278373 (* 1 = 0.00278373 loss)
I0318 23:03:50.742774 27880 sgd_solver.cpp:152] Iteration 11300, lr = 1e-07
I0318 23:04:03.666115 27880 solver.cpp:316] Iteration 11350 (3.86912 iter/s, 12.9228s/50 iter), loss = 0.0134793, remaining 0 hours and 2 minutes
I0318 23:04:03.666143 27880 solver.cpp:337]     Train net output #0: loss = 0.0134792 (* 1 = 0.0134792 loss)
I0318 23:04:03.666149 27880 sgd_solver.cpp:152] Iteration 11350, lr = 1e-07
I0318 23:04:16.600823 27880 solver.cpp:316] Iteration 11400 (3.86573 iter/s, 12.9342s/50 iter), loss = 0.000876706, remaining 0 hours and 2 minutes
I0318 23:04:16.600965 27880 solver.cpp:337]     Train net output #0: loss = 0.000876611 (* 1 = 0.000876611 loss)
I0318 23:04:16.600973 27880 sgd_solver.cpp:152] Iteration 11400, lr = 1e-07
I0318 23:04:29.548928 27880 solver.cpp:316] Iteration 11450 (3.86176 iter/s, 12.9475s/50 iter), loss = 0.00330582, remaining 0 hours and 2 minutes
I0318 23:04:29.548955 27880 solver.cpp:337]     Train net output #0: loss = 0.00330572 (* 1 = 0.00330572 loss)
I0318 23:04:29.548961 27880 sgd_solver.cpp:152] Iteration 11450, lr = 1e-07
I0318 23:04:42.248867 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_11500.caffemodel
I0318 23:04:44.573870 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_11500.solverstate
I0318 23:04:45.258697 27880 solver.cpp:316] Iteration 11500 (3.18286 iter/s, 15.7091s/50 iter), loss = 0.00191391, remaining 0 hours and 2 minutes
I0318 23:04:45.258724 27880 solver.cpp:337]     Train net output #0: loss = 0.00191382 (* 1 = 0.00191382 loss)
I0318 23:04:45.258733 27880 sgd_solver.cpp:152] Iteration 11500, lr = 1e-07
I0318 23:04:58.074204 27880 solver.cpp:316] Iteration 11550 (3.90168 iter/s, 12.815s/50 iter), loss = 0.0110167, remaining 0 hours and 1 minutes
I0318 23:04:58.074347 27880 solver.cpp:337]     Train net output #0: loss = 0.0110166 (* 1 = 0.0110166 loss)
I0318 23:04:58.074357 27880 sgd_solver.cpp:152] Iteration 11550, lr = 1e-07
I0318 23:05:10.984447 27880 solver.cpp:316] Iteration 11600 (3.87309 iter/s, 12.9096s/50 iter), loss = 0.0101553, remaining 0 hours and 1 minutes
I0318 23:05:10.984477 27880 solver.cpp:337]     Train net output #0: loss = 0.0101552 (* 1 = 0.0101552 loss)
I0318 23:05:10.984481 27880 sgd_solver.cpp:152] Iteration 11600, lr = 1e-07
I0318 23:05:23.898531 27880 solver.cpp:316] Iteration 11650 (3.8719 iter/s, 12.9136s/50 iter), loss = 0.0181445, remaining 0 hours and 1 minutes
I0318 23:05:23.898560 27880 solver.cpp:337]     Train net output #0: loss = 0.0181444 (* 1 = 0.0181444 loss)
I0318 23:05:23.898566 27880 sgd_solver.cpp:152] Iteration 11650, lr = 1e-07
I0318 23:05:36.819656 27880 solver.cpp:316] Iteration 11700 (3.86979 iter/s, 12.9206s/50 iter), loss = 0.00483269, remaining 0 hours and 1 minutes
I0318 23:05:36.819802 27880 solver.cpp:337]     Train net output #0: loss = 0.0048326 (* 1 = 0.0048326 loss)
I0318 23:05:36.819810 27880 sgd_solver.cpp:152] Iteration 11700, lr = 1e-07
I0318 23:05:49.741112 27880 solver.cpp:316] Iteration 11750 (3.86973 iter/s, 12.9208s/50 iter), loss = 0.00483417, remaining 0 hours and 1 minutes
I0318 23:05:49.741139 27880 solver.cpp:337]     Train net output #0: loss = 0.00483408 (* 1 = 0.00483408 loss)
I0318 23:05:49.741145 27880 sgd_solver.cpp:152] Iteration 11750, lr = 1e-07
I0318 23:06:02.686276 27880 solver.cpp:316] Iteration 11800 (3.86261 iter/s, 12.9446s/50 iter), loss = 0.0251835, remaining 0 hours and 0 minutes
I0318 23:06:02.686305 27880 solver.cpp:337]     Train net output #0: loss = 0.0251834 (* 1 = 0.0251834 loss)
I0318 23:06:02.686311 27880 sgd_solver.cpp:152] Iteration 11800, lr = 1e-07
I0318 23:06:15.613778 27880 solver.cpp:316] Iteration 11850 (3.86788 iter/s, 12.927s/50 iter), loss = 0.00151769, remaining 0 hours and 0 minutes
I0318 23:06:15.613948 27880 solver.cpp:337]     Train net output #0: loss = 0.0015176 (* 1 = 0.0015176 loss)
I0318 23:06:15.613957 27880 sgd_solver.cpp:152] Iteration 11850, lr = 1e-07
I0318 23:06:28.558969 27880 solver.cpp:316] Iteration 11900 (3.86264 iter/s, 12.9445s/50 iter), loss = 0.0204674, remaining 0 hours and 0 minutes
I0318 23:06:28.558997 27880 solver.cpp:337]     Train net output #0: loss = 0.0204673 (* 1 = 0.0204673 loss)
I0318 23:06:28.559003 27880 sgd_solver.cpp:152] Iteration 11900, lr = 1e-07
I0318 23:06:41.494978 27880 solver.cpp:316] Iteration 11950 (3.86534 iter/s, 12.9355s/50 iter), loss = 0.00447089, remaining 0 hours and 0 minutes
I0318 23:06:41.495007 27880 solver.cpp:337]     Train net output #0: loss = 0.0044708 (* 1 = 0.0044708 loss)
I0318 23:06:41.495012 27880 sgd_solver.cpp:152] Iteration 11950, lr = 1e-07
I0318 23:06:54.146538 27880 solver.cpp:981] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_12000.caffemodel
I0318 23:06:56.455327 27880 sgd_solver.cpp:319] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_12000.solverstate
I0318 23:06:56.984392 27880 solver.cpp:430] Iteration 12000, loss = 0.00785067
I0318 23:06:56.984416 27880 solver.cpp:470] Iteration 12000, Testing net (#0)
I0318 23:06:58.437901 27880 solver.cpp:569]     Test net output #0: accuracy = 0.953
I0318 23:06:58.437927 27880 solver.cpp:569]     Test net output #1: loss = 0.274989 (* 1 = 0.274989 loss)
I0318 23:06:58.437932 27880 solver.cpp:569]     Test net output #2: top-1 = 0.953
I0318 23:06:58.437934 27880 solver.cpp:438] Optimization Done (3.78568 iter/s).
I0318 23:06:58.437937 27880 caffe_interface.cpp:576] Optimization Done.
